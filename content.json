{"meta":{"title":"唐川的博客","subtitle":null,"description":"一只程序猿","author":"唐川","url":"http://jlutangchuan.github.io"},"pages":[{"title":"comment","date":"2018-12-20T15:13:48.000Z","updated":"2023-01-24T15:46:29.131Z","comments":true,"path":"comment/index.html","permalink":"http://jlutangchuan.github.io/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","raw":null,"content":null},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2023-01-24T15:46:29.132Z","comments":true,"path":"rss/index.html","permalink":"http://jlutangchuan.github.io/rss/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2023-01-24T15:46:29.131Z","comments":false,"path":"music/index.html","permalink":"http://jlutangchuan.github.io/music/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2023-01-24T15:46:29.132Z","comments":false,"path":"theme-sakura/index.html","permalink":"http://jlutangchuan.github.io/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro","raw":null,"content":null},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2023-01-24T15:46:29.133Z","comments":false,"path":"video/index.html","permalink":"http://jlutangchuan.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.reading .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","raw":null,"content":null}],"posts":[{"title":"个人插件推荐","slug":"生活/个人插件推荐","date":"2023-07-02T16:00:00.000Z","updated":"2023-07-03T15:10:25.746Z","comments":true,"path":"2023/07/03/sheng-huo/ge-ren-cha-jian-tui-jian/","link":"","permalink":"http://jlutangchuan.github.io/2023/07/03/sheng-huo/ge-ren-cha-jian-tui-jian/","excerpt":"","text":"个人插件推荐ChromeChrome插件安装情况如下： Web2023年7月3日近期阅读TODO list “自动驾驶的感知，定位，决策，控制哪个方向能在未来30年更容易赚钱？ - 知乎”“Occupancy Network综述！Grid-Centric的感知方法（BEV&#x2F;多任务&#x2F;轨迹预测等） - 知乎”“HDMapNet”“CVPR2023自动驾驶相关工作汇总(3D检测&#x2F;BEV&#x2F;端到端&#x2F;车道线&#x2F;SLAM等） - 知乎” 知识星球 VSCode background C&#x2F;C++ Chinese CMake CodeSnap Community Material diff filesize git history gitlens copilot indent-rainbow jupyter python pylance python indent Remote SSH vscode-icons vscode-cudacpp &#123; &quot;workbench.iconTheme&quot;: &quot;vscode-icons&quot;, &quot;leetcode.endpoint&quot;: &quot;leetcode-cn&quot;, &quot;leetcode.hint.configWebviewMarkdown&quot;: false, &quot;leetcode.hint.commandShortcut&quot;: false, &quot;background.enabled&quot;:true, &quot;background.useDefault&quot;: true, &quot;update.mode&quot;: &quot;manual&quot;, &quot;extensions.ignoreRecommendations&quot;: false, &quot;remote.SSH.remotePlatform&quot;: &#123; &quot;59.72.118.127&quot;: &quot;linux&quot;, &quot;Tangchuan&quot;: &quot;linux&quot;, &quot;03号机&quot;: &quot;linux&quot;, &quot;24号机&quot;: &quot;linux&quot;, &quot;Remote_Tangchuan&quot;: &quot;linux&quot;, &quot;Tangchuan_home&quot;: &quot;linux&quot;, &quot;Tangchuan_school&quot;: &quot;linux&quot;, &quot;Server03_home&quot;: &quot;linux&quot;, &quot;腾讯云&quot;: &quot;linux&quot;, &quot;Server24_home&quot;: &quot;linux&quot;, &quot;服务器&quot;: &quot;linux&quot;, &quot;服务器-21&quot;: &quot;linux&quot;, &quot;服务器-16&quot;: &quot;linux&quot;, &quot;服务器-20&quot;: &quot;linux&quot;, &quot;服务器-26&quot;: &quot;linux&quot;, &quot;AutoDL&quot;: &quot;linux&quot;, &quot;base服务器&quot;: &quot;linux&quot;, &quot;公共-1号机&quot;: &quot;linux&quot;, &quot;公共-11号机&quot;: &quot;linux&quot; &#125;, // &quot;terminal.integrated.shell.linux&quot;: &quot;/usr/bin/zsh&quot;, // &quot;terminal.integrated.profiles.windows&quot;: &#123; // &quot;Cmder&quot;: &#123; // &quot;path&quot;: &quot;$&#123;env:windir&#125;\\\\System32\\\\cmd.exe&quot;, // &quot;args&quot;: [&quot;/k&quot;, &quot;C:\\\\cmder\\\\vendor\\\\bin\\\\vscode_init.cmd&quot;] // &#125; // &#125;, // &quot;terminal.integrated.defaultProfile.windows&quot;: &quot;Cmder&quot;, &quot;files.associations&quot;: &#123; &quot;*.py&quot;: &quot;python&quot;, &quot;*.cjson&quot;: &quot;jsonc&quot;, &quot;*.wxss&quot;: &quot;css&quot;, &quot;*.wxs&quot;: &quot;javascript&quot; &#125;, &quot;background.style&quot;: &#123; &quot;content&quot;: &quot;&quot;, &quot;pointer-events&quot;: &quot;none&quot;, &quot;position&quot;: &quot;absolute&quot;, &quot;z-index&quot;: &quot;99999&quot;, &quot;width&quot;: &quot;100%&quot;, &quot;height&quot;: &quot;100%&quot;, &quot;background-position&quot;: &quot;100% 100%&quot;, &quot;background-repeat&quot;: &quot;no-repeat&quot;, &quot;opacity&quot;: 0.7 &#125;, &quot;glassit.alpha&quot;: 255, &quot;files.autoSave&quot;: &quot;off&quot;, &quot;workbench.colorTheme&quot;: &quot;Monokai Dimmed&quot;, &quot;editor.renderControlCharacters&quot;: true, &quot;terminal.integrated.inheritEnv&quot;: false, &quot;python.dataScience.sendSelectionToInteractiveWindow&quot;: true, &quot;python.dataScience.askForKernelRestart&quot;: false, &quot;sync.gist&quot;: &quot;90e24cdb98ed2c1129d6ee29eddadd86&quot;, // &quot;python.linting.pylintPath&quot;: &quot;/home/tangchuan/miniconda3/envs/pytorch_gpu/bin/pylint&quot;, &quot;workbench.startupEditor&quot;: &quot;welcomePage&quot;, &quot;editor.renderWhitespace&quot;: &quot;none&quot;, &quot;editor.formatOnPaste&quot;: false, &quot;python.showStartPage&quot;: false, &quot;latex-workshop.message.update.show&quot;: false, &quot;latex-workshop.view.pdf.viewer&quot;: &quot;browser&quot;, // &quot;python.linting.pylintPath&quot;: &quot;E:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\pytorch_env\\\\Scripts\\\\pylint.exe&quot;, // &quot;powermode.enabled&quot;: true, // &quot;powermode.shakeIntensity&quot;: 0, // &quot;powermode.presets&quot;: &quot;fireworks&quot;, &quot;latex-workshop.latex.recipes&quot;: [ &#123; &quot;name&quot;: &quot;xelatex&quot;, &quot;tools&quot;: [ &quot;xelatex&quot; ] &#125;, &#123; &quot;name&quot;: &quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;, &quot;tools&quot;: [ &quot;xelatex&quot;, &quot;bibtex&quot;, &quot;xelatex&quot;, &quot;xelatex&quot; ] &#125; ], &quot;latex-workshop.latex.tools&quot;: [ &#123; &quot;name&quot;: &quot;latexmk&quot;, &quot;command&quot;: &quot;latexmk&quot;, &quot;args&quot;: [ &quot;-synctex=1&quot;, &quot;-interaction=nonstopmode&quot;, &quot;-file-line-error&quot;, &quot;-pdf&quot;, &quot;%DOC%&quot; ] &#125;, &#123; &quot;name&quot;: &quot;xelatex&quot;, &quot;command&quot;: &quot;xelatex&quot;, &quot;args&quot;: [ &quot;-synctex=1&quot;, &quot;-interaction=nonstopmode&quot;, &quot;-file-line-error&quot;, &quot;%DOC%&quot; ] &#125;, &#123; &quot;name&quot;: &quot;bibtex&quot;, &quot;command&quot;: &quot;bibtex&quot;, &quot;args&quot;: [ &quot;%DOCFILE%&quot; ] &#125; ], &quot;latex-preview.command&quot;: &quot;xelatex&quot;, &quot;diffEditor.ignoreTrimWhitespace&quot;: false, &quot;vsicons.dontShowNewVersionMessage&quot;: true, &quot;remote.SSH.connectTimeout&quot;: 60, &quot;deadlines.conferences&quot;: [ // &quot;NeurIPS&quot;, // &quot;ICLR&quot;, // &quot;ICML&quot;, // &quot;CVPR&quot;, // &quot;ICCV&quot;, // &quot;ECCV&quot;, // &quot;AAAI&quot;, // &quot;AISTATS&quot;, &quot;IJCAI&quot;, // &quot;BMVC&quot;, // &quot;MM&quot; ], &quot;editor.wordWrap&quot;: &quot;on&quot;, &quot;git.confirmSync&quot;: false, &quot;explorer.confirmDelete&quot;: false, &quot;jupyter.textOutputLimit&quot;: 0, &quot;editor.accessibilitySupport&quot;: &quot;off&quot;, &quot;powershell.promptToUpdatePowerShell&quot;: false, // &quot;[vue]&quot;: &#123; // &quot;editor.defaultFormatter&quot;: &quot;esbenp.prettier-vscode&quot; // &#125;, &quot;liveServer.settings.donotShowInfoMsg&quot;: true, &quot;gitlens.views.branches.branches.layout&quot;: &quot;list&quot;, &quot;editor.inlineSuggest.enabled&quot;: true, // &quot;[html]&quot;: &#123; // &quot;editor.defaultFormatter&quot;: &quot;esbenp.prettier-vscode&quot; // &#125;, &quot;security.workspace.trust.untrustedFiles&quot;: &quot;open&quot;, &quot;workbench.editorAssociations&quot;: &#123; &quot;*.ipynb&quot;: &quot;jupyter-notebook&quot; &#125;, &quot;python.languageServer&quot;: &quot;Jedi&quot;, &quot;jupyter.interactiveWindowMode&quot;: &quot;perFile&quot;, &quot;notebook.cellToolbarLocation&quot;: &#123; &quot;default&quot;: &quot;right&quot;, &quot;jupyter-notebook&quot;: &quot;left&quot; &#125;, &quot;editor.formatOnSave&quot;: false, &quot;editor.formatOnType&quot;: false, &quot;json.maxItemsComputed&quot;: 1000, &quot;remote.SSH.showLoginTerminal&quot;: true, &quot;github.copilot.enable&quot;: &#123; &quot;*&quot;: true, &quot;yaml&quot;: true, &quot;plaintext&quot;: true, &quot;markdown&quot;: true, &quot;python&quot;: true, &quot;cpp&quot;: false &#125;, &quot;cmake.configureOnOpen&quot;: true, &quot;leetcode.defaultLanguage&quot;: &quot;cpp&quot;, &quot;leetcode.workspaceFolder&quot;: &quot;e:\\\\workdir\\\\MyAlgorithm\\\\Leetcode&quot;, &quot;leetcode.hint.commentDescription&quot;: false, &quot;settingsSync.ignoredExtensions&quot;: [ &quot;ms-python.python&quot;, &quot;tht13.python&quot; ], // &quot;terminal.integrated.defaultProfile.windows&quot;: &quot;/usr/bin/zsh (migrated)&quot;, &quot;terminal.integrated.fontFamily&quot;: &quot;MesloLGM NF&quot;, &quot;terminal.integrated.profiles.windows&quot;: &#123; &quot;PowerShell&quot;: &#123; &quot;source&quot;: &quot;PowerShell&quot;, &quot;icon&quot;: &quot;terminal-powershell&quot; &#125;, &quot;CMD&quot;: &#123; &quot;path&quot;: [ &quot;$&#123;env:windir&#125;\\\\Sysnative\\\\cmd.exe&quot;, &quot;$&#123;env:windir&#125;\\\\System32\\\\cmd.exe&quot; ], &quot;args&quot;: [], &quot;icon&quot;: &quot;terminal-cmd&quot; &#125;, &quot;Git Bash&quot;: &#123; &quot;source&quot;: &quot;Git Bash&quot; &#125;, // &quot;/usr/bin/zsh (migrated)&quot;: &#123; // &quot;path&quot;: &quot;/usr/bin/zsh&quot;, // &quot;args&quot;: [] // &#125; &#125;, &quot;terminal.integrated.defaultProfile.linux&quot;: &quot;zsh&quot;, &quot;bracket-pair-colorizer-2.depreciation-notice&quot;: false, &quot;notebook.lineNumbers&quot;: &quot;on&quot;, &quot;terminal.integrated.defaultProfile.windows&quot;: &quot;PowerShell&quot;, &quot;grunt.autoDetect&quot;: &quot;on&quot;, &quot;workbench.editor.autoLockGroups&quot;: &#123; &quot;terminalEditor&quot;: false &#125;, &quot;workbench.editor.enablePreviewFromCodeNavigation&quot;: true, &quot;terminal.integrated.shell.windows&quot;: &quot;C:\\\\Windows\\\\System32\\\\cmd.exe&quot;, &quot;code-runner.executorMap&quot;: &#123; &quot;javascript&quot;: &quot;node&quot;, &quot;java&quot;: &quot;cd $dir &amp;&amp; javac $fileName &amp;&amp; java $fileNameWithoutExt&quot;, &quot;c&quot;: &quot;cd $dir &amp;&amp; gcc $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;cpp&quot;: &quot;cd $dir &amp;&amp; g++ $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;objective-c&quot;: &quot;cd $dir &amp;&amp; gcc -framework Cocoa $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;php&quot;: &quot;php&quot;, &quot;python&quot;: &quot;python -u&quot;, &quot;perl&quot;: &quot;perl&quot;, &quot;perl6&quot;: &quot;perl6&quot;, &quot;ruby&quot;: &quot;ruby&quot;, &quot;go&quot;: &quot;go run&quot;, &quot;lua&quot;: &quot;lua&quot;, &quot;groovy&quot;: &quot;groovy&quot;, &quot;powershell&quot;: &quot;powershell -ExecutionPolicy ByPass -File&quot;, &quot;bat&quot;: &quot;cmd /c&quot;, &quot;shellscript&quot;: &quot;bash&quot;, &quot;fsharp&quot;: &quot;fsi&quot;, &quot;csharp&quot;: &quot;scriptcs&quot;, &quot;vbscript&quot;: &quot;cscript //Nologo&quot;, &quot;typescript&quot;: &quot;ts-node&quot;, &quot;coffeescript&quot;: &quot;coffee&quot;, &quot;scala&quot;: &quot;scala&quot;, &quot;swift&quot;: &quot;swift&quot;, &quot;julia&quot;: &quot;julia&quot;, &quot;crystal&quot;: &quot;crystal&quot;, &quot;ocaml&quot;: &quot;ocaml&quot;, &quot;r&quot;: &quot;Rscript&quot;, &quot;applescript&quot;: &quot;osascript&quot;, &quot;clojure&quot;: &quot;lein exec&quot;, &quot;haxe&quot;: &quot;haxe --cwd $dirWithoutTrailingSlash --run $fileNameWithoutExt&quot;, &quot;rust&quot;: &quot;cd $dir &amp;&amp; rustc $fileName &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;racket&quot;: &quot;racket&quot;, &quot;scheme&quot;: &quot;csi -script&quot;, &quot;ahk&quot;: &quot;autohotkey&quot;, &quot;autoit&quot;: &quot;autoit3&quot;, &quot;dart&quot;: &quot;dart&quot;, &quot;pascal&quot;: &quot;cd $dir &amp;&amp; fpc $fileName &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;d&quot;: &quot;cd $dir &amp;&amp; dmd $fileName &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;haskell&quot;: &quot;runhaskell&quot;, &quot;nim&quot;: &quot;nim compile --verbosity:0 --hints:off --run&quot;, &quot;lisp&quot;: &quot;sbcl --script&quot;, &quot;kit&quot;: &quot;kitc --run&quot;, &quot;v&quot;: &quot;v run&quot;, &quot;sass&quot;: &quot;sass --style expanded&quot;, &quot;scss&quot;: &quot;scss --style expanded&quot;, &quot;less&quot;: &quot;cd $dir &amp;&amp; lessc $fileName $fileNameWithoutExt.css&quot;, &quot;FortranFreeForm&quot;: &quot;cd $dir &amp;&amp; gfortran $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;fortran-modern&quot;: &quot;cd $dir &amp;&amp; gfortran $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;fortran_fixed-form&quot;: &quot;cd $dir &amp;&amp; gfortran $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;fortran&quot;: &quot;cd $dir &amp;&amp; gfortran $fileName -o $fileNameWithoutExt &amp;&amp; $dir$fileNameWithoutExt&quot;, &quot;sml&quot;: &quot;cd $dir &amp;&amp; sml $fileName&quot; &#125;, &quot;code-runner.runInTerminal&quot;: true, &quot;terminal.integrated.enableMultiLinePasteWarning&quot;: false, &quot;emmet.includeLanguages&quot;: &#123; &quot;wxml&quot;: &quot;html&quot; &#125;, &quot;minapp-vscode.disableAutoConfig&quot;: true, &quot;workbench.editor.untitled.hint&quot;: &quot;hidden&quot;, &quot;window.commandCenter&quot;: true, &quot;workbench.layoutControl.enabled&quot;: false, &quot;MarkdownPaste.path&quot;: &quot;$&#123;fileDirname&#125;/images/&quot;, &quot;MarkdownPaste.namePrefix&quot;: &quot;img&quot;, &quot;[latex]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;mathematic.vscode-latex&quot; &#125;, &quot;terminal.integrated.automationProfile.linux&quot;: &#123; &#125;, &quot;editor.smoothScrolling&quot;: true, &quot;terminal.integrated.smoothScrolling&quot;: true, &quot;editor.mouseWheelZoom&quot;: true, &quot;search.searchEditor.doubleClickBehaviour&quot;: &quot;selectWord&quot;, &quot;debug.onTaskErrors&quot;: &quot;abort&quot;, &quot;javascript.updateImportsOnFileMove.enabled&quot;: &quot;always&quot;, &quot;window.zoomLevel&quot;: 1, &#125;","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"http://jlutangchuan.github.io/tags/Chrome/"},{"name":"VSCode","slug":"VSCode","permalink":"http://jlutangchuan.github.io/tags/VSCode/"}]},{"title":"情绪价值","slug":"生活/情绪价值","date":"2023-03-04T02:19:00.000Z","updated":"2023-07-03T15:04:36.971Z","comments":true,"path":"2023/03/04/sheng-huo/qing-xu-jie-zhi/","link":"","permalink":"http://jlutangchuan.github.io/2023/03/04/sheng-huo/qing-xu-jie-zhi/","excerpt":"","text":"情绪价值情绪价值为伴侣创造价值，不只有物质价值，还有情绪价值。 情绪价值是指个体对他人情绪的影响能力，包括了正向情绪价值和负向情绪价值。为对方提供情绪价值，也即&#x3D;&#x3D;倾听、共情、理解、支持&#x3D;&#x3D;等方式让对方感受到积极情绪价值的能力，既能接住对方的负面情绪价值过滤并消化，也能共情对方的积极 每个人看重的价值不一样，而且为对方创造价值不是一味地讨好对方、看低自己，这种情况的人只能是感动了自己，但反而会让对方看轻。 情绪价值也不是玩手段，对对方PUA。 「情绪成熟」（Emotional Maturity），意味着能根据不同情境，做出适当、积极的反应。 a. 负责——既知道为自己的情绪负责，也愿意为自己给他人造成的负面情绪负责。换句话说，情绪成熟的人不会寄希望于对方完全为自己的情绪负责。(出现问题、犯错了要及时诚恳地道歉，不能打哈哈过去) b. 有适应能力，指的是有能力根据场景的变化调节自己的情绪，控制自己在情绪状态中的行为反应。同时，因为 ta 的适应能力良好，ta 掌握了情绪调节的技术，所以总体上，ta 会表现出一种情绪稳定的状态。而在亲密关系中，稳定的情绪状态也会让另一半感到安全、可靠。 c. 给予指的是一种付出的能力，表现为在情感上并不只关注自己的期望和要求，也会考虑他人、同理他人感受。 情绪价值的三个层次 满足对方的情绪需求，提供情绪价值（给予 低级别的情绪价值） 但总是不计回报的给予会让对方 共情，能够理解对方的感受，支持、认可和陪伴对方 看见与兼容，能够看见对方的脆弱与无助，看见对方的心里防御，清楚对方的痛点，拥有强大的心理包容接纳对方（同理心 专业的心理学知识与沟通技巧） 日常生活中如何做到为对方提供积极情绪价值？ 以积极建设性的方式回应对方分享的好消息（满足对方的期望，对方不喜欢被开玩笑而是希望能够得到赞同, 给对方&#x3D;&#x3D;认同感&#x3D;&#x3D;） 对日常小事表达高质量的感恩 秘密地为压力大的伴侣提供支持（对方压力大时公开地为对方表示支持可能会让对方压力更大） 争论爆发前，软化对话方式（当意见不合时，通过温和清晰的表达方式，让对方感知到尊重与关心） 情绪价值有哪几种？ 每段关系能长久维持必然是因为双方可以互相提供情绪价值，具体有以下几种： 1.治愈型价值：在我们伤心难过、迷茫心累的时候提供&#x3D;&#x3D;安慰和鼓励&#x3D;&#x3D; 2.指导型价值：在我们不思进取、过度膨胀的时候提供考虑问题的&#x3D;&#x3D;新视角和解决问题的方法论&#x3D;&#x3D; 3.分享型价值：在我们欣于所遇、需要知己的时候提供&#x3D;&#x3D;共同语言和思想碰撞&#x3D;&#x3D; 4.&#x3D;&#x3D;陪伴&#x3D;&#x3D;型价值：在我们空虚无聊寂寞冷的时候与我们作伴 5.&#x3D;&#x3D;猎奇&#x3D;&#x3D;型价值：在我们平淡枯燥、无所事事的时候打开新世界的大门 6.自娱型价值：在我们与他们的交往中能得到某些&#x3D;&#x3D;简单的快乐&#x3D;&#x3D;，且通常这种价值有附带的炫耀型情绪价值 7.怀旧型价值：因为之前有&#x3D;&#x3D;共同的经历&#x3D;&#x3D;且三观较为相符，在未来的生活中可以偶尔共同回忆往事形成怀旧型价值，从而形成长久稳定的低频率接触关系 8.&#x3D;&#x3D;自我实现型&#x3D;&#x3D;价值：在我们和他们的交往中，能够显示出自己的优越性获得嘚瑟的快感 人是受情绪支配的动物，无论是优秀还是平凡，都会需要安慰、指导、分享、陪伴和猎奇，所以每个人都是需要情绪价值的。 对于情绪价值的正确理解1.如果两个人能长久的从对方那里获取自己需要的情绪价值，那么不出意外这段关系就会一直维系下去。如果不能，只会有短期关系，而不会有长期稳态。 2.如果一方对另一方有情绪价值，而另一方对他却毫无情绪价值，这就属于降维打击，这样的关系就算短暂存在也不会长久；至少互相各有一条，才能长期维系。 3.不要指望一个人提供所有的价值。正常情况下，每个人都会根据自己的性格和经历提供一条或几条。 4.情绪价值是相对的，你对张三提供的价值，李四可能不感兴趣。 5.抛开物质价值的情况下，情绪价值是真实的不是装出来的，装也装不了一辈子。","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"台式机编程环境配置","slug":"技术/编程/台式机编程环境配置","date":"2023-01-27T16:00:00.000Z","updated":"2023-07-03T15:04:37.072Z","comments":true,"path":"2023/01/28/ji-zhu/bian-cheng/tai-shi-ji-bian-cheng-huan-jing-pei-zhi/","link":"","permalink":"http://jlutangchuan.github.io/2023/01/28/ji-zhu/bian-cheng/tai-shi-ji-bian-cheng-huan-jing-pei-zhi/","excerpt":"","text":"台式机编程环境配置配置清单 shell windows最新控制台 (powershell 7 + Terminal) psh插件管理 terminal 美化 (oh-my-posh) 字体 IDE vscode 插件库 python环境 (anaconda miniconda) C++环境 (mingw) 远程环境 ssh 远程文件传输 文档 typora picgo obsidian 安装细节VSCode没啥特别的安装步骤，直接从官网上下载安装程序就行，安装完之后用vsc自带的sync工具同步插件就好这里可能需要单独配置的内容有： VScode终端的字体（通过设置菜单直接设置） ctrl+滚轮缩放字体大小 Terminalwin11安装时附带Terminal（之前用的是从应用商店下载的预览版，感觉区别不大）这里需要配置的有： 字体配置 (NF) 安装7.0版本的powershell 如果有ssh需求的也可以配置 分栏快捷键设置（切换成类tmux的设置） &#123; &quot;command&quot;: &#123; &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;vertical&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; &#125;, &quot;keys&quot;: &quot;ctrl+[&quot; &#125;, &#123; &quot;command&quot;: &#123; &quot;action&quot;: &quot;splitPane&quot;, &quot;split&quot;: &quot;horizontal&quot;, &quot;splitMode&quot;: &quot;duplicate&quot; &#125;, &quot;keys&quot;: &quot;ctrl+]&quot; &#125;, &#123; &quot;command&quot;: &#123; &quot;action&quot;: &quot;closePane&quot;, &#125;, &quot;keys&quot;: &quot;ctrl+w&quot; &#125; 简单的美化 （改透明度） Powshell插件Terminal自带PSReadLine插件工具，需要简单配置一下 基础配置如下 oh-my-posh init pwsh --config &quot;$env:POSH_THEMES_PATH\\star.omp.json&quot; | Invoke-Expression Set-PSReadLineOption -PredictionSource HistoryAndPlugin Set-PSReadLineKeyHandler -Key UpArrow -Function HistorySearchBackward Set-PSReadLineKeyHandler -Key DownArrow -Function HistorySearchForward Set-PSReadLineKeyHandler -Key Tab -Function MenuComplete Set-PSReadLineKeyHandler -Chord &#39;&quot;&#39;,&quot;&#39;&quot; ` -BriefDescription SmartInsertQuote ` -LongDescription &quot;Insert paired quotes if not already on a quote&quot; ` -ScriptBlock &#123; param($key, $arg) $line = $null $cursor = $null [Microsoft.PowerShell.PSConsoleReadLine]::GetBufferState([ref]$line, [ref]$cursor) if ($line.Length -gt $cursor -and $line[$cursor] -eq $key.KeyChar) &#123; # Just move the cursor [Microsoft.PowerShell.PSConsoleReadLine]::SetCursorPosition($cursor + 1) &#125; else &#123; # Insert matching quotes, move cursor to be in between the quotes [Microsoft.PowerShell.PSConsoleReadLine]::Insert(&quot;$($key.KeyChar)&quot; * 2) [Microsoft.PowerShell.PSConsoleReadLine]::GetBufferState([ref]$line, [ref]$cursor) [Microsoft.PowerShell.PSConsoleReadLine]::SetCursorPosition($cursor - 1) &#125; &#125; # EditMode # Set-PSReadLineOption -EditMode Emacs Set-PSReadLineOption -ShowToolTips # enable git tab completion # Import-Module # enable gui completion # Set-PSReadlineKeyHandler -Key Tab -ScriptBlock &#123; Invoke-GuiCompletion &#125; function make-link ($target, $link) &#123; New-Item $link -ItemType SymbolicLink -Target $target &#125; scoop这是一款powershell包管理工具 $env:SCOOP=&#39;D:\\Software\\Scoop&#39; [Environment]::SetEnvironmentVariable(&#39;SCOOP&#39;, $env:SCOOP, &#39;User&#39;) $env:SCOOP_GLOBAL=&#39;D:\\Software\\Scoop\\GlobalScoopApps&#39; [Environment]::SetEnvironmentVariable(&#39;SCOOP_GLOBAL&#39;, $env:SCOOP_GLOBAL, &#39;Machine&#39;) iwr -useb get.scoop.sh | iex # cnpmjs 配置镜像 scoop config SCOOP_REPO https://github.com.cnpmjs.org/ScoopInstaller/Scoop/ 添加scoop源 scoop bucket add main &#39;https://github.com/ScoopInstaller/Main&#39; scoop bucket add extras &#39;https://github.com/ScoopInstaller/scoop-extras&#39; scoop bucket add versions &#39;https://github.com/ScoopInstaller/Versions&#39; scoop bucket add jetbrains &#39;https://github.com/Ash258/Scoop-JetBrains&#39; scoop bucket add java &#39;https://github.com/ScoopInstaller/Java&#39; scoop bucket add dorado https://github.com/chawyehsu/dorado scoop bucket add scoopet https://github.com/ivaquero/scoopet oh-my-posh新版本的omp的安装方式建议参考官网的方式配置 oh-my-posh init pwsh --config &quot;$env:POSH_THEMES_PATH\\jandedobbeleer.omp.json&quot; | Invoke-Expression 这样配置的启动时间快很多 C++环境配置这次不打算搞MSVC，打算用gcc作为编译器，而windows上gcc需要mingw64提供windows必要的环境，因此通常说mingw就是gcc+mingw环境 首先需要安装MSYS2 scoop install msys2 用msys2自带的包管理器pacman安装mingw64，之后输入msys2进入环境 pacman -S mingw-w64-x86_64-toolchain gcc执行文件加入到环境变量中 $env:MINGW64=&#39;D:\\Software\\Scoop\\apps\\msys2\\current\\mingw64\\bin&#39; [Environment]::SetEnvironmentVariable(&#39;MINGW64&#39;, $env:MINGW64,&#39;Machine&#39;) 参考 Windows Terminal美化（oh-my-posh3）","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"glob&shutil学习","slug":"技术/编程/glob-shutil学习","date":"2022-01-17T17:03:15.000Z","updated":"2023-07-03T15:04:37.029Z","comments":true,"path":"2022/01/18/ji-zhu/bian-cheng/glob-shutil-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2022/01/18/ji-zhu/bian-cheng/glob-shutil-xue-xi/","excerpt":"","text":"glob&shutil学习主要介绍python标准库中负责文件查找的高级库glob和负责文件复制删除移动的shutil，最后也简单介绍了linux的软链接 globglob是python里面文件管理的模块，属于内置包 学习这个模块是希望代替os.path https://docs.python.org/3/library/glob.html The [glob](https://docs.python.org/3/library/glob.html#module-glob) module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell 返回的文件或者文件夹都是相对路径 函数介绍主要有三个函数 __all__ = [&quot;glob&quot;, &quot;iglob&quot;, &quot;escape&quot;] glob查找符合条件的所有文件，返回list （） * 通配符 [ ] 类似正则的匹配 如：[0-9]匹配数字 ？ 匹配单字符 ** recursive&#x3D;True 多级匹配 def glob(pathname, *, recursive=False): &quot;&quot;&quot;Return a list of paths matching a pathname pattern. The pattern may contain simple shell-style wildcards a la fnmatch. However, unlike fnmatch, filenames starting with a dot are special cases that are not matched by &#39;*&#39; and &#39;?&#39; patterns. If recursive is true, the pattern &#39;**&#39; will match any files and zero or more directories and subdirectories. &quot;&quot;&quot; return list(iglob(pathname, recursive=recursive)) iglob 获取一个迭代器（glob调用了它并转化为list，而iglob实际是一个生成器，文件非常多的时候用这个） def iglob(pathname, *, recursive=False): &quot;&quot;&quot;Return an iterator which yields the paths matching a pathname pattern. The pattern may contain simple shell-style wildcards a la fnmatch. However, unlike fnmatch, filenames starting with a dot are special cases that are not matched by &#39;*&#39; and &#39;?&#39; patterns. If recursive is true, the pattern &#39;**&#39; will match any files and zero or more directories and subdirectories. &quot;&quot;&quot; it = _iglob(pathname, recursive, False) if recursive and _isrecursive(pathname): s = next(it) # skip empty string assert not s return it Problem1. 如何实现多级的glob？files = glob.glob(&quot;./**&quot;, recursive=True) 2. 是否可以获取文件夹files = glob.glob(&quot;./*&quot;) # 文件+文件夹 filter(os.path.isdir, files) shutilshutil是一个高级的文件操作库，也是属于python标准库的 __all__ = [&quot;copyfileobj&quot;, &quot;copyfile&quot;, &quot;copymode&quot;, &quot;copystat&quot;, &quot;copy&quot;, &quot;copy2&quot;, &quot;copytree&quot;, &quot;move&quot;, &quot;rmtree&quot;, &quot;Error&quot;, &quot;SpecialFileError&quot;, &quot;ExecError&quot;, &quot;make_archive&quot;, &quot;get_archive_formats&quot;, &quot;register_archive_format&quot;, &quot;unregister_archive_format&quot;, &quot;get_unpack_formats&quot;, &quot;register_unpack_format&quot;, &quot;unregister_unpack_format&quot;, &quot;unpack_archive&quot;, &quot;ignore_patterns&quot;, &quot;chown&quot;, &quot;which&quot;, &quot;get_terminal_size&quot;, &quot;SameFileError&quot;] glob如果说是文件的查找，那么shutil是文件的增删改（复制、删除、移动） 函数介绍 shutil.copyfile copyfile(src, dst, *, follow_symlinks=True) 文件内容复制（不包括元数据） src→dst，如果dst是链接且follow_symlinks为True，则创建符号链接而非拷贝（这个比较有用，比如我的数据在/data目录下，而我fork的代码调用的是文件夹内部的data，可以使用软链接的方式，软链接将在最后介绍） copymode copystat 文件属性的拷贝 copy &#x3D; copymode + copyfile (文件创建修改时间不会copy) copy2 保留全部元数据的复制 copytree 文件夹的树结构的拷贝 copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2, ignore_dangling_symlinks=False) symlinks True的时候拷贝软链接，False的时候拷贝链接内容（不支持软连接的平台此设置无用） ignore接受glob风格的文件目录，可配合ignore_patterns使用 ignore_patterns工厂函数，接受glob类似匹配的patterns字符串 copytree(source, destination, ignore=ignore_patterns(&#39;*.pyc&#39;, &#39;tmp*&#39;)) rmtree 删除文件夹 rmtree(``*path*``, ``*ignore_errors=False*``, ``*onerror=None*``) move 移动文件夹或目录 shutil.move(``*src*``, ``*dst*``, ``*copy_function=copy2*``) 软链接linux中有软链接和硬链接，硬链接类似于指针，linux中，文件内容和文件名类似于指针与内容的关系，硬链接创建了新的一个指向原内容的指针，删除原文件名后内容并不会删除，而且不允许给目录创建硬链接 类似于windows快捷键的机制，访问软链接就是访问源文件本身，删除软链接不会删除源文件，可以实现一个文件，多处引用 # 创建软链接 ln -s 【目标目录】 【软链接地址】 # 删除 rm -rf 【软链接地址】 # 找到当前文件夹下所有软链接（参考：https://blog.csdn.net/menghefang/article/details/88624161） ls -alR | grep ^l","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"},{"name":"Linux","slug":"Linux","permalink":"http://jlutangchuan.github.io/tags/Linux/"}]},{"title":"DyCo3D: Robust Instance Segmentation of 3D Point Clouds through Dynamic Convolution","slug":"技术/理论/论文/DyCo3D-Robust-Instance-Segmentation-of-3D-Point-Clouds-through-Dynamic-Convolution","date":"2021-11-24T15:50:46.000Z","updated":"2023-07-03T15:04:37.103Z","comments":true,"path":"2021/11/24/ji-zhu/li-lun/lun-wen/dyco3d-robust-instance-segmentation-of-3d-point-clouds-through-dynamic-convolution/","link":"","permalink":"http://jlutangchuan.github.io/2021/11/24/ji-zhu/li-lun/lun-wen/dyco3d-robust-instance-segmentation-of-3d-point-clouds-through-dynamic-convolution/","excerpt":"","text":"DyCo3D: Robust Instance Segmentation of 3D Point Clouds through Dynamic Convolution论文信息 作者 作者单位 年份 会议&#x2F;期刊名 引用量 研究方向 Tong He；沈春华 Adelaide 2021 CVPR 2 3D实例分割 0. TL;DR We propose instead a dynamic , proposal-free , data-driven approach (labeled DyCo3D) that generates the appropriate convolution kernels to apply inresponse to the nature of the instances (Abs ) 1. Motivation Previous top-performing approaches for point cloud instance segmentation involve a bottom-up strategy includes inefficient operations or complex pipelines , such as grouping over-segmented components , introducing additional steps for refining , or designing complicated lossfunctions. The inevitable variation in the instance scales can lead bottom-up methods to become particularly sensitive to hyper-parameter values 2. Previous work Drawbacks Previous top-performing approaches for point cloud instance segmentation involve a bottom-up strategy Including inefficient operations or complex pipelines, such as grouping over-segmented components , introducing additional steps for refining , or designing complicated loss functions . The inevitable variation in the instance scales can lead bottom-up methods to become particularly sensitive to hyper-parameter values (the performance is sensitive to values of the pre-defined hyper-parameters, which require manual tuning ) heavily reliant on the quality of the proposals , which limits their robustness and can lead to joint&#x2F;fragmented instances in practice. 3D-MPA: extracts proposals from the predicted instance centroids. Instances are then generated by aggregating proposal-wise embeddings. PointGroup: generates instances proposals by gradually merging neighbouring points that share the same category label. Both original and centroid-shifted points are explored with a manually specified search radius. A separate model (labelled ScoreNet) is used to estimate the objectness of the proposals. Dynamic Convolution 主要参考两篇论文：Dynamic filter networks. (NIPS 2016) 、Conditional convolutions for instance segmentation. (ECCV 2020) Conditional convolutions for instance segmentation 直接从2D迁移到3D效果不好有如下原因： it introduces a large amount of computation, resulting in optimization difficulties. （优化难度提升很大） the performance is constrained by the limited receptive field and representation capability due to the sparse convolution （感受野大小被稀疏卷积限制了） 3. MethodSummary Features propose a novel pipeline tailored to 3D point cloud instance segmentation using dynamic convolution, that we label DyCo3D propose to encode category-specific context by deploying a lightweight sub-network to explore homogenous points that have close votes for instance centroids and share the semantic labels. propose to introduce a small transformer to capture a long-range dependency and build high-level interactions among different regions. Robustness; 对于超参数不敏感 More efficiency Point of View To make the kernels discriminative , we explore a large context by gathering homogeneous points that share identical semantic categories and have close votes for the geometric centroids . （聚合属于同一个语义类别且具有相近实例中心的同源点） Due to the** limited receptive field introduced by the sparse convolution** , a small light-weight transformer is also devised to capture the long-range dependencies and high-level interactions among point samples. Overall Architecture DyCo3D is comprised of three primary components（整体结构）: a backbone network , which is** based on sparse convolution ** for feature extraction, and **contains a light-weighted ** transformer . A weight generator that responds to the individual characteristics of each instance to dynamically generate the appropriate filter parameters . To make the filters discriminative, a large category-specific context is introduced. An instance decoder . Instances are separated in parallel , using only three convolution layers, by convolving the generated class-aware filters with position embedded features. produce instance masks using only a small number of simple convolutional layers. The associated convolution filters are dynamically generated , conditioned on both spatial distribution of the data and the semantic predictions. （卷积核动态生成，受数据空间分布以及语义分割预测控制） BackboneU-Net + Transformer Transformer except for the position embedding layer, where the position-sensitive information is **encoded ** as the mean of the pairwise direction vector or relative position. 论文中没有具体写这个transformer加在哪里以及具体细节，推测是在U-Net bottleneck位置上的self-attention Output by the backbone 语义分割$\\mathbf{F}_{\\mathrm{seg}} \\in \\mathbb{R}^{N \\times C}$ (apply traditional cross entropy loss) 中心偏移量$\\mathbf{O}_{\\mathrm{off}} \\in \\mathbb{R}^{N \\times 3}$ $$\\mathcal{L}{\\mathrm{ctr}}&#x3D;\\frac{1}{N{v}} \\sum_{i&#x3D;0}^{N}\\left|p^{i}+o_{\\mathrm{off}}^{i}-c t r_{\\mathrm{gt}}^{i}\\right| \\cdot \\mathbb{1}\\left(p^{i}\\right)$$ instance masking $ \\mathbf{F}_{\\mathrm{mask}} \\in \\mathbb{R}^{N \\times D}$, where D is the dimension of the output channel Dynamic Weight Generator To **generate discriminative filters for distinguishing different instances ** we propose to group homogenous points that have close votes for the geometric centroids andshare the category predictions. instance-aware filters are dynamically generated by applying a small sub-network for large context aggregation 引入这个模块的动机还是稀疏卷积造成的感受野偏小 (impair the method’s ability to exploit large-scale context )，提取cluster级的feature Grouping points by using a similar strategy to PointGroup applying a breadth-first searching algorithm to group homogenous points that have identical semantic labels and close centroids predictions. **Integrates ** large context to generate filters for instances decoding Due to the removal of the reliance on the quality of the instance proposals, the performance of our method is robust to the pre-defined hyper-parameters extract instance feature by 3-layer network $G_w(\\cdot)$ First, voxelize instance points (14x14x14). The features of each grid is calculated as the average of the point feature $F_b$ within the grid, where $F_b$ is the output of the backbone aggregate context for cluster. It contains two sparse convolutional layers with a kernel size of 3, a global pooling layer, and an MLP layer. $\\mathcal{W}_C^z$ Instance Decoder directly append position embeddings in the feature space . (instance cluster中每一个点的位置相对于质心做归一化) Given a specific category, position representation is critical to separate different instances. (作者认为位置信息对于分隔两个实例来说很关键) $$f_{\\mathrm{pos}}^{i}&#x3D;p^{i}-\\mathcal{C}_{\\mathrm{ctr}}^{z}$$ 每个Cluster中每个point的input feature $f_z^i$由$f_{pos}^i$和$f_{mask}^i$拼接（注意$f_z$的维度是$N\\times(D+3)$） decode binary segmentations of instances Network: The whole decoder contains** three convolution** layers with a kernel size of 1 × 1 . Each layer uses **ReLU ** as the activation function without normalization . $m_{z} \\in \\mathbb{R}^{N}$ 这里的意思是我们将$\\mathcal{W}_{\\mathcal{C}}^{z}$作为卷积层的参数 $$177&#x3D;\\underbrace{(8+3) \\times 8+8}{\\text {conv } 1}+\\underbrace{8 \\times 8+8}{\\text {conv } 2}+\\underbrace{8 \\times 1+1}_{\\text {conv3 }}$$ $$m_{z}&#x3D;\\operatorname{Conv}\\left(\\mathcal{W}{\\mathcal{C}}^{z}, f{z}\\right)$$ mask prediction (Before that, dice loss is also utilized) $$\\mathcal{L}{\\text {mask }}&#x3D;\\frac{1}{Z} \\sum{z&#x3D;1}^{Z} \\frac{1}{N_{z}} \\sum_{j&#x3D;1}^{N} \\mathbb{1}{l{\\mathrm{seg}}^{j}&#x3D;l_{\\mathrm{c}}^{z}} \\cdot L_{\\mathrm{BCE}}\\left(m_{z}^{j}, \\hat{m}_{z}^{j}\\right)$$ Training &amp; Post-process Total loss $$\\mathcal{L}&#x3D;\\mathcal{L}{\\text {seg }}+\\mathcal{L}{\\text {ctr }}+\\mathcal{L}{\\text {mask }}+\\mathcal{L}{\\text {dice }}$$ NMS on the instance binary mask 4. ExperimentMetric mConv: mConv is defined as the mean instance-wise IoU mWConv: mWConv denotes the weighted version of mConv mPrec mRec Ablation Study Efficiency DyCo3D 0.28s PointGroup 0.39s Result 5. Remark PointGroup基础上提升了效率、精度、鲁棒性 Backbone有改动，引入小的Transformer模块 动态卷积CondInst instance embedding + mask + NMS方式解决over-seg问题 PointGroup+他们团队之前CondInst","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"}]},{"title":"OccuSeg: Occupancy-aware 3D Instance Segmentation","slug":"技术/理论/论文/OccuSeg-Occupancy-aware-3D-Instance-Segmentation","date":"2021-10-26T15:09:30.000Z","updated":"2023-07-03T15:04:37.111Z","comments":true,"path":"2021/10/26/ji-zhu/li-lun/lun-wen/occuseg-occupancy-aware-3d-instance-segmentation/","link":"","permalink":"http://jlutangchuan.github.io/2021/10/26/ji-zhu/li-lun/lun-wen/occuseg-occupancy-aware-3d-instance-segmentation/","excerpt":"","text":"《OccuSeg: Occupancy-aware 3D Instance Segmentation》Paper Reading论文信息 作者 作者单位 年份 会议&#x2F;期刊名 引用量 研究方向 方法 Lei Han; Lu Fang THU&amp;CUHK 2020 CVPR 63 点云实例分割 super-voexl 图分割 占用估计 嵌入表示学习 TL;DR作者提出一个估计占用尺寸的实例分割机制，占用尺寸(3D oocupancy size)指的是每个voxel去估计自己所在instance的voxel数量。 定义一个”3D occupancy size”定义为每个实例占用的体素数量。在此基础上，提出了一种占用感知的三维实例分割方案。聚类方案受益于预测占用大小和聚类占用大小之间的可靠比较，这有助于正确聚类硬样本并避免过度分割。 这篇工作同样也采用super-voxel的方式做pre-merge 在正式的做super-voxel clustering的时候作者利用上面提到的occupancy size以及spatial information 与 implicit feature这三个feature去计算权值进行聚类 这里的聚类是采用计算super voxel两两之间的score，卡阈值得到，聚类依据则融合了上面三个估计量以一个概率的形式得到score。 MethodFramework 这个网络输入一个点云场景，流向了两个地方，第一是做3D U-Net，后面预测偏移量(spatial term)、occupancy (实例占用大小)、feature term(隐式特征，判别损失指导训练)；第二是做super voxel生成，用得到的super voxel来构建图的节点，节点的特征用super voxel的所有点的特征聚合表示，拿到节点之间的特征之后计算边的链接概率，最后卡阈值来进行图分割得到最终的实例分割结果。 1. Multi-task learning这里就是用U-Net去学习三个事情：语义分割、embedding (包括偏移量估计还有隐式判别学习)、ouucpancy size估计。语义分割的loss就是CE Loss，而且语义分割的结果不会被用来指导实例分割。 a) Embedding Learning实际上是学习两个事情：实例中心偏移量估计、feature embedding $\\mathcal{L}{\\mathrm{e}}&#x3D;\\mathcal{L}{\\mathrm{sp}}+\\mathcal{L}{\\mathrm{se}}+\\mathcal{L}{\\text {cov }}$ 并且两种嵌入都使用协方差估计进一步正则化。 Spatial Term 实际上就是实例中心偏移量估计 $\\mathcal{L}{\\mathrm{sp}}&#x3D;\\frac{1}{C} \\sum{c&#x3D;1}^{C} \\frac{1}{N_{c}} \\sum_{i&#x3D;1}^{N_{c}}\\left|\\mathbf{d}{i}+\\mu{i}-\\frac{1}{N_{c}} \\sum_{i&#x3D;1}^{N_{c}} \\mu_{i}\\right|$ Feature Term 判别损失，学习如何判别点是否是来源于同一个实例（参考论文** ** Semantic instance segmentation with a discriminative loss function. ） $\\begin{aligned} \\mathcal{L}{\\mathrm{var}} &amp;&#x3D;\\frac{1}{C} \\sum{c&#x3D;1}^{C} \\frac{1}{N_{c}} \\sum_{i&#x3D;1}^{N_{C}}\\left[\\left|\\mathbf{u}{c}-\\mathbf{s}{i}\\right|-\\delta_{v}\\right]{+}^{2} \\ \\mathcal{L}{\\mathrm{dist}} &amp;&#x3D;\\frac{1}{C(C-1)} \\sum_{c_{A}&#x3D;1}^{C} \\sum_{c_{B}&#x3D;c_{A}+1}^{C}\\left[2 \\delta_{d}-\\left|\\mathbf{u}{c{A}}-\\mathbf{u}{c{B}}\\right|\\right]{+}^{2}, \\ \\mathcal{L}{\\mathrm{reg}} &amp;&#x3D;\\frac{1}{C} \\sum_{c&#x3D;1}^{C}\\left|\\mathbf{u}_{c}\\right| \\end{aligned}$ Covariance Term The covariance term aims to learn an optimal clustering region for each instance. 这里实际上是约束一个实例中两个embedding各自的协方差最小，不同实例的spatial 和 feature embedding差异性越大。 首先我们计算每个实例中spatial和feature embedding的协方差c-th instance covariance $(\\sigma_s^c, \\sigma_d^c)$，然后得到c-th instance的点的数据在spatial&amp;feature 的观测下属于该实例的概率 $p_{i}&#x3D;\\exp \\left(-\\left(\\frac{\\left|\\mathbf{s}{i}-\\mathbf{u}{c}\\right|}{\\sigma_{s}^{c}}\\right)^{2}-\\left(\\frac{\\left|\\mu_{i}+\\mathbf{d}{i}-\\mathbf{e}{c}\\right|}{\\sigma_{d}^{c}}\\right)^{2}\\right)$ 这里应该有个假设，估计量服从高斯分布。 最后，同样用CE Loss去学习这个概率 $\\mathcal{L}{\\text {cov }}&#x3D;-\\frac{1}{C} \\sum{c&#x3D;1}^{C} \\frac{1}{N} \\sum_{i&#x3D;1}^{N}\\left[y_{i} \\log \\left(p_{i}\\right)+\\left(1-y_{i}\\right) \\log \\left(1-p_{i}\\right)\\right]$ b) Occupancy Regression这部分也比较简单，预测i-th voxel所在的 c-th instance占有的voxel的数量，为了提高鲁棒性，实际预测数量的对数 $\\mathcal{L}{\\mathrm{o}}&#x3D;\\frac{1}{C} \\sum{c&#x3D;1}^{C} \\frac{1}{N_{c}} \\sum_{i&#x3D;1}^{N_{c}}\\left|o_{i}-\\log \\left(N_{c}\\right)\\right|$ 同时作者还引入一个测量指标来说明预测的准确性以及可行性 2. Instance Clustering前面是训练一个网络估计点的特征的工作，后面利用前面网络估计的embedding以及直接从点云场景提取super voxel的结果进行实例的聚类，因为这里实际是从super voxel聚合得到instance，所以这步叫做实例聚类而不是实例分割。 前面我们有了点的语义、空间表示、嵌入表示、占用尺寸的信息，首先我们需要构建出super voxel的信息。直接用averaging operation就可以。 对于占用尺寸，我们可以进一步计算super-voxel的占用率(occupancy rate)，拿平均后得到的占用尺寸和super voxel中voxel的数量做除法得到占用率。如果占用率大于1，说明该super voxel中可能含有多于它对应instance的点。 $r_{i}&#x3D;\\frac{\\left|\\Omega_{i}\\right|}{O_{i}}$ 有了super voxel和它的表示之后可以建立一个图$G&#x3D;(V,E,W) $，节点就是生成的超点，边的权值定义如下 $w_{i, j}&#x3D;\\frac{\\exp \\left(-\\left(\\frac{\\left|\\mathbf{S}{\\mathbf{i}}-\\mathbf{S}{\\mathbf{j}}\\right|}{\\sigma_{s}}\\right)^{2}-\\left(\\frac{\\left|\\mathbf{D}{\\mathbf{i}}-\\mathbf{D}{\\mathbf{j}}\\right|}{\\sigma_{d}}\\right)^{2}\\right)}{\\max (r, 0.5)}$ 形式上与上面训练时的概率p很像，但是感觉用t检验(双总体t检验 )更数学一点。 $\\sigma_d $与$\\sigma_s $表示两个super voxel的所有点的协方差。 分母部分$max(r,0.5)$会惩罚那些可能会引起over segmentation的super voxel，拉低他们的权重，另外还要过滤掉那些$r$过大或者过小的super voxel，限制为$0.3&lt;r&lt;2$。 ExperimentNote 利用FlashFusion制作实时实例分割系统，作为演示demo 测试了三个数据集： ScanNetV2 S3DIS SceneNN 注意这篇工作的时间分析，提取supervoxel最耗时，大约是网络推断用时的7倍 消融实验中不加偏移量估计掉1.4个点，不加occupancy掉3.3，不加feature掉7.5，可见嵌入表示的学习还是很有必要的 Thought感觉是一个不错的工作，利用概率的方式建模提高了方法设计的合理性。但是super voxel的使用会增大计算开销，不知道这一步能否用其他方式来替代。 这篇工作提出解决over segment的方式是估计occupancy size，保留那些super voxel的occ size大于super voxel的体素数量的super voxel去做clustering 而occupancy size的作用主要是用来干掉那些可能造成over segmentation的super voxel。 读论文的时候spatial feature看了半天没看明白是要干什么，到第四页看到公式的时候才知道这是偏移量估计，感觉的作者写的时候思考和后面工作不大一样，而且这个工作早于PointGroup，提出偏移量估计的原创性也挺高的。这个工作目前还是ScanNet上第二好的结果，说明方法还是挺靠谱的，另外第一是SSTNet，也是基于super voxel的方法，这方法有利有弊，确实挺有效的，但是引入了很大的计算开销。","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"}]},{"title":"PRML-绪论","slug":"技术/理论/机器学习/PRML-绪论","date":"2021-10-24T17:30:02.000Z","updated":"2023-07-03T15:04:37.086Z","comments":true,"path":"2021/10/25/ji-zhu/li-lun/ji-qi-xue-xi/prml-xu-lun/","link":"","permalink":"http://jlutangchuan.github.io/2021/10/25/ji-zhu/li-lun/ji-qi-xue-xi/prml-xu-lun/","excerpt":"","text":"PRML-绪论update 2020&#x2F;08&#x2F;14 推荐几个不错的资料 PRML英文09年版电子书 链接: https://pan.baidu.com/s/1fmae0ZDd5DNVP5wnBVOHOQ 提取码: 5md8 PRML学习笔记（感觉写得挺好的）链接: https://pan.baidu.com/s/1bLZdnSebCam-bHbz5ujGJg 提取码: n8fs 哔哩哔哩上的视频课 PRML 绪论 概率论 模型选择 维度灾难 决策论 信息论 定义什么是泛化？ 正确分类与训练集不同的数据的能力叫泛化。 什么叫特征提取？ 输入向量变换到新的变量空间，使得在新的变量空间中模式识别问题期望能被更容易地解决。 什么是有监督学习（supervised learning）？ 训练数据的样本包含输入向量和目标向量的应用 什么是无监督学习? 训练数据由一组输入向量组成，没有任何对应的目标值 常见的无监督学习问题：聚类、密度估计、数据可视化 什么是强化学习？ 在给定条件下，找到合适的动作，使得奖励达到最大值 探索（exploration）：系统尝试新类型的动作 开发（explotation）：系统使用一直能产生较高奖励的动作 什么是分类问题？ 为每个输入向量分配有限数量离散标签中的一个的问题 什么是回归问题？ 输出由一个或多个变量组成 本书的三个重要工具：概率论、决策论、信息论 多项式曲线拟合 最小化误差函数使得模型曲线（多项式函数）拟合数据点，当误差函数是平方和误差时存在解析解 在贝叶斯模型中，参数的有效数量会自动根据数据集的规模调节，也就是过拟合问题可以被避免 但在目前，控制过拟合的方法是在误差函数中加入惩罚项，使得系数不会达到很大的值 二次正则项的一个特殊情况被叫做脊回归（ridge regression），神经网络中叫做权值衰减（weight decay） 本节讲述的内容较为直觉，后面会将这些问题形式化 概率论这块需要进一步学习的知识有：贝叶斯定理、贝叶斯推断、贝叶斯概率 主要概念： 区分概率和似然 在统计学上，基于某些模型的参数（粗略地说，我们可以认为参数决定了模型），观测到某数据的概率称为概率；而已经观测到某数据，模型的参数取特定值的概率称为似然。 两个视角看贝叶斯定理 $$P(Y|X) &#x3D; \\frac{P(X|Y)P(Y)}{P(X)}$$ X和Y只表示两个随机变量 X，Y地位相同，这个公式实际问题中想解决“逆向概率”的问题，$P(Y|X)$这个概率可能不好观测（比如说考察癌症检测试剂的精确率，X表示试剂检测阳性，$Y_0$和$Y_1$分别表示是癌症或不是癌症；$P(X|Y_0)$和$P(X|Y_1)$非常好统计，拿一些癌症病人和正常人测下试剂就行，但是$P(Y|X)$不好统计，因为这要求我们需要从全人群中抽样并且需要知道每个人是否是癌症），利用贝叶斯定理就可以将问题转化为获取其他好拿到的概率。 贝叶斯推断视角 我们对于某个事件的估计可以用一个带参数的概率模型表示，存在一组观测数据，通过这组观测数据我们来更新我们的参数。使得我们使用概率模型在预测时能够兼顾先验概率与观测数据（证据）。 极大似然估计与最大后验概率估计 两者可用来进行概率模型参数估计，两者分别来自频率学派和贝叶斯学派，这两个派别主要是对概率的定义或理解不一致。 MLE是频率学派（客观概率）的观点，概率学派认为概率模型参数ω是一个固定且未知的值，样本是随机的（样本是根据要估计的概率分布随机产生的，有点概率模型决定样本的意思），极大似然估计就是将参数ω估计为$argmax_{\\omega} P(D|\\omega)$，和频率学派的观点一致，样本是服从含参数ω的概率模型下随机产生的，因此参数ω最可能的取值下的概率模型产生该观测数据的概率也应该最高。估计的误差可以用自助法等方法计算。 MAP是贝叶斯学派（主观概率）的观点，贝叶斯学派认为概率模型是具有不确定性的且应服从某个分布，因此可以简化为概率模型参数ω是一个随机变量，样本是固定的（样本只是提供信息帮助我们更新概率模型，而不是决定最终的概率，概率模型只是观测者对于可能性的主观估计）；由于贝叶斯学派认为概率模型的参数服从的分布是与观察无关且已知的，因此MAP按照贝叶斯推断的过程进行计算，参数ω的估计应该同时考虑先验知识与观测数据。 Bayesian和Frequentist的缺点 Bayesian 常受的批评之一：prior distribution is often selected on the basis of mathematicalconvenience rather than as a reflection of any prior beliefs。 例如常选择 conjugate prior。 Frequentist 方法的缺点：Over-fitting problem can be understood as a general property ofmaximum likelihood。 决策论希望能在不确定性的情况下做出最优决策 最小化分类错误率 对于给定的输入向量$x$，选择后验概率最大的类别（$argmax_i P(C_i|x)$）的决策会使错误分类率最小化 推导：先给出分类错误率的公式，每个输入向量的错误概率可以写成输入向量和某个类别的联合概率，再用乘法规则将联合概率展开，提出无关的输入向量概率；在剩下的后验概率中，用最大化后验概率放缩，得到的就是最小分类错误率 最小化期望损失 第一类错误（FN）、第二类错误（FP） 在决策时I型错误和II型错误的权重不一致，可以用损失函数重新描述目标，决策就是最小化损失函数，在给定数据下就是最小化期望损失 回归问题平方损失下的决策解释平方损失最优决策$\\hat y(x)$可以看作在$x$的条件下t的条件均值（$\\hat{y}(x) &#x3D; E_t[t|x]&#x3D;\\int t \\ p(t|x) dt$），书中给了两种推导方式（1. 平均损失最小，关于$y(x)$的梯度为0，这里用到了以前没学过的变分法； 2. 平方项中加减条件均值，带入平均损失函数中） 拒绝选项 若最大后验概率的选择的后验概率没有过给定的阈值，说明模型对给定的结果置信度不高，可以拒绝选项 决策流程推断：学习后验概率，或者联合概率 决策：利用设计好的决策目标以及后验概率进行决策 生成式模型：直接对联合概率建模（朴素贝叶斯~本来目标是最小化后验概率，但是考虑到$P(x)$无关，实际argmax的是联合概率） 判别式模型：直接对后验概率建模 ​ 这里有个问题：为什么朴素贝叶斯是属于生成模型而不是判别模型？（见《统计学习方法》附录） 离群点检测：找到$P(x)$低的数据点，这些点预测准确率可能会比较低 回归问题的决策闵可夫斯基损失函数： 损失函数为闵氏距离 q&#x3D;2就是平方损失，平均损失最小的决策就是条件均值 q&#x3D;1，平均损失最小的决策是条件中位数 $q \\to 0$，对应的决策是条件众数 信息论信息量与信息熵信息量 对于一个随机变量x，当给出一个观察值时，我们接收到的信息量可以被看做是在学习x的值的时候的“惊讶程度” “信息是用来消除随机不确定性的东西” 设计为概率的-log的原因(貌似也有证明它只能是对数形式)： 信息量和概率值应该成负相关，当数据的越符合随机变量的概率分布，其信息量越小 当两个不相关随机变量的信息量，其概率是乘关系，其信息量应该是加关系，因此考虑log 信息量的单位bit，底数通常是2 信息熵 信息熵是随机变量的期望信息量，单位nat，底数是自然对数 $$H(x)&#x3D;-\\sum_xp(x)log_2(p(x))$$ 信息熵也可以从最优编码的角度来解释，随机变量的概率表示这个信息出现的概率，而这时信息量代表着对应概率下随机变量的最优编码长度，熵代表了理论上对符合$p$分布的消息进行编码的最优编码的平均长度。（可证明） 熵家族下面四个一起来讲，这四个主要是讨论两个随机变量之间关系的 互信息$I(X,Y)&#x3D;H(X)+H(Y)-H(X,Y)$ 解释：互信息代表了$X$中包含的有关于$Y$的信息，或者$Y$中包含的有关于$X$的信息 联合熵 $H(X,Y)&#x3D;\\sum_{x\\in X,y\\in Y} P(x,y) \\mathbf{log}{\\frac{1}{P(x,y)}}$ 多个随机变量的总期望信息量，联合熵比其中任一个随机变量的信息熵要大，但是联合熵不大于两个随机变量的信息熵之和 条件熵$H(X|Y)&#x3D;\\sum_{x,y}p(x,y)\\mathbf{log} \\frac{1}{p(x|y)}$ 条件熵要小于熵x（更多的信息，不确定性降低） 差异信息 Variation of Information $V(X,Y)$ $$V(X,Y)&#x3D;H(X,Y)-I(X,Y)$$ 这两个是度量两个分布的 相对熵$KL(p||q)$ 相对熵也叫K-L散度，用来衡量两个分布的不相似程度，具体说是分布q相对与分布p的期望信息量之差 $$KL(p||q)&#x3D;-\\int log(\\frac{q(x)}{p(x)})p(x)dx$$ 交叉熵 若现在还有一种消息序列的概率分布满足p分布，但是它仍然使用q分布的最优编码方式，那么它的平均编码长度即为 $$CE(p||q)&#x3D;\\sum p(x) log\\frac{1}{q(x)}$$ 熵在机器学习理论中的应用 分类问题中的交叉熵损失 这个交叉熵损失可以从二项分布或者多项分布下的极大似然估计进行解释 还有一种考虑方式，模型训练的过程也就是拟合训练数据的过程对于训练数据$(x;y)\\in D$来说我们的模型$F(x)$实际上就是要对y的分布进行预测，现在我们有真实分布q（也就是数据中的y）$y^\\star$，模型推断得到的分布p，真实分布对应的最优编码长度就是$H(q)$，交叉熵 $D(p||q)&#x3D;\\sum_x p(x)log \\frac{1}{q(x)}$ 尽可能小去逼近$H(q)$也就是将两个分布拉近。 总结磨磨唧唧花了一个星期看个绪论，感觉还是挺有收获的，又加深了概率论相关知识的理解，还从概念上的决策、信息角度重新审视之前的一些概念，比如损失函数这个概念是怎么和概率中的东西联系在一起，平方误差在决策论中的解释等以前没注意到的东西。 Reference http://colah.github.io/posts/2015-09-Visual-Information/ https://zhuanlan.zhihu.com/p/25849615 https://www.cnblogs.com/LittleHann/p/11258395.html","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://jlutangchuan.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://jlutangchuan.github.io/tags/MachineLearning/"},{"name":"PRML","slug":"PRML","permalink":"http://jlutangchuan.github.io/tags/PRML/"}]},{"title":"Instance Segmentation in 3D Scenes using Semantic Superpoint Tree Networks","slug":"技术/理论/论文/Instance-Segmentation-in-3D-Scenes-using-Semantic-Superpoint-Tree-Networks","date":"2021-10-24T02:31:41.000Z","updated":"2023-07-03T15:04:37.110Z","comments":true,"path":"2021/10/24/ji-zhu/li-lun/lun-wen/instance-segmentation-in-3d-scenes-using-semantic-superpoint-tree-networks/","link":"","permalink":"http://jlutangchuan.github.io/2021/10/24/ji-zhu/li-lun/lun-wen/instance-segmentation-in-3d-scenes-using-semantic-superpoint-tree-networks/","excerpt":"","text":"《Instance Segmentation in 3D Scenes using Semantic Superpoint Tree Networks》Paper Reading论文信息 作者 作者单位 年份 会议&#x2F;期刊名 引用量 研究方向 Kui Jia 华南理工 华为 2021 ICCV 0 3D点云实例分割 Paper ReadingBackground作者提到之前主流方法的问题： PointGroup第二步(聚类)过程缺少监督 Segmentation碎片化 (owing to point feature data irregularities) Their point-wise feature learning and grouping are less effective to deal with data irregularities, possibly resulting in fragmented segmentations Instance segmentation challenging observed scene points are usually sparse and irregular the unknown number of object instances in a scene introduces additional uncertainties to the problem of learning point-instance associations that is already combinatorial learning consistencies among spatially adjacent points are not guaranteed, which may cause fragmented segmentations Method同样可以分成三个主要部分： 利用几何同源特性从点云中聚集超点 learning a network that groups superpoints on same object instances refine proposal and predict score Backbone and Semantic Scoring网络骨架依然是U-Net 语义分割loss是CE loss加上了dice loss 这个dice loss的目的是应对类别不平衡问题alleviates the imbalance among the K categories 中心点回归loss是l2 loss加上余弦loss Construction of Semantic Superpoint Tree这个是本文的核心创新点 整体的流程大致是： 利用点云原始信息构建超点 利用超点对前面骨架网络推断得到的特征进行group pooling 3部分特征concat（中心点 语义分割结果 中间特征） 构建超点树 贪心策略 合并依据：语义预测向量和中心点预测向量拼起来的新向量算欧氏距离 合并规则：根据点的数量加权求和得到两个part的父节点的embedding centeroid semantic vector Proposal Generation via Tree Traversal and Splitting前面整个场景构成了一个大的超点树，每个part都是一个叶子节点，我们需要找到表示实例的节点集合，因此这里我们将从超点树中分裂出instance 具体分裂依据是计算两个节点的表示之间的相似度是否小于0.5 $\\phi\\left(\\boldsymbol{f}{s{1}}^{\\dagger}, \\boldsymbol{f}{s{2}}^{\\dagger}\\right)&lt;0.5$ 而这里相似度的衡量是网络学习得到的（论文中还提到了一些训练这个相似度比较网络的细节，比如：采用soft label） CliqueNet for Refinement of Proposals前面得到了候选instance，但是前面生成的结果的准确性不高，具体表现为： proposed branch的semantic class有问题 proposed branch中存在小部分点是背景点或者属于其他instance 因此需要对这个proposed branch进行修剪，具体的方法看了但是真没看明白。 这部分在结果中的实际收益1个点不到，感觉很难说明该模块的有效性 Proposal Evaluation这里就是对生成的候选实例进行得分估计，他们采用的同样是PointGroup中的ScoreNet，也没啥好说的。 Experiment实验部分没啥特别想关注的内容 Setting Optimizer：AdamW 两个数据集生成超点的方法不一样 问题分析 超点作为不可分的个体，每个instance由若干个超点构成，但是每个超点只属于一个instance。当某些场景中几何特征很难分辨两个instance的时候，这种超点构成的步骤会成为模型上限。（比如：两个桌子紧靠，两个桌子的桌子面属于一个超点） 三篇工作的总结 问题： xyz+offset： 这里的offset是voxel之后得到的结果，对应的质心这里做得不太准确 上述三个流程都不是很直接，cluster+merge+filter+score比较复杂 质心坐标、语义类别、中间表示三部分很难同时使用（存在先后顺序的约束） &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;- 用一个网络来聚合这几部分信息，得到一个统一的embedding Clustering是否有更快速且性能卓越的方法？（网络学习的方式？） 先前的基于点的聚类方法的问题：没有考虑整体，只考虑点之间的邻近特性","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"},{"name":"InstanceSegmentation","slug":"InstanceSegmentation","permalink":"http://jlutangchuan.github.io/tags/InstanceSegmentation/"},{"name":"PointCloud","slug":"PointCloud","permalink":"http://jlutangchuan.github.io/tags/PointCloud/"}]},{"title":"Hierarchical Aggregation for 3D Instance Segmentation","slug":"技术/理论/论文/Hierarchical-Aggregation-for-3D-Instance-Segmentation","date":"2021-10-11T10:48:53.000Z","updated":"2023-07-03T15:04:37.108Z","comments":true,"path":"2021/10/11/ji-zhu/li-lun/lun-wen/hierarchical-aggregation-for-3d-instance-segmentation/","link":"","permalink":"http://jlutangchuan.github.io/2021/10/11/ji-zhu/li-lun/lun-wen/hierarchical-aggregation-for-3d-instance-segmentation/","excerpt":"","text":"Hierarchical Aggregation for 3D Instance Segmentation论文信息 HAIS 作者 作者单位 年份 会议&#x2F;期刊名 引用量 研究方向 方法 代码 备注 Shaoyu Chen, Wenyu Liu 华科&amp;地平线 2021 ICCV 1 3D点云实例分割 center predict based method code ScanNet SOTA Paper 支撑材料 3D点云实例分割SOTA榜在Paperwithcode上找了3D点云分割的SOTA，首先实例分割的数据集大家普遍用的是两个场景的数据集 ScanNet 和 S3DIS，后续自己也计划在这两个数据集上开展自己的实验 Benchmark 目前来看效果比较好的工作： Instance Segmentation in 3D Scenes using Semantic Superpoint Tree Networks (SSTNet) ICCV 2021 Hierarchical Aggregation for 3D Instance Segmentation (HAIS) ICCV 2021 Learning Gaussian Instance Segmentation in Point Clouds (GICN) 2020年工作，点数和Pointgroup差不多 Point Group 2020年工作 ScanNet &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;另外Scan Net还有一个单独的榜单 &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;http://kaldir.vc.in.tum.de/scannet_benchmark&#x2F;semantic_instance_3d S3DIS TL;DR在PointGroup的基础上提出了改进版，采用了hierarchical aggregation (首先通过fixed bandwidth 聚类算法产生一系列候选instance set，然后再对候选实例点集进行合并) 速度上相比PointGroup有了一些提升，无需NMS实现SOTA性能，相比PointGroup提升4个点 Background 2D实例分割 Top-Down Method two-stage (bbox→mask) Bottom-Up Method Clustering based Directly clustering difficult reasons: A point cloud usually contains a large number of points (待聚类的样本多) The number of instances in a point cloud has large variations for different 3D scenes (每个聚类簇含有的样本数量差别大) The sizes of instances vary significantly (聚类簇内部分布不整齐) Each point has a very weak feature, i.e., 3D coordinate and color （聚类特征数少） Deep Learning on Point Clouds Proposal-based Instance Segmentation 2D: Mask RCNN GSPN 3D-SIS 3D-BoNet 3D-MPA GICN Clustering-based Instance Segmentation SGPN JSIS3D MTML OccuSeg PointGroup Method整个Pipeline称得上是PointGroup的魔改版 Backbone: 3D sparse CNN Hierarchical aggregation → Point aggretation + Set aggretation We first aggregate points to sets with low bandwidth to avoid over-segmentation and then set aggregation with dynamic bandwidth is adopted to form complete instances. Set aggregation may absorb noisy point sets into predictions, making the aggregated instances over-complete. Sub-network→ outlier filtering and mask quality scoring Outline point-wise prediction network → extracts features from point clouds and predicts point-wise semantic labels and center shift vec-tors. point aggregation module → preliminary instance predictions set aggregation module → expands incomplete instances to cover missing parts intrainstance prediction network → smooths instances to filter out outlier 1. Point-wise Prediction NetworkSimilar with PointGroup（Backbone：3D-Unet） Semantic label prediction (CE Loss， 2 layer) Center Shift Vector Prediction (Smooth L1 loss) $\\delta x$ Point Group L1 loss+cosine loss: 在局部最优处不可导，容易产生震荡，余弦loss同样也会有问题 Why not L2 loss: 离群点梯度大，梯度爆炸？，但优势是接近局部最优时梯度小，容易收敛 2. Point Aggregation ignore background label (floor, wall) Algorithm: similar with PointGroup shrink radius size (avoid over segmentation → stone fragement) 3. Set Aggregration这个是本文提出的一个新的步骤，目的是合并主体instance和其待合并的碎片 碎片instance和主体instance合并规则： 两者属于同一类 两者的几何中心应该小于一个值（这个值是统计得到的） 4. Intra-instance Prediction Network在Score的基础上做了改进 新网络首先预测一个mask去 distinguish the instance foreground and background 然后预测mask与best matched gt的iou（CE Loss） 存在的问题 输入是一个instance（ShapeNet数据集上不友好） 5. Multi-task Training 其他特点： NMS Free ExperienceResult Ablation Study Comparsion on inference time Qualitative results on ScanNet v2","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"},{"name":"InstanceSegmentation","slug":"InstanceSegmentation","permalink":"http://jlutangchuan.github.io/tags/InstanceSegmentation/"},{"name":"PointCloud","slug":"PointCloud","permalink":"http://jlutangchuan.github.io/tags/PointCloud/"}]},{"title":"PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation","slug":"技术/理论/论文/PointGroup-Dual-Set-Point-Grouping-for-3D-Instance-Segmentation","date":"2021-09-06T15:36:41.000Z","updated":"2023-07-03T15:04:37.114Z","comments":true,"path":"2021/09/06/ji-zhu/li-lun/lun-wen/pointgroup-dual-set-point-grouping-for-3d-instance-segmentation/","link":"","permalink":"http://jlutangchuan.github.io/2021/09/06/ji-zhu/li-lun/lun-wen/pointgroup-dual-set-point-grouping-for-3d-instance-segmentation/","excerpt":"","text":"PointGroup: Dual-Set Point Grouping for 3D Instance SegmentationTL;DR提出了一个新的基于实例质心偏移量预测实例分割模型，模型首先通过一个两分支的预测网络（Backbone：3D U-Net），分别预测点云中每个点的语义分割类别和其相对于实例质心的偏移量，然后又分别用原始点云和预测出的质心点云分别进行聚类（类似于BFS、洪泛算法），接着还根据所聚的类对每个类分别送入他们设计的得分网络计算一个score，最后接一个点云上的NMS，进行实例分割。 该模型支持端到端的训练，主要可以分成三个部分：1）一个体素的3D U-Net，末端分别预测语义类别（CE loss）、质心偏移量（L1 loss + cosine loss） 2）Clustering Part 进行聚类 3）ScoreNet 预测是否能match到gt实例（soft label CE loss）。 相关工作记录一些作者对于前述工作的看法与比较 点云特征提取方法 MultiLayer Perception (MLP)-style network：PointNet PointNet++ 3D Convoution：PointCNN Voxelize point cloud 2D实例分割方法分类 Top-down Bottom-up 3D实例分割方法分类 基于检测的方法：GSPN 基于分割的方法：SGPN（embedding based method） 本文基于质心的方法 （这里作者没有提到一些对于本网络的创新有关系的 质心、偏移量类似的工作：VoteNet等） 方法整体流程 We design a two-branch network to extract point features and predict semantic labels and offsets, for shifting each point towards its respective instance centroid. A clustering component is followed to utilize both the original and offset-shifted point coordinate sets, taking advantage of their complementary strength. 各模块分析Backbone Network将点云体素化，然后用3D-UNet进行特征提取，后面再还原回点云，后面接两个分支，分别预测语义类别和质心偏移量 这里UNet采用了两种卷积：Submainfold Sparse Convolution &amp; Sparse Convolution 关于质心偏移量，作者给了一个统计，实例的点到质心的距离，大部分距离0.5m以内，实验上作者发现实例边缘上的点很难回归到质心，预测得不是那么准。因此，后面的对点的聚类作者用原始点云坐标和预测的质心坐标分别聚了一遍，相当于构造了两倍的候选实例类。 Clustering Algorithm注意的是这里要将墙这种质心很难去预测的类删掉，这个算法本质上是一个枚举+BFS ScoreNet 得到候选实例点集合之后，需要经过NMS过滤重复的候选集合，但是要送入NMS还缺少一个候选集合置信度，于是最后网络还有一个得分预测，输入是体素化的候选点集，送入一个小的U-Net网络，最后经过Max Pooling → FC Layer →Sigmoid得到预测得分，这里的gt还用soft label 结果数据集 ScanNet v2 S3DIS 评价指标 mAP：这里整理一下mAP的计算 mean Average Precision，常用于目标检测结果的评估，这里也以目标检测来介绍mAP 目标检测中会预测出很多检测框，有些预测框和gt之间有很高的重合度、有的预测框附近没有gt框、有的gt和多个预测框都有较高的重合度 目标检测会有多个类别的检测AP，首先我们需要计算每个类的AP，对于所有类的预测AP求平均得到mAP 接下来介绍AP的计算： 我们首先需要计算每个预测框和gt的最大IOU，也就是找预测框最相近的gt框的IOU，我们这里有个阈值th，只有IOU大于th的最大预测框才被视为TP，其余的都是FP 然后根据每个框的置信度从小到大排序（这个置信度不是max IOU，而是我们的模型的阈值，超过这个阈值的预测框才被输出出来） 排序后的结果，同时做一个统计，计算累计的Acc TP FP，得到了在该阈值下的Precision和Recall 然后作P-R图 AP有两种算法，一种是找recall在[0.0:0.1:1.0]这11个位置处的Precision然后算平均 另一种是先找到曲线上所有recall位置（unique），然后再找每个recall上最大的Precision（max），再求平均 计算完每个类的AP之后算一下平均得到mAP mAP50表示IOU阈值在0.5时的mAP mAP（不标注thr）的表示对不同阈值(0.50-0.95)下的mAP再取平均 指标 对比实验 对比聚两个类还是聚一个类 聚类ball query的半径 运行时间分析 可以看出最前面U-Net最耗时（50%时间） 分析这个思想在点云实例分割挺新颖的，通过计算质心来聚类，相比于计算embedding看起来更优雅，但是感觉存在以下问题： 前面Backbone网络用U-Net进行体素特征提取然后再还原回点云感觉会很耗时间 最终的模型可能处于性能的考量，设计了用原始点云和质心点云分别聚两次类，这部分不是很有说服力 后面的聚类算法和ScoreNet看起来也是感觉不是很有道理 类似的质心聚类思想也在其他地方出现过，但是用在实例分割上真的感觉很合适 对自己而言，这篇论文很友善地给了Pytorch的代码（其他点云实例分割大都是tf实现） 我要想用这个网络做自己的实例分割，需要考虑一下问题 计算开销：这里采用了体素化的形式 超参数的设置 在哪里提取part实例的embedding? 类似的工作 3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation（CVPR2020） VoteNet 3D semantic segmentation with submanifold sparse convolutional networks Gs3d: An efficient 3d object detection framework for autonomous driving U-net: Convolutional networks for biomedical image segmentation","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"},{"name":"InstanceSegmentation","slug":"InstanceSegmentation","permalink":"http://jlutangchuan.github.io/tags/InstanceSegmentation/"},{"name":"PointCloud","slug":"PointCloud","permalink":"http://jlutangchuan.github.io/tags/PointCloud/"}]},{"title":"当焦虑型依赖遇见回避型依赖-心理笔记","slug":"生活/当焦虑型依赖遇见回避型依赖-心理学笔记","date":"2021-07-08T16:00:00.000Z","updated":"2023-07-03T15:04:36.969Z","comments":true,"path":"2021/07/09/sheng-huo/dang-jiao-lu-xing-yi-lai-yu-jian-hui-bi-xing-yi-lai-xin-li-xue-bi-ji/","link":"","permalink":"http://jlutangchuan.github.io/2021/07/09/sheng-huo/dang-jiao-lu-xing-yi-lai-yu-jian-hui-bi-xing-yi-lai-xin-li-xue-bi-ji/","excerpt":"","text":"当焦虑型依赖遇见回避型依赖-心理笔记常说的两人因为性格不合导致分手，可能大都如此，一个人拼命的说爱，甚至近乎道德绑架，另一个人不得不从中抽身，尽管两人彼此还留有感情，但是现实的痛苦会促使回避型依赖的人说分手。 一、两种性格定义及特征首先谈一下心理学对这两种性格的解释，第一次见到这个词是在《亲密关系》的成人依恋风格理论中，根据对自我认知以及对他人评价敏感程度分为四种性格：安全型、焦虑型、回避型以及恐惧型 焦虑型（害怕被抛弃，不回避亲密；自我认知不清晰，他人评价敏感） 回避型（回避亲密，不忧虑被抛弃；自我认知清晰，对他人评价不敏感） 这两者都属于不安全型依赖性格。 所谓的回避型依恋，则指的是“在成人亲密关系中表现出对于情感和亲密感的回避行为模式的人群”。 二、相处模式这里主要从焦虑型人格出发分析如何与回避型人格更好相处。 1. 应该怎么做a) 如何沟通？ 协商双方诉求并寻找平衡点 合适的时机向对方表达自身诉求，并阐述自己所感觉到的对方的诉求 及时发现情感中的问题，及时沟通，沟通时注意尊重体会对方的感受 提供有价值的情感交流，减少无意义的生活琐事分享 b) 焦虑型性格应该用怎样的心态对待回避型性格？（重要） 摆脱恋爱刻板印象 如果伴侣偏向回避型人格，我们首先需要做到理解对方，放下“恋爱中应该什么样”的印象，去试着站在对方的角度理解对方 每个人都有着自己对于恋爱当中我们应该是什么样子的期待，而我们总是会以这些不自觉的期待进行判断标准去衡量对方的行为。例如，谈恋爱就是要“亲亲抱抱举高高”，但是当你以这样的标准去衡量一个回避型依恋的恋人时，结局往往会大失所望甚至会自我怀疑。 等待 需要给对方足够的时间，自己需要有巨大的耐心与时间 焦虑性格的人应该压抑对对方的猜疑，充分体谅对方的性格特点 给予对方空间感 最重要的是尊重对方的性格 给予对方能感受到的关心，在关心对方的同时要考虑好对方的感受，避免自我感动 不要过分看低自己，回避型性格看不起那些自我贬低的人，自身更应该足够优秀 学会给予对方安全感，慢慢构建回避型对你的依赖。例如：更成熟，更可靠 2. 千万不能怎么做？ 不要强人所难，强求对方按照自己的认知做事情。焦虑型性格的人容易忽视对方的需求与习惯。ta们容易用自以为对的去思考对方、要求对方。不要因为自己的无知将压力带给对方。 不能急躁，焦虑 焦虑型性格被甩时容易冲动，死缠烂打，情绪非常低落。正确的做法应该是先分析清楚对方的诉求，自我认真检讨、改正，再寻求对方的和解。 不能只顾自己、忽视对方的感受 3. 回避型人格的自我治疗 探索自我诉求 回避型依恋的人并非没有亲密感的需要，相反由于成长过程中自我诉求有时受到压抑，他们的内心深处反而有着更浓烈的感情，只不过被掩藏起来建议独处时，向内探索，抛开道德感和自我束缚，正视自我需求。 尝试表达诉求 多向伴侣表达自我诉求，试着让对方理解自己当自己感受到任何不舒服时，尽可能向伴侣表达 三、总结一个人可能不完全对应某一种性格，但是根据ta的某种表现我们可以将其归类为这种性格，两个人的依恋关系也会受到对方影响，一个人可能本不是回避型的，但是伴侣的过度亲热可能会导致其产生排斥，进而转向回避型；同时，如果两个人能在相互理解相互尊重的基础上积极沟通，两人是可以相向而行的。相信这样两个性格的人相伴是幸运的，只要两个人对对方多一些理解与信心，两个人可以相互扶持都回归到正常的依赖关系中。 Appendix恋爱过程中回避型和焦虑型的心理变化回避型：刚开始偏主动和粘人，但是互动只是暂时的，确定关系后会进入假性独立的状态，不需要对方太靠近，只做好自己；尤其度过热恋期后，害怕亲密；最后感觉到感情已经没有价值，选择放弃。 焦虑型：一开始时焦虑型担心各种事情，担心对方会不喜欢真实的自己，进而掩饰起自己；之后在看到对方冷淡的态度后以为是自己做的不好，会更加夸张的去表达爱，但是这样做没有考虑到对方的感受，反而可能会引起对方的厌恶与疏远，然后焦虑型就会感到很深的挫败感，做事会更加不理智、死缠烂打、完全陷入自我感动中。 回避型依恋的表现具体请参考 知乎 回避型依恋的人并非完全没有亲密的诉求，只不过在实际的亲密互动中他们似乎看起来如此的冷漠。 追求亲密是人的本能，对于回避型依恋人格，在如何相爱上，相信 “我们基于对对方的爱而做出的事情，应该以对方的需求作为出发点，而不是自己想要爱对方这件事”直白的说，是你要给予他他想要的，而不是你所拥有的。 而在考虑到对方需求的这件事上 如果你的恋人是回避型依恋，我建议你一定要非常小心翼翼。 如果你自身是回避型依恋，我建议你学会表达自己的需求。","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"余秀华的诗","slug":"诗词/余秀华的诗","date":"2021-05-16T13:17:06.000Z","updated":"2023-07-03T15:04:36.950Z","comments":true,"path":"2021/05/16/shi-ci/yu-xiu-hua-de-shi/","link":"","permalink":"http://jlutangchuan.github.io/2021/05/16/shi-ci/yu-xiu-hua-de-shi/","excerpt":"","text":"余秀华的诗余秀华 巴巴地活着，每天打水，煮饭，按时吃药 阳光好的时候就把自己放进去，像放一块陈皮 茶叶轮换着喝：菊花，茉莉，玫瑰，柠檬 这些美好的事物仿佛把我往春天的路上带 所以我一次次按住内心的雪 它们过于洁白过于接近春天 在干净的院子里读你的诗歌 这人间情事恍惚如突然飞过的麻雀儿 而光阴皎洁 我不适宜肝肠寸断 如果给你寄一本书，我不会寄给你诗歌 我要给你一本关于植物，关于庄稼的 告诉你稻子和稗子的区别 告诉你一棵稗子 提心吊胆的春天 释义稗子意象： 稗子和稻子外形极为相似，和稻子一起长在稻田里，区别不大，只能从叶片的宽窄深浅来辩别，但稗子是要除掉的，打除稗药，扯稗。稗子生命力强，除掉的稗子抛在田埂，还要切断根才停止生长。春天是美好的，稗子却时刻有剥夺生命的可能而”提心吊胆”。”我”想告诉心爱的人，我是多么的爱你，害怕失去你，我”提心吊胆”害怕如稗子一样的命运。","raw":null,"content":null,"categories":[{"name":"诗词","slug":"诗词","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%97%E8%AF%8D/"}],"tags":[]},{"title":"Mac OS上安装XAMPP","slug":"技术/编程/Mac-OS上安装XAMPP","date":"2021-04-25T02:34:27.000Z","updated":"2023-07-03T15:04:37.040Z","comments":true,"path":"2021/04/25/ji-zhu/bian-cheng/mac-os-shang-an-zhuang-xampp/","link":"","permalink":"http://jlutangchuan.github.io/2021/04/25/ji-zhu/bian-cheng/mac-os-shang-an-zhuang-xampp/","excerpt":"","text":"Mac OS上安装XAMPP昨天把黑苹果装上了，今天尝试安装一下XAMPP 第一步：下载程序包下载链接 我这里用的是7.4.16版本, 8.0以上的版本界面和这个不太一样，点击上面的链接下载即可 第二步：安装程序包在文件管理器（访达）中找到下载好的安装包，点击安装即可，这里全部用默认设置就行 第三步：启动XAMPP开启以下服务： XAMPP General Start Services Start All Network 两个端口转换全部Enable Volumes 挂载 （点击Mount） 第四步：打开phpmyadmin（MySQL管理工具）在浏览器上（mac os上推荐安装chrome浏览器）进入如下地址 （昨天我一直输的是phpadmin，怪不得进不去:（ ） http://localhost:8080/phpmyadmin/ 即可进入 此外，XAMPP的主页在如下位置 192.168.64.2/dashboard/ mac上XAMPP相关文件夹由于上一步中的挂载，可以在Finder中找到apache服务器里面的文件路径 简单介绍一下各个文件夹的作用 htdocs: 这个文件夹主要是服务器主页内容的源文件，可以在此更改index.php来修改主页内容 phpmyadmin：admin界面源文件，好像可以在这里添加数据库管理员密码 另外，建议下载VS Code软件写代码 P.S.mac上和win10上的用户界面设计以及逻辑不一样，导致mac上昨天没配好环境：） 一个启示就是：答应别人的事情要认真准备","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Mac OS","slug":"Mac-OS","permalink":"http://jlutangchuan.github.io/tags/Mac-OS/"}]},{"title":"科学观","slug":"生活/科学观","date":"2021-04-22T15:29:42.000Z","updated":"2023-07-03T15:04:36.973Z","comments":true,"path":"2021/04/22/sheng-huo/ke-xue-guan/","link":"","permalink":"http://jlutangchuan.github.io/2021/04/22/sheng-huo/ke-xue-guan/","excerpt":"","text":"科学观科学与科学观什么是科学？ 首先是自己对于科学的认识，科学是将外部世界现象进行解释以及预测，分为自然科学（理化生）、社会科学（经济、心理、社会学）、形式科学（数学、计算机科学、逻辑学） Science is a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe. 科学是一个建立在对宇宙进行可检验的解释和对客观事物的形式、组织等进行预测的有序的知识系统 既然科学是对外部世界解释，对外部世界进行观察是必不可少的，因此就有了实验；要探索世界的规律，就要对实验进行分析得到唯象理论；唯象理论可以很好地解释现象，但是还不能称做系统的知识，于是，从唯象理论出发结合形式科学发展出理论框架（范式） 以上是从现象出发的归纳推理出的科学——归纳主义科学观 科学观西方科学哲学的几个解释：实证主义、逻辑实证主义、证伪主义 实证主义：相信归纳得出理论 波普尔证伪主义：科学理论无法通过归纳证实，但可证伪 归纳主义科学观认为科学就是通过对事实进行归纳总结之后，所得到的理论。归纳主义科学观的诞生，是人类的一大进步，有力地推动了现代科学的发展。但问题在于，我们所观察到的事实未必就是正确的，而且归纳推理这种方法，本身在逻辑上也不够严谨，容易出问题。 除了归纳主义的科学观，还有三种科学观，以下是A.F.查尔莫斯的四种科学观： 归纳主义科学观——科学是通过归纳总结事实，所得到的理论 证伪主义科学观——科学的本质，是可以被证伪。如果一套理论，不能被证伪，怎么说都对，那就不是科学。科学是可以被检验，而且可能被证明是错误的理论。（波普尔） 结构科学观——科学不是某一个具体的理论，而是诸多理论组织的结构，在这个结构中所有理论都在一个框架中，这个框架，就是“范式”。科学依赖于“范式”这个框架，有没有这个框架，是衡量科学与非科学的标准。（马库斯） 贝叶斯主义的科学观——科学理论的正确与否，是一个概率问题。我们可以根据新出现的证据，来描述事件发生的概率变化。 对于证伪主义的科学观，存在的问题是如果一个理论由于目前的技术限制而暂时无法证伪，那么它是否应该算作科学？（否定理论先于观察的可能） 结构主义科学观强调范式的科学，在结构科学观看来，所有成熟的科学，都要有一个处在核心地位的基础理论。存在一个被广泛接受的“范式”，是科学研究和进步基础，也是区分科学与非科学的标志。并且这种范式是不断更新的，新的科学理论可能会打破旧的范式（前科学—常规科学—反常—危机—科学革命—新的常规科学—…） 科学品味需要承认，科学品味与收到的教育、接触的机会、环境有关，同时我们也需要不断地思考这个科研价值、科研品味这些问题 什么是有价值的研究？可以讨论对于谁而言有价值 对于社会来说：能够为社会整体创造巨大价值的研究更有意义 对于自己来说：能够实现的研究、从中得到满足的研究更有意义 对于研究方向来说：1. 完善一个理论 2. 发现一个理论的缺陷 3. 提出一个新的理论 都有意义 不同品味的研究陶哲轩：什么是好数学？ 好的数学题解（比如在一个重要数学问题上的重大突破）； 好的数学技巧（比如对现有方法的精湛运用，或开发新的工具）； 好的数学理论（比如系统性地统一或推广一系列现有结果的概念框架或符号选择）； 好的数学洞察（比如一个重要的概念简化，或对一个统一的原理、启示、模拟或主题的实现）； 好的数学发现（比如对一个出人意料、引人入胜的新的数学现象、关联或反例的揭示）； 好的数学应用（比如应用于物理、工程、计算机科学、统计等领域的重要问题，或将一个数学领域的结果应用于另一个数学领域）； 好的数学展示（比如对新近数学课题的详尽而广博的概览，或一个清晰而动机合理的论证）； 好的数学教学（比如能让他人更有效地学习及研究数学的讲义或写作风格，或对数学教育的贡献）； 好的数学远见（比如富有成效的长远计划或猜想）； 好的数学品位（比如自身有趣且对重要课题、主题或问题有影响的研究目标）； 好的数学公关（比如向非数学家或另一个领域的数学家有效地展示数学成就）； 好的元数学（比如数学基础、哲学、历史、学识或实践方面的进展）； 严密的数学（所有细节都正确、细致而完整地给出）； 美丽的数学（比如拉马努金的那些令人惊奇的恒等式；陈述简单漂亮、证明却很困难的结果）； 优美的数学（比如保罗·厄多斯的“来自天书的证明”观念通过最少的努力得到困难的结果）； 创造性的数学（比如本质上新颖的原创技巧、观点或各类结果）； 有用的数学（比如会在某个领域的未来工作中被反复用到的引理或方法）； 强有力的数学（比如与一个已知反例相匹配的敏锐的结果，或从一个看起来很弱的假设推出一个强得出乎意料的结论）； 深刻的数学（比如一个明显非平凡的结果，比如理解一个无法用更初等的方法接近的微妙现象）； 直观的数学（比如一个自然的、容易形象化的论证）； 明确的数学（比如对某一类型的所有客体的分类；对一个数学课题的结论） 方法论如何培养良好品味？ Seek out others with good taste, 寻找那些有不错学术品味的人 Read trend-setting conference proceedings, and develop opinions about research problems and trends in your area, 从最杰出的工作中模仿学习，有筛选地学习 Sample and experiment with abandon, 不断地尝试新的内容 Keep a list of ideas that you like and exchange your favorite ideas with colleagues, 多记录、多交流 除此之外，还需要自己去思考什么样的方向、问题、论文更有价值 问题的重要性 看一个工作的结论的好坏，来评价工作的价值 Reference https://greatresearch.org/2013/09/13/cultivating-your-research-taste/ http://www.theexclusive.org/2014/12/taste-in-research-and-paradox-of.html http://en.wikisource.org/wiki/On_Taste 一个人的科研品位会对自己的学术道路有什么影响？ - 想飞的猪的回答 - 知乎 What is This Thing Called Science","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://jlutangchuan.github.io/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"Bottom-Up and Top-Down Attention for Image Captioningand Visual Question Answering","slug":"技术/理论/论文/Bottom-Up-and-Top-Down-Attention-for-Image-Captioningand-Visual-Question-Answering","date":"2021-02-01T13:51:07.000Z","updated":"2023-07-03T15:04:37.099Z","comments":true,"path":"2021/02/01/ji-zhu/li-lun/lun-wen/bottom-up-and-top-down-attention-for-image-captioningand-visual-question-answering/","link":"","permalink":"http://jlutangchuan.github.io/2021/02/01/ji-zhu/li-lun/lun-wen/bottom-up-and-top-down-attention-for-image-captioningand-visual-question-answering/","excerpt":"","text":"Bottom-Up and Top-Down Attention for Image Captioningand Visual Question Answering2018 CVPR 这篇之前一直没看，做image caption和VQA任务，SCAN正式受此启发的在image-text matching上的工作 首先解释一下Top-down和Bottom-up是啥意思，参考链接 一开始不了解这个概念，就不大理解题目起得是啥意思，后来在Youtube上找到这两个概念的解释 这两个概念应该算是认知领域使用的名词：Top-down processing、Bottom-up processing，同样attention也应该是认知领域率先提出的概念吧。。 Bottom-up processing： 源于刺激（stimulus），比如在视觉中，运动的物体、未见过的内容会对我们产生更大的刺激 Bottom-up processing是指当没有任何先入为主的想法时对内容的认知 Top-down processing： 是指结合了背景知识(Background Knowledge)的对观察到内容的感知，我们对观察内容的理解受到背景期望的影响 介绍提出自底向上、自顶向下注意力机制来处理image caption和VQA任务 以下是自己的认识 这里自底向上意思是从图像中无背景知识地获取内容 这里自顶向下注意力的意思是在对获取到的内容进行注意力获取时利用了语言模型的背景知识 先前使用自顶向下注意力机制的imagel caption模型的问题：之前的方法大多都是根据部分句子或单词从整个图片获取注意力区域（top-down），However, this approach gives little consideration to how the image regions that are subject to attention are determined. 这篇工作主要是在SAN(Stacked Attention Networks for Image Question Answering)的基础上思考的，SAN中作者用CNN来获得10x10一共100个特征向量，然后拿这些向量和问题计算注意力并以此输出回答。作者认为SAN这篇工作缺少对于图片内容的处理 方法首先用Faster-RCNN进行目标检测和属性预测(Genome)，获取Faster-RCNN的候选区域的中间表示作为自底向上处理获得的内容信息 注意这里还有属性预测，可以说提升了自底向上获得内容的丰富度，region embeddings应该包含更多的信息量，这里根据候选框的置信度取topk的region。 接下来就是利用自底向上提取的视觉信息完成image caption和VQA任务，具体实现目前不是很关心 评价 SCAN借鉴的应该是从检测模型获取Bottom-up信息的实现，其他的貌似也不像 这种利用检测&amp;分类模型的image caption应该说是在模型上经过了额外的标注训练（类似语言上的预训练模型？），这种思路应该可以扩展开 感觉这个attention用得不是很好 目前Image Caption有个类似GPT-3的工作CLIP，貌似是与机器学习中zero-shot等有关来进行预训练，后面可以考虑看看这些工作，从机器学习的角度来思考这个任务","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"}]},{"title":"ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences","slug":"技术/理论/论文/ShapeCaptioner-Generative-Caption-Network-for-3D-Shapes-by-Learning-a-Mapping-from-Parts-Detected-in-Multiple-Views-to-Sentences","date":"2021-02-01T08:32:56.000Z","updated":"2023-07-03T15:06:27.000Z","comments":true,"path":"2021/02/01/ji-zhu/li-lun/lun-wen/shapecaptioner-generative-caption-network-for-3d-shapes-by-learning-a-mapping-from-parts-detected-in-multiple-views-to-sentences/","link":"","permalink":"http://jlutangchuan.github.io/2021/02/01/ji-zhu/li-lun/lun-wen/shapecaptioner-generative-caption-network-for-3d-shapes-by-learning-a-mapping-from-parts-detected-in-multiple-views-to-sentences/","excerpt":"","text":"ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to SentencesACM MM 2020 Oral Zhizhong Han 利用3D模型在多视图下的检测来做3D模型文本生成 摘要&amp;主要工作先前的3D文本生成的工作（Y2Seq2Seq）没有考虑part-level的特征，ShapeCaptioner通过多视图检测让文本生成模型能从part-level来进行描述生成 贡献 提出用检测来进行shape caption任务 提出一个利用分割标注进行多视图检测的方法 part aggregation 相关工作Image Caption： e2e的使用全局embedding的图片描述生成模型 object-level semantics 基于检测的图片描述生成模型 方法 Part geometry detection 首先用3D分割数据集来获得多视图检测标注（同样，检测标注没有颜色、纹理、材料等属性标注），但在多视图图像中有RGB信息 这里检测模型的训练有技巧，先训练一个无颜色的检测器，然后用无颜色检测器的检测结果来辅助训练有颜色的检测器（不确定是不是这个意思） Part aggregration pooling进行part embedding的获取（撞车！！！） 得到的part embeddings用RNN进行编码，并用RNN进行解码生成文本，这里的损失是负对数损失 实验评估指标 BLEU（B-1、B-2、B-3、B-4） bilingual evaluation understudy n-grams$$B L E U&#x3D;B P * \\exp (\\sum_{n&#x3D;1}^{N} w_{n} * \\log ^{p_{n}})$$BP为最佳匹配长度 CIDEr 常用与Image Caption任务，计算TF-IDF，看看关键单词是否抓取到 METEOR ROUGE 实验设计3组搜参数实验，3组消融实验 RNN hidden state dimension H 搜参数实验{16,32,64,128,256,512}：发现设置为32比较好，而且32和其他指标的结果相比提升很高 检测模型参数的设置，好像也挺敏感的，略 多视图数量搜参 {1，4，8，12} 这个还比较正常，越多越好 消融实验：aggregation操作{mean、max、mixed}，mixed：视图内max pooling，视图间mean pool；最后发现还是max好 比较GRU和LSTM，发现GRU好 对比part好还是view好：肯定是part好-。- 可视化：检测模型的可视化、Caption结果的展示 与其他方法的对比（C-Chair T-Table） 还做了一个调查统计，看看普通人对于生成的描述的满意程度","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"}]},{"title":"云边有个小卖部","slug":"读书笔记/云边有个小卖部","date":"2021-01-21T05:15:16.000Z","updated":"2023-07-03T15:04:36.977Z","comments":true,"path":"2021/01/21/du-shu-bi-ji/yun-bian-you-ge-xiao-mai-bu/","link":"","permalink":"http://jlutangchuan.github.io/2021/01/21/du-shu-bi-ji/yun-bian-you-ge-xiao-mai-bu/","excerpt":"Here's something encrypted, password is required to continue reading.","text":"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 Hey, password is required here.","raw":null,"content":null,"categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"小说","slug":"小说","permalink":"http://jlutangchuan.github.io/tags/%E5%B0%8F%E8%AF%B4/"}]},{"title":"千与千寻","slug":"读书笔记/千与千寻","date":"2021-01-21T05:15:16.000Z","updated":"2023-07-03T15:04:36.980Z","comments":true,"path":"2021/01/21/du-shu-bi-ji/qian-yu-qian-xun/","link":"","permalink":"http://jlutangchuan.github.io/2021/01/21/du-shu-bi-ji/qian-yu-qian-xun/","excerpt":"Here's something encrypted, password is required to continue reading.","text":"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 Hey, password is required here.","raw":null,"content":null,"categories":[{"name":"随记","slug":"随记","permalink":"http://jlutangchuan.github.io/categories/%E9%9A%8F%E8%AE%B0/"}],"tags":[{"name":"影视剧","slug":"影视剧","permalink":"http://jlutangchuan.github.io/tags/%E5%BD%B1%E8%A7%86%E5%89%A7/"}]},{"title":"GTD任务管理","slug":"生活/GTD任务管理","date":"2021-01-18T14:59:49.000Z","updated":"2023-07-03T15:04:36.966Z","comments":true,"path":"2021/01/18/sheng-huo/gtd-ren-wu-guan-li/","link":"","permalink":"http://jlutangchuan.github.io/2021/01/18/sheng-huo/gtd-ren-wu-guan-li/","excerpt":"","text":"GTD任务管理为什么要学GTD？ 目前自己的工作状态有些混乱：经常不知道干嘛、经常摸鱼、有时候一件事情干着干着就容易分神、每天列计划但总是完不成、经常性的焦虑… 所以最近总是想去尝试学习一些可能让自己生活学习工作变得井井有条的一些方法。 无意中看到了这个GTD任务管理的一套方法，花了一天学习这个东西，于是就打算实验一下，感受一下这种任务计划模式是否适合自己。 GTD自我管理学习 GTD时间管理：Getting Things Done 背景日常遇到的问题： 待办事情非常混乱，不得不一边思考做什么，一边思考如何去做 人在短期内只能记住有限的事物，从长期记忆中获取信息比较困难 混乱的待办事项会让大脑陷入失控感，会造成焦虑、拖延、压力大等问题 GTD的目的： 让大脑不再混乱 明确下一步应该做什么 GTD流程 捕获：将所有遇到的大小事情装进收集箱 明晰：将收集箱中的事项逐项回顾：直接可行？可以一步搞定？可以立即做？是否该自己去完成？有安排固定时间？ 组织：将上面形成的清单进行组织、记录 回顾：定期检查清单 执行 执行清单排序注意事项 执行清单内的事情用时比较短 不同事情的费力程度、耗时程度、琐碎程度不一样 做计划、做方案这类事情应该多去训练 做好时间预估 为特别的事情提前预留时间 执行清单处理事情的质量与效率 每次只处理一件事情 订时钟 打破负罪感幻觉（避免因为别人而打断自己的事情而产生负罪感） （扩展阅读） 关于高效工作类的书 GTD作者原书 高效能人士的七个习惯 最重要的事只有一件 GTD总体流程回顾 首先将想到要做的所有事情放入inbox收集箱中 进行任务明晰，将收集箱中的事情放入各自的分区中： 日历 执行清单 等待清单 项目清单 可能清单 参考资料 回收箱 对执行清单内的内容进行排序 不可能做完所有事情 尽可能做离自己目标近的事情 定期回顾 执行 GTD工作时间安排 每天早上第一件事情就是按照这个时间管理做计划 定期进行回顾 清空收集箱 随时随地进行事项收集 参考资料、回收箱的功能 可能但暂时没必要做的事情 参考资料 找高可信度的参考资料 记录下来","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[]},{"title":"Self attention工作两篇","slug":"技术/理论/论文/Self-attention工作两篇","date":"2021-01-16T12:53:00.000Z","updated":"2023-07-03T15:04:37.116Z","comments":true,"path":"2021/01/16/ji-zhu/li-lun/lun-wen/self-attention-gong-zuo-liang-pian/","link":"","permalink":"http://jlutangchuan.github.io/2021/01/16/ji-zhu/li-lun/lun-wen/self-attention-gong-zuo-liang-pian/","excerpt":"","text":"Self attention工作两篇最近在看自注意力的工作，要把这个加到现有的模型中，先记录一下两篇引用量比较高的工作 Outline Self Attention A Structured Self-Attentive Sentence Embedding Non-local Neural Networks Paper ReadingA Structured Self-Attentive Sentence Embedding2017 ICLR Bengio 主要工作提出的模型主要是针对从词嵌入获得句子嵌入表示的，在这个过程中加入自注意力机制 提出了一个新的通过自注意力机制提取（集成）句子embedding的方法，使用矩阵表示句子embedding sentence embedding matrix each row vector represent a different part of the sentence 可以很方便地进行可视化（part与word的对应关系） task author profiling 情感分类 textual entailment 贡献 提出自注意力机制 使用自注意力获取句子embedding 提出一个特别的正则项 背景此前的提取sentence embedding的方法不是很好，这些方法大致可以分成两类： universal sentence embeddings usually trained by unsupervised learning: Skip-Thought vectors、ParagraphVector、recursive auto-encoders、Sequential Denoising Autoencoders、FastSent trained specifically for a certain task（这种方法得到的embedding一般来说比前者好），这种方法通常用max pooling或者mean pooling提取sentence embedding或者N-gram卷积或者用最后time step的输出作为句子的表示 方法self-attention 上图是注意力向量获取方法，拿到注意力向量之后对wordembedding进行加权⊕$$a&#x3D;\\operatorname{softmax}(w_{s 2} \\tanh (W_{s 1} H^{T}))$$ 这里既可以输出一个attention vector，也可以输出multi-head attention$$A&#x3D;\\operatorname{softmax}\\left(W_{s 2} \\tanh \\left(W_{s 1} H^{T}\\right)\\right) \\M&#x3D;AH$$在加入multi-head attention之后，希望这些attention尽可能关注不同的内容，所以需要加入惩罚项进行学习 The embedding matrix M can suffer from redundancy problems if the attention mechanism always provides similar summation weights for all the r hops. Thus we need a penalization term to encourage the diversity of summation weight vectors across different hops of attention. $$P&#x3D;\\left|\\left(A A^{T}-I\\right)\\right|_{F}^{2}$$ 这一项让各个注意力权重向量尽可能正交，同时自身范数尽可能为1 摘录 注意力机制 use attention mechanism on top of the CNN or LSTM model to introduce extra source of information to guide the extraction of sentence embedding This enables attention to be used in those cases when there are no extra inputs We hypothesize that carrying the semantics along all time steps of a recurrent model is relatively hard and not necessary Non-local Neural Networks2018 CVPR, Ross Girshick Kaiming He 主要工作和前面的论文不同，这篇论文使用注意力来做视觉的 摘录 Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time Convolutional and recurrent operations both process a local neighborhood, either in space or time For image data, long-distance dependencies are modeled by the large receptive fields formed by deep stacks of convolutional operations Repeating local operations has several limitations. First, it is computationally inefficient. Second, it causes optimization difficulties that need to be carefully addressed In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Our non-local operation computes the response at a position as a weighted sum of the features at all positions. Intuitively, a non-local operation computes the response at a position as a weighted sum of the features at all positions in the input feature maps. 使用注意力机制来进行非局部特征融合 task 视频分类 COCO 检测、分割、姿态估计 贡献提出了一种非局部计算方法，提出模型 non-local neural networks 非局部操作的优势： 相比与堆叠的CNN、RNN，这种non-local 可以无视距离来提取long range dependencies 结果上看比此前的方法更有效 很容易加入到现有模型中 背景问题 卷积结构和循环结构都阻碍了全局信息的获取，注意力机制能帮助解决这个问题 相关工作从多个不同角度来讲相关工作，厉害厉害！ Non-local image processing Non-local means方法 A non-local algorithm for image denoising(classical non-local means method) BM3D Graphical models 通过图来建模长距离依赖，代表方法有：CRF、GNN Feedforward modeling for sequences 用卷积代替RNN做序列问题 Self-attention Attention is all you need在这个论文之前。。 our work bridges self-attention for machine translation to the more general class of non-local filtering operations that are applicable to image and video problems in computer vision Interaction networks（Relation Network） 用和自注意力不同的另一个视角看这种非局部操作 方法$$y_{i}&#x3D;\\frac{1}{C(x)} \\sum_{\\forall j} f(x_{i}, x_{j}) g(x_{j})$$ 任意两个位置i和j通过pairwise function算一下类似权重的东西，然后对于特征图中所有点进行这样的加权计算，然后再用C函数进行归一化，这里g函数应该是一个j位置的输入信号的表示向量 和全连接的区别：fc的权重是网络学得的，non-local的权重$f(x_i,x_j)$是计算相应得到的；fc的权重是一个受位置固定的（对于任意两个位置，它们的fc权值是固定的），non-local的权重是与位置无关的（权值受具体输入信号影响）；fc要求输入的size固定 具体的g函数可以是一个1x1的卷积操作 pairwise function $f$可以有很多种 Gaussian f(x_i, x_j)=e^&#123;&#123;x_i&#125;^T x_j&#125; Embedded Gaussian f(x_i, x_j)=e^&#123;\\theta(x_i)^T \\phi(x_j)&#125; 在计算点积之前先乘个矩阵，这个可以用另一种与self-attention一致的方式表示：$${y}&#x3D;\\operatorname{softmax}(x^T W_{\\theta}^T W_{\\phi} x) g(x)$$ 这个操作之后，相当于特征图中每个位置都有注意的区域的信息 此外还有直接点乘、concatenation等方法 Non-local Block$$z_i&#x3D;W_z y_i+x_i$$ 这里使用残差链接构成一个模块，这个模块很容易加入到其他视觉模型中，相当于每个位置的注意力表示和原来的输入表示做了个运算（加法运算。。） 计算图如下 分析感觉这两个工作的self-attention的大致思路是： 首先有长距离依赖问题，需要有选择地获得某个位置对应的长距离依赖区域的表示 用响应函数以及归一化组合来获得注意力得分 用得分和得到的中间表示加权求和得到注意力表示 第一篇工作直接用注意力表示，而第二个工作通过残差链接的方式将注意力表示和原始表示又做了一个计算 第一篇论文不仅考虑了注意力得分的计算，还考虑了这个注意力需要加入惩罚项来防止每个学到的注意力权重都一样 自己的工作首先先完成老师讲的文本端的self-attention，然后要考虑point到part这个过程如何用self-attention来拿到part embedding 感觉还要看看点云上的注意力机制的论文： PVNet: 基于注意力嵌入式的点云与多视角图像融合感知网络 MM 2018 PCT: Point Cloud Transformer：清华团队将Transformer用到3D点云分割上后，效果好极了 Relation-shape convolutional neural network for pointcloud analysis 貌似同期还有一篇Point Transform和PCT差不多？","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"}]},{"title":"程序员健康-坐骨神经痛","slug":"生活/程序员健康-坐骨神经痛","date":"2021-01-09T14:40:26.000Z","updated":"2023-07-03T15:04:36.975Z","comments":true,"path":"2021/01/09/sheng-huo/cheng-xu-yuan-jian-kang-zuo-gu-shen-jing-tong/","link":"","permalink":"http://jlutangchuan.github.io/2021/01/09/sheng-huo/cheng-xu-yuan-jian-kang-zuo-gu-shen-jing-tong/","excerpt":"","text":"程序员健康-坐骨神经痛概览首先坐骨神经痛是一类病症的表现：这个博客搜集了坐骨神经痛的检测方法，坐骨神经痛的原因分析：1. 椎间盘或者骨刺压迫坐骨神经引起的坐骨神经痛；2. 梨状肌引起的坐骨神经痛。发病的原因有：久站久坐、腰部肌肉缺乏锻炼、坐姿不好造成坐骨神经挤压。自我恢复的方法也学习了几个，坚持对于坐骨神经的保护、多进行针对性的锻炼 检测方法 原因分析 什么习惯引起的？ 坐骨神经痛应该是一类疾病造成的现象，所以造成此种问题的可能原因有多种。 在网上找的资料，查到可能有如下因素造成的： 骨刺 假性坐骨神经痛 「梨狀肌症候群」也稱為假性坐骨神經痛，梨狀肌是臀部深層的一塊肌肉，因其下方有坐骨神經通過，所以一旦梨狀肌發炎、過度使用，就可能變得緊繃而壓迫到坐骨神經，引發臀部痠痛、腿麻、腳麻等症狀。 這種情況常發生在身材較瘦或是突然減重較多的人身上，因其臀部的脂肪較薄，所以久坐後也容易壓迫坐骨神經。 而另一種假性坐骨神經痛也可能是「臀肌肌膜疼痛」所致，如臀部的臀中肌、臀小肌可能因為跌倒、過度運動、走遠路或久站而引起類似坐骨神經痛的症狀。 椎间盘突出 位置：下背部第四、第五节腰椎间，神经根收到压迫 椎间盘突出 椎間盤指的是連結每一節脊椎的軟骨，一旦長期受到擠壓而突出，就會壓迫神經根造成疼痛。某些過度彎腰、長時間姿勢不良的動作，都可能引起椎間盤突出，例如彎腰搬重物、久坐、退化等等。^2 表现 坐骨神经痛并不是某一特定的疾病，而是因神经根收到压迫引起的一种沿着坐骨神经的通路传递，由腰骶部经臀部向下肢放射至小腿甚至足踝部的烧灼样、刀割样疼痛、麻木等临床症候群。 有学者使用该术语作为由腰椎间盘突出压迫一个或多个腰或骶神经根部引起的神经功能障碍的诊断。 坐骨神经痛是多种疾病均可表现出的症状，如腰椎间盘突出症、腰椎滑脱、椎管狭窄、梨状肌综合症等。坐骨神经痛严重的时候，咳嗽或稍微用力疼痛都会加剧，部分情况下，夜晚疼痛更加明显。^1 治疗注意事项 避免搬重物 避免激烈的腰部運動 坐姿端正，避免翹二郎腿 椅子高度不宜過低 使用軟硬適中、支撐力良好的床墊 維持標準體重，肥胖會增加對腰椎的負荷 锻炼方法参考知乎文章的锻炼方法^3 “倒” “蹬” “撑” “悬” “立” 直立，双脚微微分开，手放腰背部，四指并拢。手指向后，以双手作支柱，尽量将腰以上身躯向后弯，双膝要保持挺直。维持一两秒钟，然后回到开始位置。每次重复练习时，尽量尝试将上半身弯得比前一次更后、更弯，以达到最大可能的伸展度。 按摩 按摩法非常简单，腰椎突出的那一节两边的肌肉一般比较僵硬，宜推揉放松后，涂上活络酒，每日2次，对促进微循环、消除软组织炎症很有帮助。每日吊5分钟单杠，晚上睡觉时，患者可以在腰椎下方垫上折叠的毛巾，随着治疗的进展逐渐加高，以纠正腰椎键盘突出。 梨状肌锻炼^4 ^5 ^6 腰部肌肉锻炼 三点撑、四点撑、五点撑 引体向上 坐姿下拉 山羊挺身 参考资料","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"健康","slug":"健康","permalink":"http://jlutangchuan.github.io/tags/%E5%81%A5%E5%BA%B7/"}]},{"title":"Hexo使用简单教程","slug":"技术/编程/hello-world","date":"2021-01-09T14:40:26.000Z","updated":"2023-07-03T15:04:37.034Z","comments":true,"path":"2021/01/09/ji-zhu/bian-cheng/hello-world/","link":"","permalink":"http://jlutangchuan.github.io/2021/01/09/ji-zhu/bian-cheng/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post $ hexo new &quot;My New Post&quot; More info: Writing Run server $ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy # 可以简写为 hexo d 上边同理 More info: Deployment make-link &quot;E:\\OneDrive\\Note\\OBSIDIAN Note\\Obsidian笔记\\600 publish\\blog&quot; &quot;D:\\blog\\source\\_posts&quot;","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://jlutangchuan.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"http://jlutangchuan.github.io/tags/Blog/"}]},{"title":"PySnooper与Rich库学习","slug":"技术/编程/PySnooper与Rich库学习","date":"2020-12-03T08:36:07.000Z","updated":"2023-07-03T15:04:37.049Z","comments":true,"path":"2020/12/03/ji-zhu/bian-cheng/pysnooper-yu-rich-ku-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2020/12/03/ji-zhu/bian-cheng/pysnooper-yu-rich-ku-xue-xi/","excerpt":"","text":"PySnooper与Rich库学习最近看到两个Python的包，1）pysnooper（偷窥狂）2）Rich Pysnooper是一个用来代替print在代码调试的是否监看程序运行情况的库 Rich是一个美化输出结果的库，主要想用这个美化一下输出的结果 Pysnooper学习目前有14K的star，而且还有个TorchSnooper的专门用来调试pytorch的库，先学习一下Pysnooper的基本使用方法 函数snooperGithub上的示例 在要分析的函数加入@pysnooper.snoop()装饰器语法糖，然后在被调用时会自动输出全部中间结果 import pysnooper @pysnooper.snoop() def number_to_bits(number): if number: bits = [] while number: number, remainder = divmod(number, 2) bits.insert(0, remainder) return bits else: return [0] number_to_bits(6) 输出结果 主要信息： 文件位置 传进去的参数 每行的调用时间 当出现新变量或变量值修改的时候会打印一下新的值 返回的结果 总的耗时 Source path:... /my_code/foo.py Starting var:.. number = 6 15:29:11.327032 call 4 def number_to_bits(number): 15:29:11.327032 line 5 if number: 15:29:11.327032 line 6 bits = [] New var:....... bits = [] 15:29:11.327032 line 7 while number: 15:29:11.327032 line 8 number, remainder = divmod(number, 2) New var:....... remainder = 0 Modified var:.. number = 3 15:29:11.327032 line 9 bits.insert(0, remainder) Modified var:.. bits = [0] 15:29:11.327032 line 7 while number: 15:29:11.327032 line 8 number, remainder = divmod(number, 2) Modified var:.. number = 1 Modified var:.. remainder = 1 15:29:11.327032 line 9 bits.insert(0, remainder) Modified var:.. bits = [1, 0] 15:29:11.327032 line 7 while number: 15:29:11.327032 line 8 number, remainder = divmod(number, 2) Modified var:.. number = 0 15:29:11.327032 line 9 bits.insert(0, remainder) Modified var:.. bits = [1, 1, 0] 15:29:11.327032 line 7 while number: 15:29:11.327032 line 10 return bits 15:29:11.327032 return 10 return bits Return value:.. [1, 1, 0] Elapsed time: 00:00:00.000001 过程snooper也可以不对函数而对一段代码进行snoop分析,使用with语句实现此功能 import pysnooper import random def foo(): lst = [] for i in range(10): lst.append(random.randrange(1, 1000)) with pysnooper.snoop(): lower = min(lst) upper = max(lst) mid = (lower + upper) / 2 print(lower, mid, upper) foo() 输出结果 New var:....... i = 9 New var:....... lst = [681, 267, 74, 832, 284, 678, ...] 09:37:35.881721 line 10 lower = min(lst) New var:....... lower = 74 09:37:35.882137 line 11 upper = max(lst) New var:....... upper = 832 09:37:35.882304 line 12 mid = (lower + upper) / 2 74 453.0 832 New var:....... mid = 453.0 09:37:35.882486 line 13 print(lower, mid, upper) Elapsed time: 00:00:00.000344 pysnooper.snoop()参数分析默认参数：输出文件位置，将输出结果存到log中而不是控制台 @pysnooper.snoop(&#39;/my/log/file.log&#39;) watch：加入监看哪些非局部变量的值 @pysnooper.snoop(watch=(&#39;foo.bar&#39;, &#39;self.x[&quot;whatever&quot;]&#39;)) depth：函数监看深度 watch_explode ： prefix：添加前缀 Remove all machine-related data (paths, timestamps, memory addresses) to compare with other traces easily: @pysnooper.snoop(normalize=True) On multi-threaded apps identify which thread are snooped in output: @pysnooper.snoop(thread_info=True) 另外还可以定制输出（list、dict、numpy、tensor、。。。）","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"近期看到的几首现代诗-11.22","slug":"诗词/近期看到的几首现代诗-11-22","date":"2020-11-21T11:26:00.000Z","updated":"2023-07-03T15:04:36.959Z","comments":true,"path":"2020/11/21/shi-ci/jin-qi-kan-dao-de-ji-shou-xian-dai-shi-11-22/","link":"","permalink":"http://jlutangchuan.github.io/2020/11/21/shi-ci/jin-qi-kan-dao-de-ji-shou-xian-dai-shi-11-22/","excerpt":"","text":"近期看到的几首现代诗-11.22最近看到一个漂亮的小姐姐读现代诗的视频，所以就记一下感觉不错的几首诗😊 致橡树 我曾七次鄙视自己的灵魂 从前慢 致橡树舒婷 我如果爱你—— 绝不像攀援的凌霄花， 借你的高枝炫耀自己； 我如果爱你—— 绝不学痴情的鸟儿， 为绿荫重复单调的歌曲； 也不止像泉源， 常年送来清凉的慰藉； 也不止像险峰， 增加你的高度，衬托你的威仪。 甚至日光。 甚至春雨。 不，这些都还不够！ 我必须是你近旁的一株木棉， 作为树的形像和你站在一起。 根，紧握在地下， 叶，相触在云里。 每一阵风过， 我们都互相致意， 但没有人， 听懂我们的言语。 你有你的铜枝铁干， 像刀，像剑， 也像戟； 我有我红硕的花朵， 像沉重的叹息， 又像英勇的火炬。 我们分担寒潮、风雷、霹雳； 我们共享雾霭、流岚、虹霓。 仿佛永远分离， 却又终身相依。 这才是伟大的爱情， 坚贞就在这里： 爱—— 不仅爱你伟岸的身躯， 也爱你坚持的位置，足下的土地。 我曾七次鄙视自己的灵魂纪伯伦【黎巴嫩】 第一次，当它本可进取时，却故作谦卑； 第二次，当它在空虚时，用爱欲来填充； 第三次，在困难和容易之间，它选择了容易； 第四次，它犯了错，却借由别人也会犯错来宽慰自己； 第五次，它自由软弱，却把它认为是生命的坚韧； 第六次，当它鄙夷一张丑恶的嘴脸时，却不知那正是自己面具中的一副； 第七次，它侧身于生活的污泥中，虽不甘心，却又畏首畏尾。 从前慢木心 记得早先少年时大家诚诚恳恳说一句 是一句清早上火车站长街黑暗无行人卖豆浆的小店冒着热气从前的日色变得慢车，马，邮件都慢一生只够爱一个人从前的锁也好看钥匙精美有样子你锁了 人家就懂了","raw":null,"content":null,"categories":[{"name":"诗词","slug":"诗词","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%97%E8%AF%8D/"}],"tags":[]},{"title":"服务器新环境配置","slug":"技术/编程/服务器新环境配置","date":"2020-11-14T07:30:26.000Z","updated":"2023-07-03T15:04:37.078Z","comments":true,"path":"2020/11/14/ji-zhu/bian-cheng/fu-wu-qi-xin-huan-jing-pei-zhi/","link":"","permalink":"http://jlutangchuan.github.io/2020/11/14/ji-zhu/bian-cheng/fu-wu-qi-xin-huan-jing-pei-zhi/","excerpt":"","text":"服务器新环境配置今天找学长又要了新的服务器账号，新机器的配置如下： GPU 两块 RTX TITAN CPU 四个 Intel(R) Xeon(R) Gold 5120 CPU @ 2.20GHz ；逻辑CPU个数 112 内存 400G 外存 8TB Ubuntu 18.04.4 LTS 重新配置一下环境，记录下配置的命令或者参考链接，方便下次配置😂 [TOC] 登录配置1. ssh key 服务器添加key，放到自己的github中 自己电脑的pubkey放到服务器中 配置方式 服务器执行ssh-keygen，然后一直回车 找到本地的pub key，塞到/home/tangchuan/.ssh/authorized_keys中，我的本地路径如下（有的可能还要chmod改下authorized_keys文件的权限，但这次我没遇到这个问题） C:\\Users\\11695\\.ssh 将ssh key和github绑定的方式自行谷歌即可 2. Vscode远程登录首先在vscode插件库中下载Remote-SSH 然后Ctrl+P打开搜索，搜&gt; ssh，添加SSH Host 输入自己的username、ip、port ssh 用户名@IP地址 -p 端口号 然后侧边远程资源管理器就有这个ip了（可能VS Code会先自动在服务器上下载Server，需要等一段时间） 3. powershell相关指令配置主要配置以下内容 terminal中添加服务器 windows terminal中Ctrl+,&#96;打开settings.json，list下插入如下片段 &#123; &quot;guid&quot;: &quot;&#123;guid&#125;&quot;, &quot;hidden&quot;: false, &quot;name&quot;: &quot;Sai Service&quot;, &quot;commandline&quot;: &quot;ssh 用户名@IP地址 -p 端口号&quot;, &quot;colorScheme&quot;: &quot;One Half Dark&quot;, // &quot;colorScheme&quot;: &quot;Argonaut&quot;, &quot;backgroundImage&quot;: &quot;图片路径&quot;, &quot;fontFace&quot; : &quot;Consolas&quot;, &quot;icon&quot;: &quot;icon路径&quot; // &quot;useAcrylic&quot; : false, // &quot;backgroundImage&quot;: false, // &quot;acrylicOpacity&quot;: 0.3 &#125;, 配好一些常用的指令 本地powershell notepad $profile，插入如下片段，这样在powershell中输入sss就会进入服务器，输入send-to-server $file就会将file传送到服务器Download文件夹下 function sss &#123; ssh 用户名@IP地址 -p 端口号 &#125; function send-to-server($file) &#123; scp -P 端口号 $file 用户名@ip地址:~/Download/ &#125; 常用软件配置Bash &amp; Zsh &amp; Tmux查看当前环境 echo $SHELL 查看系统自带哪些shell cat /etc/shells 设置默认shell chsh -s /bin/zsh .zshrc配置 alias ll=&#39;ls -alF&#39; alias la=&#39;ls -A&#39; alias l=&#39;ls -CF&#39; 查看现有主题 ls ~/.oh-my-zsh/themes 这里我配置的是p10k，效果如下，注意本地要下载好Hack字体 重新配置主题指令 p10k configure zsh插件 plugins=(git zsh-syntax-highlighting zsh-autosuggestions z extract last-working-dir) 参考链接 zsh推荐插件配置 Vim之前想把vim配置成IDE装装逼，但是感觉还是不太实用，就简单配置下吧 vim ~/.vimrc 参考 注意将下面的中文全部删除 &#39;设置编码&#39; set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 set termencoding=utf-8 set encoding=utf-8 &#39;显示行号&#39; set nu set number set cursorline set cul &#39;cursorline的缩写形式&#39; set showmatch &#39;设置Tab长度为4空格&#39; set tabstop=4 &#39;设置自动缩进长度为4空格&#39; set shiftwidth=4 &#39;继承前一行的缩进方式，适用于多行注释&#39; set autoindent &#39;总是显示状态栏&#39; set laststatus=2 &#39;显示光标当前位置&#39; set ruler filetype plugin indent on Cmake由于没有sudo权限，所以以后装软件只能自己编译了，因此cmake是必不可少的 链接 Gitgit config --global user.name [username] git config --global user.email [email] Conda下载sh文件Miniconda3-latest-Linux-x86.sh sh ./Miniconda3-latest-Linux-x86.sh 其他插件安装由于没有sudo权限，目前装插件的方法只能是git clone，解压，export的方式 cloc：统计项目代码量✅ htop：查看CPU利用率✅ tree：生成文件树✅ wget ftp://mama.indstate.edu/linux/tree/tree-1.6.0.tgz tar xzvf tree-1.6.0.tgz cd tree-1.6.0 make 然后将路径放到PATH中 Python &amp; Conda配置pip设置镜像 临时使用 pip install -i https://pypi.tuna.tsinghua.edu.cn/simple 包 Jupyter Lab配置conda install jupyterlab ipython from notebook.auth import passwd passwd() jupyter lab --generate-config c.NotebookApp.allow_root = True c.NotebookApp.open_browser = False c.NotebookApp.password = xxx sha cd ~/.jupyter vim jupyter_notebook_config.json jupyter lab --port 8249 # 虚拟环境 conda install nb_conda conda install ipykernel ipython kernel install --user --name 进入jupyter lab，允许插件，安装一些有用的插件，但是在这之前还有装一下nodejs（暂时懒得整） 虚拟环境配置创建新环境 conda create --name env python=3.6 source activate env tensroflow环境配置没验证过。。 conda create -n tensorflow python=2.7 source activate tensorflow conda install -c conda-forge tensorflow-gpu pytorch环境配置conda create -n pytorch_gpu python=3.7 source activate pytorch_gpu conda install cudatoolkit=10.2 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/linux-64/","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://jlutangchuan.github.io/tags/Ubuntu/"}]},{"title":"Stacked Cross Attention for Image-Text Matching","slug":"技术/理论/论文/Stacked-Cross-Attention-for-Image-Text-Matching","date":"2020-11-12T02:03:53.000Z","updated":"2023-07-03T15:04:37.121Z","comments":true,"path":"2020/11/12/ji-zhu/li-lun/lun-wen/stacked-cross-attention-for-image-text-matching/","link":"","permalink":"http://jlutangchuan.github.io/2020/11/12/ji-zhu/li-lun/lun-wen/stacked-cross-attention-for-image-text-matching/","excerpt":"","text":"Stacked Cross Attention for Image-Text Matching微软 SCAN主要贡献 结合并改进DVSA，VSE++，DAN三个的工作，取得了非常不错的结果 用不同于DAN的方式引入Attention机制以及采用多模态对齐提升了模型可解释性，解决了DAN只能关注固定数量attention region的问题 具体改进 DVSA：采用更强大的检测模型Faster RCNN(backbone：ResNet-101)，同时检测预训练模型不止学习检测显著对象，还要加入属性的学习（如毛茸茸、。。。） VSE++损失函数采用加入难样本挖掘的Max hinge loss，同时经过消融实验发现，该模型对于loss比较敏感，换成Sum hinge loss掉了22个点 Attention这里应该不算借鉴DAN的方法，而是从DVSA的基础上设计新的Attention机制，具体好像借鉴了《Bottom-up and top-down attention for image captioning and VQA》 这篇工作 这里展开介绍一下： 首先这个Attention对称地分成两部分Image-To-Text和Text-To-Image ；先介绍Image-To-Text的方法 如下图，在经过Faster RCNN将image划出若干个region后，Fast RCNN的第二个阶段的最后一个avg pooling层连一个fc层，产生image region的embedding，再拿这些image embeddings和word经过双向GRU后算出的word embedding进行相似度计算（这里采用cosine similarity），得到image region对word的响应矩阵（类似DVSA），算出的相应权重会经过公式3的λ-softmax在sentence上进行归一化 拿归一化后的权重对word embedding做加权求和作为sentence的相似度，这个相似度再和之前的image embedding算image region和sentence的相似度，最后拿image region和sentence的相似度做pooling得到整体的相似度。 训练时Faster RCNN部分的参数固定住，只需要学习抽image embedding的fc层以及双向GRU就行 注意这里的word embedding指的是经过双向GRU的embedding，不用训练好的embedding的原因是缺少这些训练好的embedding matrix缺少上下文信息 思考一下整个Attention过程，做了一个流程图如下 Text-To-Image的Attention同理 两种pooling方法，后续实验给出了最佳的组合配置： 结果Flickr30k MS-COCO（MS的论文居然不把MS-COCO放在第一个实验😂） 另外论文还通过attention产生的显著图进行可解释分析以及可视化，和自己要做的东西关系不大，就不放了。。","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"},{"name":"ImageTextMatching","slug":"ImageTextMatching","permalink":"http://jlutangchuan.github.io/tags/ImageTextMatching/"}]},{"title":"Pytorch学习-01","slug":"技术/编程/Pytorch学习-01","date":"2020-11-02T10:28:18.000Z","updated":"2023-07-03T15:04:37.058Z","comments":true,"path":"2020/11/02/ji-zhu/bian-cheng/pytorch-xue-xi-01/","link":"","permalink":"http://jlutangchuan.github.io/2020/11/02/ji-zhu/bian-cheng/pytorch-xue-xi-01/","excerpt":"","text":"Pytorch学习-01本次主要学习了三部分 nn.Module部分，通过看知乎上一个源码分析博客习得 pytorch梯度机制，这个主要是看一些博客然后进行总结的 Visdom，Facebook的配合pytorch的可视化工具 nn.Module方法 自定义时需要实现的方法 __init__ forward:前向传播计算,返回类型无限制 转换相关 to()：in-place改Module类型（device、dtype、non_blocking） non_blocking： device dtype device转换相关 cuda(device=None)：Moves all model parameters and buffers to the GPU cpu()：Moves all model parameters and buffers to the CPU 类型转换相关：都是进行类型转换的函数 type：指定类型转换 float double half apply与_apply _apply函数调用children()方法循环遍历一遍全部的子模型，都执行一次传入的函数；然后遍历一遍_parameters字典，也都执行一次传入的函数操作（会自行判断是否需要in-place）;对parameters.grad和buffer也执行同样的操作；这个函数一般是用来内部调用的，外部使用apply apply：递归执行传入的函数，常用来进行初始化 share_memory：将Module中的Tensor放到共享内存空间中（参数固定） 模型的保存与加载 state_dict()：拿到parameter和buffer组成的字典 load_state_dict() _save_to_state_dict() _load_from_state_dict() 获取内部属性相关方法 parameters &amp; named_parameters buffer &amp; named_buffer children &amp; named_children modules &amp; named_modules 训练相关：分别设置为训练模式和评估模式，只对特定的Module有影响：dropout、batchnorm train() eval() 梯度相关 requires_grad_():用于设置self.parameters()是否需要record梯度，默认情况下是True requires_grad:是Tensor一个属性，用于说明当前量是否需要在计算中保留对应的梯度信息，若置为False则无法进行反向传播，常用来冻结部分参数 class RESNET_MF(nn.Module): def __init__(self, model, pretrained): super(RESNET_MF, self).__init__() self.resnet = model(pretrained) for p in self.parameters(): p.requires_grad = False #预训练模型加载进来后全部设置为不更新参数，然后再后面加层 self.f = SpectralNorm(nn.Conv2d(2048, 512, 1)) self.g = SpectralNorm(nn.Conv2d(2048, 512, 1)) self.h = SpectralNorm(nn.Conv2d(2048, 2048, 1)) zero_grad():用于设置self.parameters()的gradients为零 class属性相关 常见的属性有_parameters 、_modules 、_buffers 还有若干hooks _get_name：返回类名 extra_repr：输出模块信息、需要自己实现 __repr__：输出子模块的信息 __dir__：输出属性的信息或者keys 运算调用细节相关 _slow_forward 封装forward方法 __call__ 调用_slow_forward，另外还执行了hook的运算 def __call__(self, *input, **kwargs): for hook in self._forward_pre_hooks.values(): # _forward_pre_hooks result = hook(self, input) if result is not None: if not isinstance(result, tuple): result = (result,) input = result if torch._C._get_tracing_state(): # _slow_forward -&gt; forward result = self._slow_forward(*input, **kwargs) else: result = self.forward(*input, **kwargs) for hook in self._forward_hooks.values(): # _forward_hooks hook_result = hook(self, input, result) if hook_result is not None: result = hook_result if len(self._backward_hooks) &gt; 0: # _backward_hooks var = result while not isinstance(var, torch.Tensor): if isinstance(var, dict): var = next((v for v in var.values() if isinstance(v, torch.Tensor))) else: var = var[0] grad_fn = var.grad_fn if grad_fn is not None: for hook in self._backward_hooks.values(): wrapper = functools.partial(hook, self) functools.update_wrapper(wrapper, hook) grad_fn.register_hook(wrapper) # variable hook return result 注册相关 register_parameter：加入一个新参数到module中 register_buffer：有些非网络的参数如batchnorm的mean和var add_module 钩子函数相关 通常配合isinstance(module, nn.ReLU)和model.named_children()在特定位置加入hook register_backward_hook register_forward_pre_hook register_forward_hook _register_state_dict_hook _register_load_state_dict_pre_hook Pytorch梯度记录机制torch.Tensor中有一个requires_grad属性，默认为False，决定是否反向传播计算梯度（1.若置为False其之前的都无法计算梯度；2.置为True的之后的中间变量默认都是True） 在nn.Module中的参数默认是自动计算梯度的，Module中用requires_grad_方法递归改Tensor的requires_grad属性 一个例子是冻结预训练模型参数 class RESNET_MF(nn.Module): def __init__(self, model, pretrained): super(RESNET_MF, self).__init__() self.resnet = model(pretrained) for p in self.parameters(): p.requires_grad = False #预训练模型加载进来后全部设置为不更新参数，然后再后面加层 self.f = SpectralNorm(nn.Conv2d(2048, 512, 1)) self.g = SpectralNorm(nn.Conv2d(2048, 512, 1)) self.h = SpectralNorm(nn.Conv2d(2048, 2048, 1)) torch.no_grad(): 将下文Tensor、Module的requires_grad都置为空，常用于冻结权值、eval with torch.no_grad(): ... optimizer.zero_grad() &amp; model.zero_grad() 将self.parameters()的gradients置零，因为在计算图反向传播过程中必须用+&#x3D;而不是赋值来算梯度 torch.Tensor.backward()：tensor执行反向传播 retain_graph参数 If False, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Defaults to the value of create_graph. optimizer.step() : 参数更新 optimizer.zero_grad() loss.backward() optimizer.step() Performs a single optimization step (parameter update). torch.detach() 返回一个新的Variable，从当前计算图中分离下来的，但是仍指向原变量的存放位置,不同之处只是requires_grad为false，得到的这个Variable永远不需要计算其梯度，不具有grad。 Visdomvisdom是FB的，所以对pytorch会更友好一些；并且可以通过visdom显示matplotlib的图片 启动python3 -m visdom.server 文字vis.text(&#39;Hello World&#39;, win=&#39;text1&#39;, append=True) 绘制单条折线图win：某个窗格id env：某个大标签栏id 默认为main vis.line(y, x, win, env, opts=&#123;title:&quot;title_name&quot;&#125;) 绘制多条折线图 绘制图片好处是不用转化成numpy数据就可以传到visdom里面 Reference pytotch源码分析 hook detach用法 visdom可视化","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jlutangchuan.github.io/tags/Pytorch/"}]},{"title":"PRML-概率分布","slug":"技术/理论/机器学习/PRML-概率分布","date":"2020-10-29T14:23:56.000Z","updated":"2023-07-03T15:04:37.089Z","comments":true,"path":"2020/10/29/ji-zhu/li-lun/ji-qi-xue-xi/prml-gai-lu-fen-bu/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/29/ji-zhu/li-lun/ji-qi-xue-xi/prml-gai-lu-fen-bu/","excerpt":"","text":"PRML-概率分布参数估计 少量可调节的参数控制了整个概率分布 共轭分布将以前学的MLE改为MAP进行参数估计，可以加入先验知识帮助估计参数。 用MAP进行参数估计涉及到先验概率与后验概率分布形式是否一致的问题。当分布形式一致时，若出现新的观测数据，后验概率可以扮演先验概率，并且数学形式仍一致。 参数估计时后验概率分布与先验概率分布的形式相同 似然函数 共轭分布 二项分布 Beta分布 多项式分布 Dirichlet分布 Gaussian , Given variance, mean unknown 高斯分布 Gaussian, Given mean, variance unknown Gamma 分布 Gaussian, both mean and variance unknown Gaussian-Gamma分布 二项分布&amp;Beta分布$$Beta(\\mu|a,b)&#x3D;\\frac{\\Gamma(a+b)}{\\Gamma(a)\\cdot \\Gamma(b)}\\mu^{a-1}(1-\\mu)^{b-1}$$ Gamma函数 这里的Gamma函数主要是通过算归一化推导出的 多项式分布&amp;Dirichlet分布可以看作二项分布的推广 迪利克雷分布 高斯分布和前面介绍的两个共轭分布不同，前面两个的观测数据是离散的，而现在要解决连续值的观测数据；另外，高斯分布的参数量也比前面两个要大，高斯分布的参数量的规模是N^2的。 不过他们的共同点是这些分布都是观测结果的指数形式，后面会归纳这一类分布族（指数族分布） 一元高斯分布 设计： 归一化 关于期望分布对称（平方） 共轭性质（指数） 多元高斯分布 单数据点马氏距离的平方(1. 尺度无关 2. 主成分空间各维度独立)$$\\Delta^2&#x3D;(x-\\mu)^T\\Sigma^-1(x-\\mu)$$ 对于协方差矩阵（实对称矩阵），可以找出其单位正交的特征向量，并且协方差矩阵还可以写成下述形式： 因此，Gaussian Distribution的指数部分可以改写成 高斯概率分布公式分母部分的行列式可以改写 如此，整个公式改写为 y表示主成分空间中的量，其各个变量之间是独立的，整体的概率分布可以写成单个概率分布的乘积 也可以证明多元高斯分布的一些性质： 积分为1 期望与协方差 高斯分布存在的问题： 参数量大，协方差矩阵，估计和计算都比较麻烦：解决方法是限制协方差矩阵的形式 unimodal（单峰）：解决方法是引入隐变量，构造高斯混合模型 条件高斯分布&amp;边缘高斯分布 仍旧是考虑两个多元变量的关系，比如两个多元变量假定服从线性关系$$y&#x3D;Ax+b$$而且$p(x)$和$p(y|x)$又已知，可表示为： 由此可以求出y的分布以及x的条件分布 贝叶斯概率下的高斯分布参数估计这里以一元的高斯分布解释 注意方差倒数（精度）在加入观测前后的变化，具有加和的性质，也就是观测数据越多，精度越大，方差是恒递减的。 指数族分布 指数族分布有：高斯分布、伯努利分布、二项分布、泊松分布、beta分布、Dirichlet分布、gamma分布等 分布族形式$$P(x|\\eta)&#x3D;h(x)e^{\\eta^{T} \\Phi(c)-A(\\eta)}$$ $A(\\eta)$：log partition function(log配分函数：主要是做归一化的) $\\Phi(x)$：充分统计量（统计量：对于样本的函数），充分表示具有完整表达样本信息来进行参数估计 共轭指数族分布一般都具有共轭的性质 最大熵原理（无信息先验）对未知的参数假定分布等可能（熵值最大） logistic sigmoid &amp; softmax 对于伯努利分布，可以写成指数族分布的通用形式$$P(x|\\mu)&#x3D;(1-\\mu)\\exp(ln(\\frac{\\mu}{1-\\mu})x)$$做变量替换$\\eta&#x3D;ln(\\frac{\\mu}{1-\\mu})$$$p(x|\\mu)&#x3D;\\frac{1}{1+exp(-\\eta)}\\exp(\\eta x)$$可以看到配分函数就是logistic函数 同样考察多项式分布，其配分函数为softmax函数 非参数化方法 form of distribution typically depends on the size of the data set. Such models still contain parameters, but control the model complexity rather than the form of the distribution. 直方图 核密度估计 近邻方法 Reference https://www.cnblogs.com/nxf-rabbit75/p/10381691.html 白板推导-指数族分布","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://jlutangchuan.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://jlutangchuan.github.io/tags/MachineLearning/"},{"name":"PRML","slug":"PRML","permalink":"http://jlutangchuan.github.io/tags/PRML/"}]},{"title":"Deep Cross-Modal Projection Learning for Image-Text Matching","slug":"技术/理论/论文/Deep-Cross-Modal-Projection-Learning-for-Image-Text-Matching","date":"2020-10-25T09:29:42.000Z","updated":"2023-07-03T15:04:37.101Z","comments":true,"path":"2020/10/25/ji-zhu/li-lun/lun-wen/deep-cross-modal-projection-learning-for-image-text-matching/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/25/ji-zhu/li-lun/lun-wen/deep-cross-modal-projection-learning-for-image-text-matching/","excerpt":"","text":"Deep Cross-Modal Projection Learning for Image-Text Matching ECCV 2018 Question 是否有论文用Attention来做这件事？DAN（那我们这个思路还有什么意义？） 如何进行解释？Grad-CAM等方法如何融入其中？ 训练过程的样本选择这篇论文没讲 Case Study（感觉预训练的分类网络只有对象的判别能力，没有相对位置的识别能力，可以用一对位置相反的对象图来验证这个事） 这个问题感觉能改的地方主要在跨模态的loss设计以及样本选择上 TODO Learning deep structure-preserving image-text embeddings paper reading Dual attention networks for multimodal reasoning and matching paper reading Finding beans in burgers: Deep semantic-visual embedding with localization paper reading 本文工作 提出两个loss（跨模态投影匹配损失 CMPM loss； 跨模态投影分类损失 CMPC loss）来学到更有判别性的嵌入表示，提升匹配精度 Related Work目前采用深度学习进行图像描述匹配的方法可以分成两类： 联合嵌入表示学习 寻找公共隐空间 correlation loss bi-directional ranking loss：基于三元组损失（所以主要问题是负样本选择于margin值的设置） DCCA（深度典型相关分析）：存在的问题是每个minibatch的协方差估计不稳定 成对相似度学习 直接学习如何判别两者是否匹配 这部分研究也分成两部分 全局相似度：直接判别图像与描述的相似度 局部相似度，对齐描述中的文字与图像切片内容 现有的学习joint embedding的方法（4个）： Learning deep structure-preserving image-text embeddings（cvpr 2016） Learning two-branch neural networks for image-text matching tasks（TPAMI 2018） Deep correlation for matching images and text（CVPR 2015） Learning a recurrent residual fusion network for multimodal matching（ICCV 2017） 这些方法都是采用学习图片和描述在隐空间中的联合嵌入表示或者建立一个相似度学习网络（直接算相似度得分），其中前者效果要好（速度快，效果好） 这些方法的机制图如下 通常的流程 首先图片和描述各自抽取嵌入表示 接下来使用精心设计的目标函数将原始embedding转化成discriminative cross-modal embeddings ​ 常用的函数如：CCA（canonical correlation analysis）、bi-directional ranking loss identity-level annotations cross-modal matching method Learning deep representations of finegrained visual descriptions（CVPR 2016） Identity-aware textual-visual matching with latent co-attention（ICCV 2017） 两阶段训练方法，先用CMCE loss训一下，然后fine-tune Person search with natural language description（2017 CVPR） 提出跨模态交叉熵（CMCE） 对于深度度量学习，研究的最热的当然是人脸识别和ReID问题主要有两派： Softmax loss的各种变体损失 三元组loss的各种变体损失 度量学习存在的主要问题： 样本选择（如三元组损失中的正负样本对的选择比较有讲究） 模型对于margin参数比较敏感 对于多模态问题前面的方法不一定很适用 预备知识CCA 典型相关分析 常见度量学习损失 人脸识别中Softmax-based Loss的演化史 t-SNE t-SNE原理与推导 CSDN Method网络结构和前面的机制图一样，一个CNN、一个Bi-LSTM、一个联合学习模块 backbone： MobileNet Bi-LSTM LossCMPM loss &gt; 最小化KL散度（projection compatibility distributions and the normalized matching distributions） CMPC loss &gt; categorize the vector projection of representations from one modality onto another with the improved norm-softmax loss CMPM Loss预测匹配概率p 这里图片特征与描述特征的内积越大表示x在z上的投影长度大，表示两者的相似度越高；其中z为归一化的描述产生的特征向量。当图像i与描述j匹配时，p趋近于1&#x2F;c（c个对应i的描述），其他不匹配的趋近于零 真实分布q 用来对匹配概率进行规范化，使得mini-batch中某个有多个图片-描述对的图片权值（也可以看成是某个图片i对于batch中所有描述是否匹配的分布） 损失 总的损失可以看成预测分布p与真实分布q的KL散度，其中$\\epsilon$用来防止除0的。 Note 为什么是KL(p||q)，而不是KL(q||p)? 因为q本身的分布不是one-hot型的，CE Loss会让p中高概率的值逼近q的值，但是q的值由于不是1，所以逼近的效果不太好（感觉这是建模成KL散度的问题，反过来也不能解决这个问题） “will be further demonstrated in experiments.” bi-directional CMPM loss 在训练中是同时考虑image2text和text2image的，即CNN得到的图片表示和LSTM学到的文本表示都要主动转变到对方的空间中。 CMPC Loss在loss上加入分类损失的目的是帮助每个模态学到的特征更具有判别性 具体细节 提出了一个norm-softmax loss来改进softmax loss，就是将权值的范数限制为1。然后仍旧是两个loss 在inference阶段，首先用各自的模型去抽取特征，然后计算特征之间的余弦距离 实验结果数据集 Flickr30k MSCOCO CUHK-PEDES Caltech-UCSD Birds Oxford102 Flowers 评估 Recall AP@50 结果 DAN要看一下😂 此外还做了消融实验来分析两个loss的贡献，但是用的数据集比较小。 还比较了KL散度方面的内容，并且调节不同的batch size大小，说明他们的loss设计得更好，而且CMPM+CMPC的loss对batch size也更不敏感。 特征可视化 想看看抽取的特征是否能直观地看出有判别能力，使用t-SNE进行降维","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"},{"name":"ImageTextMatching","slug":"ImageTextMatching","permalink":"http://jlutangchuan.github.io/tags/ImageTextMatching/"}]},{"title":"Web可视化包Dash学习","slug":"技术/编程/Web可视化包Dash学习","date":"2020-10-19T13:00:10.000Z","updated":"2023-07-03T15:04:37.071Z","comments":true,"path":"2020/10/19/ji-zhu/bian-cheng/web-ke-shi-hua-bao-dash-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/19/ji-zhu/bian-cheng/web-ke-shi-hua-bao-dash-xue-xi/","excerpt":"","text":"Web可视化包Dash学习打算复现Grad-CAM，但是感觉服务器上的话不用jupyter搞可视化有点麻烦，用jupyter的话不适合搞代码量大的程序，所以干脆找找有没有解决我这个需求的工具，于是就找到了dash这个框架。 Dash是一个用于构建Web应用程序的高效Python框架。 Dash写在Flask，Plotly.js和React.js之上，非常适合在纯Python中，使用高度自定义的用户界面，构建数据可视化应用程序。它特别适合使用Python进行数据分析的人。 但是要学这个就要学下他们家的可视化库Plotly，学习成本不大，于是就决定入坑。 Outline 搭建基本框架 可视化图的尝试 交互 自己定制的UI 基本框架Flask有个优点是实时渲染，边改代码边看样式（双屏打开😁） import dash import dash_core_components as dcc import dash_html_components as html import plotly.express as px import pandas as pd # css样式 external_stylesheets = [&#39;https://codepen.io/chriddyp/pen/bWLwgP.css&#39;] # 实例化一个dash.Dash app = dash.Dash(__name__, external_stylesheets=external_stylesheets) # assume you have a &quot;long-form&quot; data frame # see https://plotly.com/python/px-arguments/ for more options # DataFrame数据 df = pd.DataFrame(&#123; &quot;Fruit&quot;: [&quot;Apples&quot;, &quot;Oranges&quot;, &quot;Bananas&quot;, &quot;Apples&quot;, &quot;Oranges&quot;, &quot;Bananas&quot;], &quot;Amount&quot;: [4, 1, 2, 2, 4, 5], &quot;City&quot;: [&quot;SF&quot;, &quot;SF&quot;, &quot;SF&quot;, &quot;Montreal&quot;, &quot;Montreal&quot;, &quot;Montreal&quot;] &#125;) # plotly绘制条形图 fig = px.bar(df, x=&quot;Fruit&quot;, y=&quot;Amount&quot;, color=&quot;City&quot;, barmode=&quot;group&quot;) # 设置布局 app.layout = html.Div(children=[ html.H1(children=&#39;Hello Dash&#39;), html.Div(children=&#39;&#39;&#39; Dash: A web application framework for Python. &#39;&#39;&#39;), dcc.Graph( id=&#39;example-graph&#39;, figure=fig ) ]) if __name__ == &#39;__main__&#39;: # 类似Flask开启server # server # host 0.0.0.0 # port 8033 不跟其他人冲突就好-。- app.run_server(debug=True) 常用组件 Div H1 Table # 定义表格组件 def create_table(df, max_rows=12): &quot;&quot;&quot;基于dataframe，设置表格格式&quot;&quot;&quot; table = html.Table( # Header [ html.Tr( [ html.Th(col) for col in df.columns ] ) ] + # Body [ html.Tr( [ html.Td( df.iloc[i][col] ) for col in df.columns ] ) for i in range(min(len(df), max_rows)) ] ) return table Markdown dcc.Markdown 交互组件 见https://dash.plotly.com/dash-core-components","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"},{"name":"可视化","slug":"可视化","permalink":"http://jlutangchuan.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"}]},{"title":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization","slug":"技术/理论/论文/Grad-CAM-Visual-Explanations-from-Deep-Networks-via-Gradient-based-Localization","date":"2020-10-19T01:27:49.000Z","updated":"2023-07-03T15:04:37.106Z","comments":true,"path":"2020/10/19/ji-zhu/li-lun/lun-wen/grad-cam-visual-explanations-from-deep-networks-via-gradient-based-localization/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/19/ji-zhu/li-lun/lun-wen/grad-cam-visual-explanations-from-deep-networks-via-gradient-based-localization/","excerpt":"","text":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization中文名：梯度加权的类激活图 produce a coarse localization map highlighting the important regions in the image for predicting the concept 主要工作 Grad-CAM应用到：图像分类、图像描述、VQA问题中 判断哪些神经元是重要的(use neuron importance from Grad-CAM and obtain textual explanations) Guide Grad-CAM 背景先前的CAM只能使用最后为GAP的CNN，不能适用含有fc层(VGG)、结构输出(caption)、多输入(VQA)、强化学习还有without architectural changes or re-training等类型的模型 对于可解释模型的观点： 当AI弱于人类时，通过解释识别错误模式，帮助研究者进行更深入地分析 当AI与人类能力相近时，可解释模型能提升模型的可信度 当AI强于人类时，可解释模型能教人类如何做更好的决策 分类任務中Grad-CAM用途 对分类错误的图片进行可视化 作为弱监督检测，效果不错 对于对抗扰动具有一定的鲁棒性 提升了模型的可信度 通过识别数据集偏差帮助实现模型泛化 对于VQA、Image Caption问题，提供了一个不用注意力模型的弱监督方法 相关工作 Guided Backpropagation [53] and Deconvolution [57]这两个方法能做到高分辨率、细粒度的可视化，但是不具有类可判别的能力 CNN可视化（这些方法的共同缺点是都不具有类可判别性） Deep inside convolutional networks: Visualising image classification models and saliency maps. 可视化预测分数的偏导 Striving for Simplicity: The All Convolutional Net Guided Backpropagation Visualizing and understanding convolutional networks Deconvolution Devnet: A deep event network for multimedia event detection and evidence recounting Salient deconvolutional networks 这篇论文对前面的一系列工作做了比较 此外还有一些方法如：最大激活网络单元、隐空间转换这些方法不是对图像的可视化，而是对模型进行可视化 模型可信度评估 弱监督检测（任务描述：只是用图像中对象的类别标签学习对象定位问题） CAM GAP、log-sum-exp pooling 其他方法 通过遮挡斑块等干扰输入方法看哪些区域对于目标类别有较大影响（Grad-CAM相比于这些方法来说更简洁“one shot”） w.r.t. : with respect to 关于;谈及,谈到 Grad-CAM &amp; Guided Grad-CAMclass-discriminative localization map 反向传播得到的特征图进行求和，然后和前向运算的结果进行加权求和，最后过一个ReLU得到Grad-CAM Guided Grad-CAM是Grad-CAM与Guided Backprop进行逐元素乘得到的结果 权重计算的数学形式 Grad-CAM的数学形式 Q&amp;A使用ReLU的原因 we are only interested in the features that have a positive influence on the class of interest without this ReLU, localization maps sometimes highlight more than just the desired class and perform worse at localization(后面有消融实验解释了这一点) 为什么不用低层的卷积层做Grad-CAM? We find that Grad-CAM maps become progressively worse as wemove to earlier convolutional layers as they have smaller receptive fields and only focus on less semantic local features. 为什么梯度求和的Grad-CAM是CAM方法的泛化? 推导发现GAP时,梯度求和结果与权重相等 Guided Grad-CAM有什么用途 Grad-CAM在算完location map后，需要resize到224x224，但是这样相当于location map的分辨率停留在14x14，因此，有必要用Guided Grad-CAM进行更高分辨率的解释 Evluation实验做的很多,有定性的有定量的,但是没什么信息量。 弱监督检测与分割任务 消融实验 没有最后的ReLU,error涨了15个点","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"}]},{"title":"近期想记录的诗(10.18)","slug":"诗词/近期想记录的诗-10-18","date":"2020-10-18T15:05:18.000Z","updated":"2023-07-03T15:04:36.955Z","comments":true,"path":"2020/10/18/shi-ci/jin-qi-xiang-ji-lu-de-shi-10-18/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/18/shi-ci/jin-qi-xiang-ji-lu-de-shi-10-18/","excerpt":"","text":"近期想记录的诗(10.18) 咏素蝶诗刘孝绰【南朝】 随蜂绕绿蕙，避雀隐青薇。映日忽争起，因风乍共归。出没花中见，参差叶际飞。芳华幸勿谢，嘉树欲相依。 咏蟹皮日休 【唐】 未游沧海早知名， 有骨还从肉上生。 莫道无心畏雷电， 海龙王处也横行。 旅程汪国真 意志倒下的时候生命也就不再屹立歪歪斜斜的身影又怎耐得秋叶萧瑟 晚来风急 垂下头颅只是为了让思想扬起你若有一个不屈的灵魂脚下，就会有一片坚实的土地 无论走向何方都会有无数双眼睛跟随着你从别人那里我们认识了自己","raw":null,"content":null,"categories":[{"name":"诗词","slug":"诗词","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%97%E8%AF%8D/"}],"tags":[]},{"title":"Parse库介绍","slug":"技术/编程/Parse库介绍","date":"2020-10-10T10:29:26.000Z","updated":"2023-07-03T15:04:37.047Z","comments":true,"path":"2020/10/10/ji-zhu/bian-cheng/parse-ku-jie-shao/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/10/ji-zhu/bian-cheng/parse-ku-jie-shao/","excerpt":"","text":"Parse库介绍介绍一个看到的python第三方库parse，主要用途是代替正则表达式做字符匹配的 正则表达式通常被用来做模板匹配等字符任务，其缺点是规则缺少语义解释不好长时间记忆，表达式的可读性很差。 于是今天学习一个相对简单的第三方库parse，当然，这个parse也没有re一样强大全面的功能、应该说各有利弊。 Outline parse常见需求分析 parse使用方法解析 parse返回结果分析 常见需求分析 当需要接收传进来的长字符串中包含的部分数据，可以用一个写好的规则(pattern)来检测这个字符串 当判断某个字符串是否符合某个格式时也可以用这种方法（以前都是用split进行的😁） 某个pattern需要被重复利用 直接对提取的内容进行类型转化(int datetime float …) 去除匹配得到的信息前后的空格 控制匹配时的大小写敏感 限制匹配内容的长度（匹配字符数） 使用方法说明 基本用法 from parse import * profile = parse(&quot;I am &#123;&#125;, &#123;&#125; years old, &#123;&#125;&quot;, &quot;I am Jack, 27 years old, male&quot;) profile # &gt;&gt;&gt; &lt;Result (&#39;Jack&#39;, &#39;27&#39;, &#39;male&#39;) &#123;&#125;&gt; parse.parse方法的第一个参数是模板，第二个参数是目标字符串 当&#123;&#125;内无参数名时，返回的对象可以看作一个list，profile[0]即可取得内容 当&#123;param&#125;内有参数名时，有参数名的内容构成一个dict、无参数名的内容构成一个list。也就是同时可以用[idx]、[key]来调结果 profile = parse(&quot;I am &#123;name&#125;, &#123;age&#125; years old, &#123;gender&#125;&quot;, &quot;I am Jack, 27 years old, male&quot;) # &gt;&gt;&gt; &lt;Result () &#123;&#39;gender&#39;: &#39;male&#39;, &#39;age&#39;: &#39;27&#39;, &#39;name&#39;: &#39;Jack&#39;&#125;&gt; pattern重复利用 将pattern字符串用compile接收 from parse import compile pattern = compile(&quot;I am &#123;&#125;, &#123;&#125; years old, &#123;&#125;&quot;) pattern.parse(“I am Jack, 27 years old, male”) 3. 内置类型转换方法 `&#123;:d&#125;`表示转化为整数，其他的也是`&#123;param:type&#125;`这样进行转化的 ```python profile = parse(&quot;I am &#123;name&#125;, &#123;age:d&#125; years old, &#123;gender&#125;&quot;, &quot;I am Jack, 27 years old, male&quot;) 下面时type的具体内容以及解释 | Type | Characters Matched | Output | |------|--------------------------------------------------------------------------------------|----------| | l | Letters \\(ASCII\\) | str | | w | Letters, numbers and underscore | str | | W | Not letters, numbers and underscore | str | | s | Whitespace | str | | S | Non\\-whitespace | str | | d | Digits \\(effectively integer numbers\\) | int | | D | Non\\-digit | str | | n | Numbers with thousands separators \\(, or \\.\\) | int | | % | Percentage \\(converted to value/100\\.0\\) | float | | f | Fixed\\-point numbers | float | | F | Decimal numbers | Decimal | | e | Floating\\-point numbers with exponent e\\.g\\. 1\\.1e\\-10, NAN \\(all case insensitive\\) | float | | g | General number format \\(either d, f or e\\) | float | | b | Binary numbers | int | | o | Octal numbers | int | | x | Hexadecimal numbers \\(lower and upper case\\) | int | | ti | ISO 8601 format date/time e\\.g\\. 1972\\-01\\-20T10:21:36Z \\(“T” and “Z” optional\\) | datetime | | te | RFC2822 e\\-mail format date/time e\\.g\\. Mon, 20 Jan 1972 10:21:36 \\+1000 | datetime | | tg | Global \\(day/month\\) format date/time e\\.g\\. 20/1/1972 10:21:36 AM \\+1:00 | datetime | | ta | US \\(month/day\\) format date/time e\\.g\\. 1/20/1972 10:21:36 PM \\+10:30 | datetime | | tc | ctime\\(\\) format date/time e\\.g\\. Sun Sep 16 01:03:52 1973 | datetime | | th | HTTP log format date/time e\\.g\\. 21/Nov/2011:00:07:11 \\+0000 | datetime | | ts | Linux system log format date/time e\\.g\\. Nov 9 03:37:44 | datetime | | tt | Time e\\.g\\. 10:21:36 PM \\-5:30 | time | 去除无关空格 parse(&#39;hello &#123;:^&#125; , hello python&#39;, &#39;hello world , hello python&#39;) # &gt;&gt;&gt; &lt;Result (&#39;world&#39;,) &#123;&#125;&gt; 开关大小写敏感 parse默认是不区分大小写的匹配，case_sensitive=True即开启大小写敏感 parse(&#39;SPAM&#39;, &#39;spam&#39;, case_sensitive=True) 限制匹配字符数 target = &quot;http://jlu.edu.cn/username=55161115&amp;password=xxx/u12g3evbhjv2uyv23&quot; pattern = &quot;http://jlu.edu.cn/username=&#123;user:.8&#125;&amp;&#123;&#125;&quot; # 要求user必须小于等于8位，否则返回结果为None # pattern = &quot;&#123;&#125;username=&#123;username&#125;&amp;password=&#123;password&#125;/&#123;&#125;&quot; parse(pattern, target) 返回结果返回结果是一个result对象，有三个属性：fixed、named、spans fixed储存无参数名的匹配结果 &#x3D;&#x3D;&gt; list named储存有参数名的匹配结果 &#x3D;&#x3D;&gt; dict spans储存匹配位置信息 &#x3D;&#x3D;&gt; list Reference 再见，正则表达式 pypi-parse","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"python debug","slug":"技术/编程/python-debug","date":"2020-10-08T13:26:25.000Z","updated":"2023-07-03T15:04:37.051Z","comments":true,"path":"2020/10/08/ji-zhu/bian-cheng/python-debug/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/08/ji-zhu/bian-cheng/python-debug/","excerpt":"","text":"python debugdebug方法千千万，分析一下这些可以分成哪几类？ 直接看报错结果：比较清晰看到出错位置 鸵鸟算法。。。 抛出异常 logging 中途print：要求知道出错地方大致在哪里 print assert 控制 IDE 断点调试 pdb Outline assert介绍 logging介绍 pdb介绍（ipdb为增强版pdb） Assertassert expression [, arguments] assert condition &quot;sentence&quot; 判断条件是否成立，如果不成立，则打印后面的句子并且结束程序 等价于 if not expression: raise AssertionError eg import sys assert (&#39;linux&#39; in sys.platform), &quot;该代码只能在 Linux 下执行&quot; Logging基础介绍logging是系统内置库，可以看作print的plus版，对于大一些的项目logging比print更合适。 logging日志有级别，在开发时可以打印所有的信息，帮助我们进行debug等；在项目上线时可能只需要打印info以上的信息。这种分级的打印减少开发与部署之间代码的改动 import logging # 引入logging模块 # 将信息打印到控制台上 logging.debug(u&quot;aaa&quot;) logging.info(u&quot;bbb&quot;) logging.warning(u&quot;ccc&quot;) logging.error(u&quot;ddd&quot;) logging.critical(u&quot;fff&quot;) 默认只打印warning以及以上的内容，手动设置级别只需简单配置一下 logging.baseConfig(level=logging.DEBUG) 需要注意的是，logging打印出的日志信息与print打印的信息在控制台上的顺序和代码中的顺序不一定是一致的，因为logging要控制并发的日志做了并发的处理；但是logging自己的打印信息顺序是正常的 更多功能 输出到指定文件中(但此时不会显示在控制台中)（默认下次运行会追加内容） logging.baseConfig(filename=&#39;debug.log&#39;, level=logging.DEBUG) # 参数介绍 # filemode: 写入模式 w a # format = &quot;%&#123;asctime&#125;s|%&#123;levelname&#125;s|%&#123;filename&#125;s:%&#123;lineno&#125;s|%&#123;message&#125;s&quot; # datefmt = &quot;%Y-%m-%d %H:%M:%S&quot; 当出现错误时用try except来接住错误，并使用logging记录下来（用这种方法相比于直接看结果的缺点是缺少回溯信息） try: xxx except Exception as e: print(&#39;Error:&#39;,e) print(e.args) print(e.with_traceback()) # Traceback logging.critical(e) 若想打印回溯信息 e.with_traceback() pdbpdb是一种替代IDE在控制台进行调试的方法 pdb 模块定义了一个交互式源代码调试器，用于 Python 程序。它支持在源码行间设置（有条件的）断点和单步执行，检视堆栈帧，列出源码列表，以及在任何堆栈帧的上下文中运行任意 Python 代码。它还支持事后调试，可以在程序控制下调用。调试器的提示符是 (Pdb) 有两种使用方法 侵入式：在python代码中加入pdb import pdb pdb.set_trace() # 基本类似于设断点 非侵入式：不用额外修改源代码，在命令行下直接运行就能调试 python -m pdb xxx.py 进入pdb调试界面后使用命令进行设断点、单步调试、打印变量等进一步调试 命令 使用方法 作用 h h or h 【cmd】 查看帮助 b b 3 b filename:line_no b line_no （第三行）设置断点 b b function 在函数function的第一条可执行语句处添加断点 tbreak - 临时断点，在第一次命中时会自动删除。它的参数与 break 相同 l l 打印当前环境上下文代码 n n c c 继续执行（当后面存在断点时会再次暂停） cl - 清除断点 s s 执行下一条命令（step） r r 继续运行，直到当前函数返回（return） n n 执行下一条语句（next） 【cmd】 - 像ipython一样控制程序 a a （args）列出当前执行函数的参数，查看函数参数 p p （print）输出expression的值，打印变量值 q q 推出debug","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"近期看到的三首小诗(10.06)","slug":"诗词/近期看到的三首小诗-10-06","date":"2020-10-06T14:25:29.000Z","updated":"2023-07-03T15:04:36.957Z","comments":true,"path":"2020/10/06/shi-ci/jin-qi-kan-dao-de-san-shou-xiao-shi-10-06/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/06/shi-ci/jin-qi-kan-dao-de-san-shou-xiao-shi-10-06/","excerpt":"","text":"近期看到的三首小诗(10.06) 送前卫县李宷少府 淮上喜会梁州故人 绮怀其十五 送前卫县李宷少府高适 唐 黄鸟翩翩杨柳垂，春风送客使人悲。怨别自惊千里外，论交却忆十年时。云开汶水孤帆远，路绕梁山匹马迟。此地从来可乘兴，留君不住益凄其。 淮上喜会梁州故人韦应物 唐 江汉曾为客，相逢每醉还。浮云一别后，流水十年间。欢笑情如旧，萧疏鬓已斑。何因不归去？淮上有秋山。 绮怀其十五黄景仁 清 几回花下坐吹箫，银汉红墙入望遥。似此星辰非昨夜，为谁风露立中宵。缠绵思尽抽残茧，宛转心伤剥后蕉。三五年时三五月，可怜杯酒不曾消。","raw":null,"content":null,"categories":[{"name":"诗词","slug":"诗词","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%97%E8%AF%8D/"}],"tags":[]},{"title":"Towards Explainable Artificial Intelligence","slug":"技术/理论/论文/Towards-Explainable-Artificial-Intelligence","date":"2020-10-06T10:27:34.000Z","updated":"2023-07-03T15:04:37.123Z","comments":true,"path":"2020/10/06/ji-zhu/li-lun/lun-wen/towards-explainable-artificial-intelligence/","link":"","permalink":"http://jlutangchuan.github.io/2020/10/06/ji-zhu/li-lun/lun-wen/towards-explainable-artificial-intelligence/","excerpt":"","text":"Towards Explainable Artificial Intelligence摘要 (Deep Learining) not providing any information about what exactly makes them arrive at their predictions 一、介绍AI遇到的挑战（对抗样本不鲁棒、缺少可解释性） the lack of robustness to adversarial attacks which pose a severe security risk in application such as autonomous driving the lack of transparency and explainability, which reduces the trust in and the verifiability of the decisions made by an AI system 本文主要想讨论第二点：the lack of transparency and explainability 可解释性不仅能向人们解释AI做出决策的原因，更可能的是产生新的知识。 The remainder of the paper is organized as follows. Section 1.2 discusses the need for transparency and trust in AI. Section 1.3 comments on the different types of explanations and their respective information content and use in practice. Recent techniques of explainable AI are briefly summarized in Sect. 1.4, including methods which rely on simple surrogate functions, frame explanation as an optimization problem, access the model’s gradient or make use of the model’s internal structure. The question of how to objectively evaluate the quality of explanations is addressed in Sect. 1.5. The paper concludes in Sect. 1.6 with a discussion on general challenges in the field of explainable AI. 二、Need for Transparency and Trust in AI现实需求 Case 1:当AI发生判断错误时候，需要可解释性来告诉我们为什么AI会判断出错Clever Hans AI在学习中，会将一些共现信息当作识别对象；比如：看到水就识别出船只、看到铁轨就识别出火车、甚至看到水印就识别出马 The occurrence of the copyright tags in horse images is a clear artifact in the dataset, which had gone unnoticed to the organizers and participants of the challenge for many years. 这说明数据对于AI学习的影响非常大，而且我们很难在一开始去消除训练数据中所有的共现信息。 对于极端case，可解释性能帮助我们展示检测器的misbehaviour Case 2: 可解释性帮助提升模型的可信度如何提升模型可信度？ 提供决策的原因、过程 更好的与人进行交互（explanations help to build trust in a relationship between humans） Case3: 解释是洞察新事物的先决条件 AI systems have the potential to discover patterns in data, which are not accessible to the human expert. 以围棋为例，可以通过可解释AI发现新的决策、新的见解。 Case4: 可解释性可以为AI立法、伦理做支撑 Anti-discrimination and fairness aspects 要求AI在做出判断时需要给出决策原因（增强AI模型的透明度） 三、解释方法从信息内容、接收者、目的三个角度进行AI可解释性研究 1 Recipient向不同的对象进行解释需要准备不同的内容以及详细程度，这里想讨论XAI模型向哪些对象进行解释。 对于图片分类任务，给用户解释判断原因可能只需要高亮目标区域 对于模型的开发人员，可能需要展示尽可能多的更有用、更细粒度的信息；因为只有这些完整的信息才能提供对模型功能的详细了解。 2 Information Content介绍了四种不同的解释方式 Explaining learned representations 比如分析训练好的网络中神经元的可解释性 比如对于分类模型，可以通过让模型生成该类别原型图片来分析模型是否真正学到了判别此类别 Explaining individual predictions heatmaps visualizing（highlighting the most sensitive parts of an input） Layer-wise Relevance Propagation(LRP) Explaining model behavour 解释模型的整体表现，可以对全部个体的解释做统计，进而得出对模型表现的更普遍的分析 Explaining with representative examples 从训练样本集中选择有代表性的样本，这种类型的解释对于更好地理解训练数据集以及它如何影响模型是有用的；此外，这些代表性的样本可以潜在地帮助识别数据中的偏差，使模型对训练数据集的变化更加稳健。 3 Role在XAI中，有一个问题是解释方法与我们真正想探究的内容不一致，因此本节主要想从这两个观点进行分析： 某种解释方法的意图（what specific question does the explanation answer?） 我们真正想探究的问题（what do we want to use the explanation for?） Explanations are relative and it makes a huge difference whether their intent is to explain the prediction as is, whether they aim to visualize what the model “thinks” about a specific class, or whether they explain the prediction relative to another alternative. 此外，解释的目的还可以是提升模型的性能（提升判别能力、模型压缩、修剪） 四、可解释模型方法介绍了四种模型可解释方法 利用替代模型进行可解释性分析 用可解释性高的模型解释黑盒模型（LIME） 可视化局部扰动 包括三种：基于梯度信息、基于局部扰动、基于优化的方法 基于梯度信息的可解释性分析方法（如灵敏度分析）存在的问题：gradient shattering and explanation discontinuities 基于模型扰动的可解释性分析：很难做出进一步的解释 基于传播的方法 代表工作：Layer-wise Relevance Propagation (LRP) 、Deconvolution、Guided Backprogagation LRP不受gradient shattering and explanation discontinuities影响 元解释 元解释从个体解释发展而来 代表工作：spectral relevance analysis（SpRAy）、network dissection clustering individual heatmaps 五、可解释性评价与度量 measure for heatmap quality（perturbation analysis） 根据扰动造成置信度掉点的多少来进行分析 pointing game，通过解释对象的位置来评估模型的判别能力 六、Challenges and Open Questions heatmaps computed with today’s explanation methods visualize “first-order” information 意思是当前的一些工作都只是将特征和语义信息对应，但是缺少对于特征之间的关系的分析 the low abstraction level of explanations 缺少对于高语义信息的解释，比如热图只是解释了某像素对于判别是重要的，缺少更高语义内容的解释 explanations beyond visualization 人机交互 AI可解释性理论","raw":null,"content":null,"categories":[{"name":"论文","slug":"论文","permalink":"http://jlutangchuan.github.io/categories/%E8%AE%BA%E6%96%87/"}],"tags":[{"name":"PaperReading","slug":"PaperReading","permalink":"http://jlutangchuan.github.io/tags/PaperReading/"},{"name":"XAI","slug":"XAI","permalink":"http://jlutangchuan.github.io/tags/XAI/"}]},{"title":"PRML-回归线性模型","slug":"技术/理论/机器学习/PRML-回归线性模型","date":"2020-09-23T14:07:11.000Z","updated":"2023-07-03T15:04:37.082Z","comments":true,"path":"2020/09/23/ji-zhu/li-lun/ji-qi-xue-xi/prml-hui-gui-xian-xing-mo-xing/","link":"","permalink":"http://jlutangchuan.github.io/2020/09/23/ji-zhu/li-lun/ji-qi-xue-xi/prml-hui-gui-xian-xing-mo-xing/","excerpt":"","text":"PRML-回归线性模型 PRML 回归线性模型 本章主要将的是使用线性模型进行回归的问题，首先讲线性模型、回归问题的基本概念，其中涉及基函数等重要概念；接下来从几个不同的视角来看线性回归模型求解算法（最小二乘）：极大似然估计、几何视角；接下来主要讨论模型的复杂度这个问题，从频率学派和贝叶斯学派分开讨论，对于频率学派来说，通过对于目标函数期望损失的分解（偏置-方差分解），得到模型的复杂度变化对于偏置、方差的影响。 接下来讨论贝叶斯线性回归，但介绍此内容之前，先介绍了正则化和顺序学习方面的内容，这部分实际和贝叶斯线性回归也有密切的关系。贝叶斯线性回归的一个重要问题实际上还是先验的确定，这里实际上是为了数学上的简洁性，把先验定为零均值的高斯分布（也就是先验不是通过数据确定的）；接着又从数据的角度分析贝叶斯线性回归模型的不确定性，“预测的不确定性依赖于输入变量，数据点邻域处的不确定性小”。 接下来“等价核”、贝叶斯模型比较证据近似等内容先略过，后续再补充。 有待学习的知识点： 概率分布（CH02） 共轭先验 边缘似然 主要知识笔记一、线性回归模型介绍回归问题线性模型基函数二、线性回归模型学习算法1.直观：最小二乘估计误差函数与损失函数 损失函数在第一章决策论中提出一个最小化期望损失$\\mathbb{E}[L]&#x3D;\\sum_{k} \\sum_{j} \\int_{R_{j}} L_{k j} p\\left(\\mathbf{x}, C_{k}\\right) \\mathrm{d} \\mathbf{x}$；在推断中，只需要寻找目标变量的最大后验概率$\\mathbf{argmax}{k} L{k j} p\\left(C_{k} \\mid \\mathbf{x}\\right)$。 误差函数是手工设计的目标函数，通常将其设计为与MLE有等价解的函数。 在1.5.5回归问题的损失函数一节中，对于回归问题，从使用了平方损失作为损失函数，并分解如下（这个期望损失可以看作自变量$y$的函数，理想情况下当取得最优解是第一项为0，但实际数据集是指定的，因此第一项无法完全消除，后续会将第一项分解，只剩下关于最优预测与gt的项）$$h(\\mathbf{x})&#x3D;\\mathbb{E}[t \\mid \\mathbf{x}]&#x3D;\\int t p(t \\mid \\mathbf{x}) \\mathrm{d} t$$ $$\\mathbb{E}[L]&#x3D;\\int{y(\\mathbf{x})-\\mathbb{E}[t \\mid \\mathbf{x}]}^{2} p(\\mathbf{x}) \\mathrm{d} \\mathbf{x}+\\int\\int{\\mathbb{E}[t \\mid \\mathbf{x}]-t}^{2} p(\\mathbf{x},t) \\mathrm{d} \\mathbf{x} \\mathrm{d} t$$大概可以看到总的损失为数据的噪声方差损失与模型的偏差平方和损失构成。 平方和误差函数和平方损失函数之间一个是面向数据点做求和，另一个是理想的对联合分布积分，两者实际上是一个东西在两个侧重点的不同叫法。 第一章中的多项式拟合问题中，使用了最小化平方和误差函数作为确定参数的目标函数，这里将从几何角度和概率角度解释这个误差函数 $$E_{D}(\\mathbf{w})&#x3D;\\frac{1}{2} \\sum_{n&#x3D;1}^{N}\\left{t_{n}-\\mathbf{w}^{\\mathrm{T}} \\boldsymbol{\\phi}\\left(\\mathbf{x}_{n}\\right)\\right}^{2}$$ 2.概率解释：高斯噪声假设下的极大似然估计假设数据集为$(\\mathbf{X,T})$，目标变量t由输入变量的线性函数$y(x,w)$给出，且假设数据服从高斯噪声$\\epsilon \\sim N(0,\\beta^{-1})$$$t&#x3D;y(x,w)+\\epsilon$$ 对于一个新的输入变量，目标变量可以用条件均值来估计$$\\mathbb{E}[t \\mid \\mathbf{x}]&#x3D;\\int t p(t \\mid \\mathbf{x}) \\mathrm{d} t&#x3D;y(\\mathbf{x}, \\mathbf{w})$$利用极大似然估计来确定参数，首先写出似然函数，取对数后有$$\\begin{aligned}\\ln p(\\mathbf{t} \\mid \\mathbf{w}, \\beta) &amp;&#x3D;\\sum_{n&#x3D;1}^{N} \\ln \\mathcal{N}\\left(t_{n} \\mid \\mathbf{w}^{\\mathrm{T}} \\boldsymbol{\\phi}\\left(\\mathbf{x}{n}\\right), \\beta^{-1}\\right) \\&amp;&#x3D;\\frac{N}{2} \\ln \\beta-\\frac{N}{2} \\ln (2 \\pi)-\\beta \\frac{1}{2} \\sum{n&#x3D;1}^{N}\\left{t_{n}-\\mathbf{w}^{\\mathrm{T}} \\boldsymbol{\\phi}\\left(\\mathbf{x}_{n}\\right)\\right}^{2}\\end{aligned}$$ 记误差函数为 $$E_{D}(\\mathbf{w})&#x3D;\\frac{1}{2} \\sum_{n&#x3D;1}^{N}\\left{t_{n}-\\mathbf{w}^{\\mathrm{T}} \\boldsymbol{\\phi}\\left(\\mathbf{x}_{n}\\right)\\right}^{2}$$ 算出最小平方和误差函数和极大似然估计的解析解都为$$\\mathbf{w}_{\\mathrm{ML}}&#x3D;\\left(\\mathbf{\\Phi}^{\\mathrm{T}} \\mathbf{\\Phi}\\right)^{-1} \\mathbf{\\Phi}^{\\mathrm{T}} \\mathbf{t}$$其中$\\Phi$为设计矩阵形式如下 因此，最小平方和误差函数的解析解和高斯噪声下极大似然估计算出的解结果相同 3.几何解释：最小平方和的几何描述N个数据点的数据集（每个数据点有d个维度）看作N维空间中的d个向量，这d个向量可以看作基向量，形成张成空间S，N个目标变量T同样构成一个向量t；最小平方和误差函数等于S到t的距离的平方，相当于原问题就是找t在S上的投影。 三、顺序学习&amp;正则项1.顺序学习有两个顺序学习，一种是频率下的顺序学习（SGD），好处有二，一是顺序学习可以做成实时算法，数据边采集边学习；二是当解析解不好计算（数据量高的时候由于矩阵计算复杂度也大导致计算时空开销巨大）时可以采用顺序学习降低计算复杂度。另一种是贝叶斯下的顺序学习，就是不断获取新的evidence并更新posterior。 顺序学习 频率视角下的参数更新 参考SGD算法 优点 实时 传统算法在数据量大的时候矩阵运算时空开销非常巨大 贝叶斯视角下的参数更新 不断获取新的evidence并更新posterior 2.正则项正则化方法 使用正则的目的是控制过拟合，降低模型复杂度 常见的正则有L1、L2、L1L2 正则化方法有时被称为权值衰减，因为其倾向于让权值向零方向衰减 线性回归模型正则化 在误差函数中加入正则项$$E(\\mathbf{w})&#x3D;\\frac{1}{2} \\sum_{n&#x3D;1}^{N}\\left{t_{n}-\\mathbf{w}^{\\mathrm{T}} \\boldsymbol{\\phi}\\left(\\mathbf{x}{n}\\right)\\right}^{2}+\\frac{\\lambda}{2} \\sum{j&#x3D;1}^{M}\\left|\\mathbf{w}_{j}\\right|^{q}$$ $q&#x3D;1$时为Lasso回归：趋向于形成更稀疏的模型（模型复杂度降低程度大） $q&#x3D;2$时为Ridge回归 此外，正则化方法也可以用贝叶斯线性回归来解释，将在后续内容中讨论 四、模型复杂度分析这部分是分析期望损失的构成以及控制模型复杂度对于结果的影响 偏置-方差分解此前对于期望损失的分解如下$$\\mathbb{E}[L]&#x3D;\\int{y(\\mathbf{x})-\\mathbb{E}[t \\mid \\mathbf{x}]}^{2} p(\\mathbf{x}) \\mathrm{d} \\mathbf{x}+\\int\\int{\\mathbb{E}[t \\mid \\mathbf{x}]-t}^{2} p(\\mathbf{x},t) \\mathrm{d} \\mathbf{x} \\mathrm{d} t$$对于特定数据集D，第一项还可以展开成 重新分解期望损失 期望损失分解成3部分：基于特定数据集的期望预测模型与最优预测模型之间偏差的平方、特定数据集内预测模型的方差、最优预测与gt形成的噪声。 当模型复杂度变化时，期望损失也会发生变化： 模型复杂度升高，方差项升高 模型复杂度升高，偏差平方项降低 贝叶斯线性回归贝叶斯线性回归中，我们用概率来建模参数的更新过程，求的是关于X,y的参数最大后验概率；在之前的线性回归中，用条件概率、条件期望分析的是对目标变量的估计，也可以认为求关于X,y的极大似然。也会引出使用训练数据本身确定模型复杂度的自动化方法。 极大后验概率的 正则化操作的另一种解释 参数分布先验 贝叶斯线性回归中，假设参数是随机变量，服从某一分布，根据共轭先验参数服从高斯分布，为了数学上的形式简洁，假设参数服从0均值、各向同性的高斯分布，计算MAP 得到与正则化一致的结果$$\\begin{aligned}\\mathbf{m}{N} &amp;&#x3D;\\mathbf{S}{N}\\left(\\mathbf{S}{0}^{-1} \\mathbf{m}{0}+\\beta \\mathbf{\\Phi}^{\\mathrm{T}} \\mathbf{t}\\right) \\\\mathbf{S}{N}^{-1} &amp;&#x3D;\\mathbf{S}{0}^{-1}+\\beta \\mathbf{\\Phi}^{\\mathrm{T}} \\mathbf{\\Phi}\\end{aligned}$$ 以上是对于参数$w$的估计部分，现在需要考虑预测$p(t|\\mathbf{t},\\alpha,\\beta)$的分布情况$$p(t|\\mathbf{t},\\alpha,\\beta)&#x3D;\\int p(t|w,\\beta)p(w|\\mathbf{t},\\alpha,\\beta){\\rm d} w &#x3D; \\mathcal{N}\\left(t \\mid \\mathbf{m}{N}^{\\mathrm{T}} \\boldsymbol{\\phi}(\\mathbf{x}), \\sigma{N}^{2}(\\mathbf{x})\\right)$$ 可以给出输入空间中任一点的协方差估计$$\\sigma_{N}^{2}(\\mathbf{x})&#x3D;\\frac{1}{\\beta}+\\phi(\\mathbf{x})^{\\mathrm{T}} \\mathbf{S}_{N} \\phi(\\mathbf{x})$$这个估计可以视作模型在此处的不确定性，直观地讲，一个地方的数据点越密集、同时这些数据点之间的方差越小，该位置的不确定性越小。","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://jlutangchuan.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://jlutangchuan.github.io/tags/MachineLearning/"},{"name":"PRML","slug":"PRML","permalink":"http://jlutangchuan.github.io/tags/PRML/"}]},{"title":"Tensorflow学习 - 2.Layer","slug":"技术/编程/Tensorflow学习-2-Layer","date":"2020-09-08T05:21:21.000Z","updated":"2023-07-03T15:04:37.067Z","comments":true,"path":"2020/09/08/ji-zhu/bian-cheng/tensorflow-xue-xi-2-layer/","link":"","permalink":"http://jlutangchuan.github.io/2020/09/08/ji-zhu/bian-cheng/tensorflow-xue-xi-2-layer/","excerpt":"","text":"Tensorflow学习 - 2.Layer主要学习内容 Layer类特点 Layer组成 activations weight initializers weight regularizers weight constraints 常见Layer类 Core layers Input object Dense layer Activation layer Embedding layer Masking layer Lambda layer 卷积层 池化操作 循环层 预处理层 正则（regularization） &amp; 正规化（Normalization） 注意力层 Reshape Layers Merging Layers 激活函数层 如何使用Layer派生类 自定义Layer类 一、Layer类介绍 初始化 tf.keras.layers.Layer( trainable=True, name=None, dtype=None, dynamic=False, **kwargs ) trainable 该层参数是否可训练（Boolean） dynamic 可以直接当作函数调用 from tensorflow.keras import layers layer = layers.Dense(32, activation=&#39;relu&#39;) inputs = tf.random.uniform(shape=(10, 20)) outputs = layer(inputs) # callable 属性 需要继承的方法 实际自定义中一般只需重写__init__、build、call方法；build中声明参数以及进行参数初始化；call中进行运算（输入inputs返回结果） build中可以用self.add_weight的形式加入变量，也可以用tf.Variable 二、激活函数Teneorflow中激活函数既可以当作某个Layer的回调动作，也可以自己形成一个激活函数层 from tensorflow.keras import layers from tensorflow.keras import activations model.add(layers.Dense(64)) model.add(layers.Activation(activations.relu)) # 作为一个layer，但是这种情况下也需传递tensorflow.keras.activations model.add(layers.Dense(64, activation=activations.relu)) # 作为layer的子部分 当使用默认参数时，可以直接传激活函数名字符串 model.add(layers.Dense(64, activation=&#39;relu&#39;)) 三、权值初始化在全连接层中有kernel_initializer和bias_initializer两个参数 from tensorflow.keras import layers from tensorflow.keras import initializers layer = layers.Dense( units=64, kernel_initializer=initializers.RandomNormal(stddev=0.01), bias_initializer=initializers.Zeros() ) 这些初始化方法都放在了tf.keras.initializers中主要有： 四、正则惩罚项在layer中声明惩罚项，这些惩罚项会加到损失函数中进行优化；主要需要配置的时正则项权重参数 from tensorflow.keras import layers from tensorflow.keras import regularizers layer = layers.Dense( units=64, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), bias_regularizer=regularizers.l2(1e-4), activity_regularizer=regularizers.l2(1e-5) ) L1 L2 L1-L2 同样，可以用正则名字符串进行默认参数的正则项初始化 dense = tf.keras.layers.Dense(3, kernel_regularizer=&#39;l2&#39;) 五、核心层 Input object Input对象放在Model的input参数中 model = Model(input=[a, b], output=c) tf.keras.Input( shape=None, # 不包括Batch size batch_size=None, name=None, dtype=None, sparse=False, tensor=None, ragged=False, **kwargs ) Dense layer 最常见的Layer；注意输入输出维度(batch_size,…,…) tf.keras.layers.Dense( units, activation=None, use_bias=True, kernel_initializer=&quot;glorot_uniform&quot;, bias_initializer=&quot;zeros&quot;, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs ) Activation layer Embedding layer Turns positive integers (indexes) into dense vectors of fixed size. 根据索引序列从矩阵中找到对应的向量组 是一个可学习层，用于学习单词或者其它以index标记的数据的编码（通常是向量编码） 这个层只能用于模型的第一层 tf.keras.layers.Embedding( input_dim, output_dim, embeddings_initializer=&quot;uniform&quot;, embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs ) 相关函数tf.nn.embedding_lookup Masking layer Lambda layer 六、预处理层核心处理层 TextVectorization layer Normalization layer 类别数据预处理层 CategoryEncoding layer Hashing layer Discretization layer StringLookup layer IntegerLookup layer CategoryCrossing layer 图像处理&amp;增强层 ♥ Resizing layer Rescaling layer CenterCrop layer RandomCrop layer RandomFlip layer RandomTranslation layer RandomRotation layer RandomZoom layer RandomHeight layer RandomWidth layer 七、Reshape层 Reshape layer Flatten layer RepeatVector layer Permute layer tensor转置 Cropping1D layer Cropping2D layer Cropping3D layer UpSampling1D layer UpSampling2D layer UpSampling3D layer ZeroPadding1D layer ZeroPadding2D layer ZeroPadding3D layer 八、合并层 Concatenate layer Average layer Maximum layer Minimum layer Add layer Subtract layer Multiply layer Dot layer 小结这部分内容比较多，但是不需要全部记住，只需要知道Layer类能在写code中能干什么就行","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://jlutangchuan.github.io/tags/TensorFlow/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://jlutangchuan.github.io/tags/DeepLearning/"}]},{"title":"凸优化知识总结","slug":"技术/理论/机器学习/凸优化知识总结","date":"2020-09-07T16:52:55.000Z","updated":"2023-07-03T15:04:37.092Z","comments":true,"path":"2020/09/08/ji-zhu/li-lun/ji-qi-xue-xi/tu-you-hua-zhi-shi-zong-jie/","link":"","permalink":"http://jlutangchuan.github.io/2020/09/08/ji-zhu/li-lun/ji-qi-xue-xi/tu-you-hua-zhi-shi-zong-jie/","excerpt":"","text":"凸优化知识总结 重新搞一个电子版的凸优化知识总结，凸优化在支持向量机中的应用待补充。 有一个没展开的是二次规划以及半正定性的讨论 另外就是跳过了Slater条件和KKT条件的证明 补充阅读书籍《凸优化》 基础知识凸函数定义 一个函数 $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ 被称为凸函数，如果 $\\mathbf{dom}(f)(f$ 的定义域 $)$ 是凸集 对于任何 $\\mathbf{x}, \\mathbf{y} \\in \\operatorname{dom}(f)$ 和 $0 \\leq \\theta \\leq 1,$ 有 $$f(\\theta \\mathbf{x}+(1-\\theta) \\mathbf{y}) \\leq \\theta f(\\mathbf{x})+(1-\\theta) f(\\mathbf{y})$$ 仿射集 如果一个集合 $C \\in \\mathbb{R}^{n}$ 是仿射的，则 C 中两点间的直线也在 C 中 $$\\mathbf{x}&#x3D;\\theta \\mathbf{x_{1}}+(1-\\theta) \\mathbf{x_{2}} \\in C , \\theta \\in \\mathbb{R}$$ 凸集 一个集合 $C \\in \\mathbb{R}^{n}$ 是凸的，则对于任意的 $\\mathbf{x}, \\mathbf{y} \\in C,$ 有 $\\theta \\mathbf{x}+(1-\\theta) \\mathbf{y} \\in C \\quad 0 \\leq \\theta \\leq 1$ 常见的凸集： $\\mathbb{R}^n$ $\\mathbb{R}_{+}^{n}$ 超平面 半空间 多面体：有限个半空间的交集 $-\\log x \\ on \\ x&gt;0$ $x\\log x \\ on \\ x\\geq0$ $f(\\mathbf{x})&#x3D;\\mathbf{x}^{T} \\mathbf{P} \\mathbf{x}+2 \\mathbf{q}^{T} \\mathbf{x}+\\mathbf{r}$ ， $\\mathbf{P}\\geq \\mathbf{0}$ $n\\geq 1$的范数球 凸集性质 凸集的交集是凸集 凸函数充要条件 一阶充要条件 $f\\left(\\mathbf{x_{1}}\\right) \\geq f(\\mathbf{x})+\\nabla^{T} f(\\mathbf{x})\\left(\\mathbf{x_{1}}-\\mathbf{x}\\right)$对于所有的$x_1$,$x$均成立 二阶充要条件 若函数$f$二阶可导，则函数为凸函数iff Hessian矩阵 $$ \\mathbf{H}(\\mathbf{x}) \\succeq \\mathbf{0} $$ 保凸运算 若$f$为凸函数，则$f(\\mathbf{Ax+b})$为凸函数 若$g$凸、$h$凸，$h$非递减，则$h(g(x))$为凸函数 $f_1,f_2,..,f_m$为凸函数，$w_1,w_2,..,w_m \\geq 0$ 则$\\sum_{i&#x3D;1}^m{w_if_i}$为凸函数 $f_1,f_2,..,f_m$为凸函数，则有 优化问题无约束最值问题$$\\min f(\\mathbf{x}) \\quad \\mathbf{x} \\in \\mathbb{R}^{n}$$ 有约束最值问题这里等式约束和不等式约束同时出现 $$\\begin{array}{cl}\\operatorname{minimize} &amp; f_{0}(\\mathbf{x}) \\\\text { subject to } &amp; f_{i}(\\mathbf{x}) \\leq 0 \\text { for } i&#x3D;1,2, \\cdots, m \\&amp; h_{i}(\\mathbf{x})&#x3D;0 \\text { for } i&#x3D;1,2, \\cdots, p\\end{array}$$ 凸优化问题 对于凸优化问题，要求$f$是凸函数，$h$是仿射函数（可行域是凸集，目标函数是凸函数） 解法是将带约束的优化问题利用拉格朗日乘数法转化为无约束优化问题 线性规划 二次规划 QCQP （这部分内容不考虑$f$函数和$h$函数是否为凸函数或是仿射函数） 拉格朗日乘数法$$L(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{v})&#x3D;f_{0}(\\mathbf{x})+\\sum_{i&#x3D;1}^{m} \\lambda_{i} f_{i}(\\mathbf{x})+\\sum_{i&#x3D;1}^{p} v_{i} h_{i}(\\mathbf{x})\\s.t. \\ \\ \\ \\ \\ \\lambda \\geq 0$$ 主问题如下$$\\hat{p}&#x3D;\\min_{\\mathbf{x}}\\left(\\max_{\\boldsymbol{\\lambda\\geq 0}, \\boldsymbol{v}} L(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{v})\\right)$$拆解来看，是先最大化两个带约束函数的式子；若满足约束，这部分最大是0，若不满足约束，这部分为＋∞，后面无论怎么优化目标函数主问题的解都是正无穷；当满足约束条件时，主问题的最优解就是原问题的最优解，记主问题的最优解也就是目标函数的最优解为$\\hat{p}$。 拉格朗日对偶性构造一个对偶问题，其中$D$为函数$L$的定义域（此处不考虑$f$函数和$h$函数是否为凸函数或是仿射函数）$$\\max_{\\lambda \\geq 0 , \\mathbf{v}} \\min_{\\mathbf{x}\\in D} L(\\mathbf{x,\\lambda,v})$$记对偶问题的最优解为$d^{*}$ 首先考察$g( \\mathbf{\\lambda,v})&#x3D; \\min_{\\mathbf{x}\\in D} f_{0}(\\mathbf{x})+\\sum_{i&#x3D;1}^{m} \\lambda_{i} f_{i}(\\mathbf{x})+\\sum_{i&#x3D;1}^{p} v_{i} h_{i}(\\mathbf{x})$的凸性，对于每一个$x$，这都是一个关于$ \\lambda,v$的仿射函数（既凸又凹），根据保凸运算有，关于$x$的g函数的逐点下确界是凹函数。 探究$g$函数的不等关系，若$\\mathbf{\\tilde{x}}$为可行域中任一点$$g(\\mathbf{\\lambda},v) &#x3D; \\min_{\\mathbf{x}\\in D} L(\\mathbf{x,\\lambda,v}) \\leq L(\\mathbf{\\tilde{x},\\lambda,v})$$又因为可行域中$\\sum_{i&#x3D;1}^{m} \\lambda_{i} f_{i}(\\mathbf{\\tilde{x}})+\\sum_{i&#x3D;1}^{p} v_{i} h_{i}(\\mathbf{\\tilde{x}}) \\leq 0$$$L(\\mathbf{\\tilde{x},\\lambda,v})&#x3D;f_{0}(\\mathbf{\\tilde{x}})+\\sum_{i&#x3D;1}^{m} \\lambda_{i} f_{i}(\\mathbf{\\tilde{x}})+\\sum_{i&#x3D;1}^{p} v_{i} h_{i}(\\mathbf{\\tilde{x}}) \\leq f_{0}(\\mathbf{\\tilde{x}})$$所以有$$g(\\mathbf{\\lambda},v) \\leq f_{0}(\\mathbf{x^{*}}) &#x3D; \\hat{p}$$注意:这里逐点下确界函数$g(\\mathbf{\\lambda},v)$的$x$只是在定义域中，而并不一定在可行域中。 涉及到一个问题，$\\min_{x\\in D} L(\\mathbf{x,\\lambda,v})$是关于$\\lambda,\\mathbf{v}$的一个函数，结果为$f_{0}(\\mathbf{x^{‘}})+\\sum_{i&#x3D;1}^{m} \\lambda_{i} f_{i}(\\mathbf{x^{‘}})$，并且这里的$f_i(x^{‘}) \\leq 0$ 接下来需要探究主问题的最优解与对偶问题的最优解的关系： 利用前面两个结论 对于任意$\\lambda \\geq 0,\\mathbf{v}$满足$g(\\mathbf{\\lambda},v) \\leq f_{0}(\\mathbf{\\hat{x}}) &#x3D; \\hat{p}$ 对偶问题最优解$\\hat d$时的$\\hat \\lambda,\\mathbf{\\hat v}$ 因此有结论（这被叫做弱对偶条件）。需要注意，这个结论与$f_0$函数是否为凸函数无关；并且$d^*$对应的$x$也不一定在可行域中。$$\\hat d \\leq \\hat p$$ 继续观察对偶问题，对偶问题可以写为关于$\\lambda,\\mathbf{v}$的优化问题$$\\max g(\\lambda,\\mathbf{v})\\s.t. \\lambda \\geq 0$$可以很简单地观察出，对偶问题为在凸集的可行域中最大化一个凹函数，仍然是一个凸优化问题 （以下部分暂不加证明） Slater条件上面推导出一个结论：对偶问题的最优解总是小于等于原问题的最优解（$\\hat d \\leq \\hat p$），Slater条件想探究不等式取等号（强对偶）的充分条件。 直接给条件： 原问题是一个凸优化问题 存在内点$\\mathbf{x}$，使得$f_i(\\mathbf{x})&lt;0$对于$i&#x3D;1,2,..,m$均成立（Slater条件） 并且此时两个问题的最优值点重合（都位于可行域中）$$\\hat p&#x3D;\\hat d&#x3D;L(\\mathbf{\\hat x,\\hat \\lambda,\\hat v})$$ KTT条件目前想探究凸优化问题且满足Slater条件的前提下$\\mathbf{\\hat x,\\hat \\lambda, \\hat v}$为原问题、对偶问题的最优解的充要条件 KKT条件如下","raw":null,"content":null,"categories":[{"name":"数学","slug":"数学","permalink":"http://jlutangchuan.github.io/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"math","slug":"math","permalink":"http://jlutangchuan.github.io/tags/math/"}]},{"title":"矩阵求偏导知识总结","slug":"技术/理论/机器学习/矩阵求偏导知识总结","date":"2020-09-02T07:41:36.000Z","updated":"2023-07-03T15:04:37.095Z","comments":true,"path":"2020/09/02/ji-zhu/li-lun/ji-qi-xue-xi/ju-zhen-qiu-pian-dao-zhi-shi-zong-jie/","link":"","permalink":"http://jlutangchuan.github.io/2020/09/02/ji-zhu/li-lun/ji-qi-xue-xi/ju-zhen-qiu-pian-dao-zhi-shi-zong-jie/","excerpt":"","text":"矩阵求偏导知识总结看这方面的资料时候感觉有点混乱（有的布局方式没有讲清，时而分子布局，时而分母布局；有的规则本身存在一些矛盾解释不清），又没有非常全面地了解这方面的知识，导致自己也很迷糊，主要参考的是维基百科的介绍（但是也有一些问题没解决）。 基本原则：矩阵对矩阵求偏导，就是自变量矩阵中的每个元素对因变量的每个元素求偏导。矩阵求偏导有两套摆放习惯（分子布局、分母布局），常用的是分子布局（两种layout各有利弊）。 注意：默认情况是$x$表示列向量，$x^T$表示行向量 分子布局与分母布局分子布局 Lay out according to $\\mathbf{y}$ and $\\mathbf{x}^T$ 分母布局 Lay out according to $\\mathbf{y^T}$ and $\\mathbf{x}$ 存在的问题： 当分子分母一个行向量一个列向量时怎么处理不知道 偏导数布局形式 标量&#x2F;向量分子布局下结果的形状是分母向量的转置 向量&#x2F;标量分子布局下形状与分子保持一致 矩阵&#x2F;标量与分子矩阵形式一致 标量&#x2F;矩阵为分母矩阵的转置形式一致 向量&#x2F;向量列向量&#x2F;列向量的偏导计算结果是矩阵 行向量&#x2F;列向量（感觉用分子布局的方式解释不了） 偏导数结果常见的一些结论 分类： 对无关量求偏导 $\\mathbf{0}$ 对自身求偏导 $\\mathbf{I}$ 线性变换 系数求偏导 函数乘法求偏导 复合函数 另外，关于迹和行列式的偏导wiki上也很容易找到 Reference https://en.wikipedia.org/wiki/Matrix_calculus https://blog.csdn.net/shouhuxianjian/article/details/46669365","raw":null,"content":null,"categories":[{"name":"数学","slug":"数学","permalink":"http://jlutangchuan.github.io/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"math","slug":"math","permalink":"http://jlutangchuan.github.io/tags/math/"}]},{"title":"python可视化","slug":"技术/编程/python可视化","date":"2020-08-13T04:28:26.000Z","updated":"2023-07-03T15:04:37.055Z","comments":true,"path":"2020/08/13/ji-zhu/bian-cheng/python-ke-shi-hua/","link":"","permalink":"http://jlutangchuan.github.io/2020/08/13/ji-zhu/bian-cheng/python-ke-shi-hua/","excerpt":"","text":"python可视化后续如果再学习可视化就是列一些看到不错的图加上自己的实现代码 预备学习目标 掌握数据可视化常见图都有哪些？每个图想做什么事情？ python实现这些图需要设置哪些参数？pd、mpl和sns的基本用法？ 时间安排主要根据[^1]进行学习，感觉正常速度的话需要看完要1个月，看完+写代码要2个月，看完+记笔记+写代码要2个半月，前面可以三个任务都做，后面可以提速一下。 学习内容主要根据可视化50图[^1]进行学习，还有一个视频课[^2]，因为自已pandas用得少，不太熟练，还会补充学一些pandas的知识，另外就是把这些图的模板留一下，方便未来使用。 前面见过的图主要学习matplotlib的代码风格以及参数选项、后面一些没见过的图主要学习这个图的用途、绘制方法以及如何对图进行解读。 这些50图主要还是从几个主要的图中派生出来的，派生的意义可能有：1. 加入更多信息 2. 样式更加美观 3. 突出某些信息 可视化50图0. pandas &amp; matplotlib reviewpandas基本用法 特点 处理浮点与非浮点数据里的缺失数据，表示为 NaN； 大小可变：插入或删除 DataFrame 等多维对象的列； 自动、显式数据对齐：显式地将对象与一组标签对齐，也可以忽略标签，在 Series、DataFrame 计算时自动与数据对齐； 强大、灵活的分组（group by）功能：拆分-应用-组合数据集，聚合、转换数据； 把 Python 和 NumPy 数据结构里不规则、不同索引的数据轻松地转换为 DataFrame 对象； 基于智能标签，对大型数据集进行切片、花式索引、子集分解等操作； 直观地合并（merge）、连接（join）数据集； 灵活地重塑（reshape）、透视（pivot）数据集； 轴支持结构化标签：一个刻度支持多个标签； 成熟的 IO 工具：读取文本文件（CSV 等支持分隔符的文件）、Excel 文件、数据库等来源的数据，利用超快的 HDF5 格式保存 &#x2F; 加载数据； 时间序列：支持日期范围生成、频率转换、移动窗口统计、移动窗口线性回归、日期位移等时间序列功能。 matplotlib 见前面的笔记 1. 关联分析 散点图、气泡图、待线性回归的散点图、抖动图、计数图 图 描述 图示 matplotlib实现 抖动图 通常，多个数据点具有完全相同的 X 和 Y 值。 结果，多个点绘制会重叠并隐藏。 为避免这种情况，请将数据点稍微抖动，以便可以直观地看到它们。 使用 seaborn 的 `stripplot（）` 很方便实现这个功能。 seaborn自带实现。sns.stripplot(df.cty, df.hwy, jitter=0.25, size=8, ax=ax, linewidth=.5) 气泡图 气泡图（bubble chart）是可用于展示三个变量之间的关系。 第三个变量通过改变点的大小实现 带线性回归的散点图 加入一条线性预测以及error range sns.lmplot 计数图 一种避免点重叠问题的方法是增加点的大小，取决于有多少点在那个点上。所以，点的尺寸越大，它周围的点的集中度就越大。 sns.stripplot(df_counts.cty, df_counts.hwy, size=df_counts.counts*2, ax=ax) 边缘直方图、边缘箱式图 图 描述 图示 matplotlib实现 边缘直方图 探索两个变量各自的分布 左上、右上、左下三个subplot；注意画hist的方向参数 边缘箱式图 在上图的基础上将直方图换成箱式图 sns.boxplot(df.hwy, ax=ax_right, orient=\"v\") 相关图、矩阵图 图 描述 图示 matplotlib实现 相关图(Correllogram) 相关图用于直观地查看给定数据框(或二维数组)中所有可能的数值变量对之间的相关度量 sns.heatmap(df.corr(), xticklabels=df.corr().columns, yticklabels=df.corr().columns, cmap='RdYlGn', center=0, annot=True) 矩阵图Pairwise Plot Pairwise plot is a favorite in exploratory analysis to understand the relationship between all possible pairs of numeric variables. It is a must have tool for bivariate analysis. `sns.pairplot(df, kind=\"scatter\", hue=\"species\", plot_kws=dict(s=80, edgecolor=\"white\", linewidth=2.5)) ` `sns.pairplot(df, kind=\"reg\", hue=\"species\")` 4. 偏差分析 偏差分析 偏差条形图、偏差文本、偏差点阵图、面积图、带标记的偏差棒棒糖图 5. 序关系 排序 有序条形图、点阵图、坡度图、哑铃图、棒棒糖图 6. 分布 连续变量的直方图、分类变量的直方图、密度图、带直方图的密度曲线、山峦图、分布式点阵图、箱式图、点图+箱图、小提琴图、人口金字塔、分类图 图 描述 图示 matplotlib实现 山峦图 多个密度图（or 直方图）的叠加 fig, axes = joypy.joyplot(mpg, column=['hwy', 'cty'], by=\"class\", ylim='own', figsize=(14,10)) 箱式图 中位数、四分位数Q1和Q3、上下限、异常值；上下限的计算方式为：IQR = Q3-Q1 上限=Q3+1.5IQR 下限=Q1-1.5IQR；异常值为上下限之外的数。箱式图适合单变量的数据分析以及多类似变量的对比分析、同时还能反应数据中的异常值（偏态与尾重） sns.boxplot(x='class', y='hwy', data=df, notch=False) 7.组合 Waffle Chart Pie Chart Treemap Bar Chart 8. Change Time Series Plot Time Series with Peaks and Troughs Annotated Autocorrelation Plot Cross Correlation Plot Time Series Decomposition Plot Multiple Time Series Plotting with different scales using secondary Y axis Time Series with Error Bands ❤ Stacked Area Chart ❤ Area Chart Unstacked Calendar Heat Map ❤github日历 Seasonal Plot 9. Groups Dendrogram Cluster Plot Andrews Curve Parallel Coordinates 常见问题以及解决方法 matplotlib中文乱码问题？ 解决[^3]： import matplotlib as mpl mpl.rcParams[&#39;font.sans-serif&#39;] = [&#39;SimHei&#39;] mpl.rcParams[&#39;font.serif&#39;] = [&#39;SimHei&#39;] mpl.rcParams[&#39;axes.unicode_minus&#39;] = False # 解决保存图像是负号&#39;-&#39;显示为方块的问题,或者转换负号为字符串 这段代码目前已经放在自己的自定义代码段中，vscode直接键入mpl就可以了 设置自定义代码段方法： vscode-&gt;文件-&gt;首选项-&gt;用户代码片段-&gt;python &quot;import matplotlib&quot;: &#123; &quot;prefix&quot;: &quot;mpl&quot;, &quot;body&quot;: [ // 确认后添加的代码 &quot; import numpy as np # 导入numpy库 &quot;, &quot; import pandas as pd # 导入pandas库 &quot;, &quot; import matplotlib as mpl # 导入matplotlib库 &quot;, &quot; import matplotlib.pyplot as plt &quot;, &quot; import seaborn as sns # 导入seaborn库 &quot;, &quot; &quot;, &quot; mpl.rcParams[&#39;font.sans-serif&#39;] = [&#39;SimHei&#39;] &quot;, &quot; mpl.rcParams[&#39;font.serif&#39;] = [&#39;SimHei&#39;] &quot;, &quot; mpl.rcParams[&#39;axes.unicode_minus&#39;] = False # 解决保存图像是负号&#39;-&#39;显示为方块的问题,或者转换负号为字符串, &quot;, &quot;$0&quot; // $0代表光标最后停留的位置 ], &quot;description&quot;: &quot;导入matplotlib并解决中文乱码问题&quot; &#125; Reference https://datawhalechina.github.io/pms50/#/ https://www.bilibili.com/video/BV1pE411c7XM?from=search&amp;seid=18165956011282754418 https://www.jb51.net/article/150878.htm https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python[^1]: https://datawhalechina.github.io/pms50/#/[^2]: https://www.bilibili.com/video/BV1pE411c7XM?from=search&amp;seid=18165956011282754418[^3]: https://www.jb51.net/article/150878.htm[^4]: https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"matplotlib学习","slug":"技术/编程/matplotlib学习","date":"2020-08-09T01:04:36.000Z","updated":"2023-07-03T15:04:37.042Z","comments":true,"path":"2020/08/09/ji-zhu/bian-cheng/matplotlib-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2020/08/09/ji-zhu/bian-cheng/matplotlib-xue-xi/","excerpt":"","text":"matplotlib学习专门整理一下mpl主要是想过一下作图中所有的可变元素，方便自定义作图，对后面学具体图或者seaborn等有帮助，mpl有两种接口，一种是模仿matlab实现的接口pyplot(plt)，另一种是面向对象的。 目前的许多实现教程大部分没有区分这两种接口，很多时候都在混用，使得想要掌握mpl全貌不是很方便。但自己学可视化主要不是扩展API的名字用法，主要还是想扩展更多的可视化图。 这个github项目^4感觉写得不错，细节可以参考这个 组件目录 Matplotlib 容器类：图(figure)、坐标系(axes)、坐标轴(axis)、刻度(tick) 主要是图外的辅助内容，与数据无关 基础类：线(line)、点(marker)、文字(text)、图例(legend)、网格(grid)、标题(title) 需要结合数据进行维护的内容 主要内容 matplotlib有一套完全仿照MATLAB的函数形式的绘图接口，在matplotlib.pyplot模块中。这套函数接口方便MATLAB用户过度到matplotlib包。 基本流程 创建figure实例； 在figure上创建axes； 在axes上添加基础类对象。 准备# !pip install brewer2mpl import numpy as np import pandas as pd import matplotlib as mpl import matplotlib.pyplot as plt import seaborn as sns import warnings; warnings.filterwarnings(action=&#39;once&#39;) large = 22; med = 16; small = 12 params = &#123;&#39;axes.titlesize&#39;: large, &#39;legend.fontsize&#39;: med, &#39;figure.figsize&#39;: (16, 10), &#39;axes.labelsize&#39;: med, &#39;axes.titlesize&#39;: med, &#39;xtick.labelsize&#39;: med, &#39;ytick.labelsize&#39;: med, &#39;figure.titlesize&#39;: large&#125; plt.rcParams.update(params) plt.style.use(&#39;seaborn-whitegrid&#39;) sns.set_style(&quot;white&quot;) %matplotlib inline 展示plt.gca().set(xlim=(0.0, 0.1), ylim=(0, 90000), xlabel=&#39;Area&#39;, ylabel=&#39;Population&#39;) # gca == get current axes plt.xticks(fontsize=12); plt.yticks(fontsize=12) plt.title(&quot;Bubble Plot with Encircling&quot;, fontsize=22) plt.legend(fontsize=12) plt.show() Fig建立一个fig（matlab式的代码可以不用加这个，这里是为了配置一些参数） plt.figure(figsize=(16, 10), dpi= 80, facecolor=&#39;w&#39;, edgecolor=&#39;k&#39;) 颜色控制plt.cm中有许多色带，可供我们选择，使用方法就是plt.cm.tab10(float_between_0_and_1) colors = [plt.cm.tab10(i/float(len(categories)-1)) for i in range(len(categories))] 有些作图函数有cmap参数只需要传cm中的类名就可以 ax_main.scatter(&#39;displ&#39;, &#39;hwy&#39;, s=df.cty*4, c=df.manufacturer.astype(&#39;category&#39;).cat.codes, alpha=.9, data=df, cmap=&quot;tab10&quot;, edgecolors=&#39;gray&#39;, linewidths=.5) matplotlib-cheatsheet样式讲得挺详细的 常见图 Scatter plt.scatter(&#39;area&#39;, &#39;poptotal&#39;, data=midwest.loc[midwest.category==category, :], s=&#39;dot_size&#39;, c=colors[i], label=str(category), edgecolors=&#39;black&#39;, linewidths=.5) # eg 参数名 作用 data 传一个dataFrame，此时需要指定要用的column名称 s 大小 c 颜色 label 指定这组散点的名称 edgecolors 散点边缘颜色 linewidths 散点边缘宽度 pie plot imshow contour text fill step boxplot hist violinplot barbs eventplot hexbin xcorr Reference Matplotlib优雅作图笔记 https://segmentfault.com/a/1190000020450334?utm_source=tag-newest https://zhuanlan.zhihu.com/p/77782561?utm_source=qq&amp;utm_medium=social&amp;utm_oi=775799432212918272 https://github.com/rougier/matplotlib-cheatsheet","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"侧耳倾听","slug":"读书笔记/侧耳倾听","date":"2020-07-29T07:03:21.000Z","updated":"2023-07-03T15:04:36.979Z","comments":true,"path":"2020/07/29/du-shu-bi-ji/ce-er-qing-ting/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/29/du-shu-bi-ji/ce-er-qing-ting/","excerpt":"","text":"侧耳倾听电影链接：https://tw.iqiyi.com/v_19rs4j8m1s.html 文案文字版 概述 这是一部关乎爱与成长的电影，真正美好的爱情应该有其积极意义，当你迷茫踟躇时 我为你照亮方向，当我步履蹒跚时 你给我前进动力，好的恋人 会与你并肩成长，甚至ta什么都没做 什么也没说，但你就是会为了能和ta看同样的风景而拼命努力。 圣司为了能让自己的名字出现在借书卡上，耗费漫长的时间和精力读了大量的书，阿雯为了能追赶上圣司疾驰的脚步，拼尽全力给了自己一场试炼，圣司如愿了 他靠近了自己喜欢的姑娘，阿雯失败了 但她找到了成为更好自己的路，这便是爱的积极意义。 美好的爱情固然令人心生向往，但其实影片最令我触动的，是对自我认知的思考，你有没有问过自己，你的梦想到底是什么，你以后要当什么样的人，你要走什么样的路，其实很多人压根没有认真的思考过这些问题，他们只是在随大流 ，只是在适合的时间将就着做对应的事情，别人上学我也上学，该工作的时候找份工作，到了适当年龄再结婚生子，当然这样也没什么不好，只要你过得顺心满足，怕只怕哪天忽然开窍开始审视自我，才发现这一切并不是自己想要的，才发现自己稀里糊涂的走了这么多不中意的路，然而你的一生早已将就着过去一大截。 在爱情之外，《侧耳倾听》还讨论了青春期的迷茫与奋斗，月岛雯因为圣司找到了自己应该前进的方向，这一点可以从前后两次《Country Road》的歌词中可以窥见，在得知圣司要去意大利学习小提琴制作，觉得自己也不能再迷茫下去，也因此尝试写猫男爵的故事；爱情可以看做辅助剂，主要想说的是像月岛雯这样的女孩内心成长历程。 人物月岛雯雯是一个喜欢文学的女孩，开头向闺蜜展示自己改编的《Country Road》，热爱读书，正在就读初三的阿雯面对升学没有半点紧张，本身就极爱读书的她几乎一有时间就会泡在图书馆，即便是在暑假，在帮助父母做完家中琐事之余，其唯一想做的事情也是读书。也正是如此喜欢读书的阿雯，才能赶在图书馆全面实施计算机化之前，抓住借书卡机制的尾巴与天泽圣司相遇。 喜欢读书但学习称不上刻苦，迷茫、不知道自己将来该怎么度过自己还没好好想过。在面对且优秀的圣司的告白时陷入了自卑，想跟上圣司的脚步。在遇到圣司之后认真思考自己想做什么，尝试用尽全力去做一件事。 天泽圣司想成为小提琴匠人，在追求理想的道路上虽然还做得称不上制作技术非常到家，但是对热爱的事情非常谦虚也足够努力，也有勇气并愿意为此走一条人迹罕至的路。为此，圣司选择去意大利学习小提琴制作的手艺，尽管有家人暂时的不理解、尽管要离开朝思暮想的人 暗恋月岛雯，为了能遇到雯，努力去图书馆看大量的书，在借书卡上留下自己的名字。 圣司的爷爷原石的比喻 阿雯和圣司就跟这块石头一样，是没有经过磨砺的自然原石，我最喜欢这种原石了， 可是要做小提琴、写故事书就不一样了，要从自己心里去找那块原石，经过磨砺才行，那是要花一番功夫的。你也看过比这个还大的原石吧，其实这些石头被磨砺之后，反而没什么意思了，因为高纯度的部分都在内部比较小的地方，外表看起来不起眼的石头也有可能是一颗好原石。 台词 因为你,我愿意成为一个更好的人,不想成为你的包袱,因此发奋努力,只是为了想要证明我足以与你相配。 其实很早以前，我就在图书馆的借书卡上注意到你了，你不知道我在图书馆有几次跟你擦肩而过吧，好几次我还曾经坐在你旁边。为了要让我的名字早点出现在借书卡上，我看了好多书。将来…我如果去了意大利，会不停地唱着你那首歌来努力的。 只要有你在我就会努力，我很高兴我尽了力，让我比以前更了解我自己。 我…我写了之后才发现，光是想写是不够的，要学的东西还有很多很多。但是…因为圣司一步步走的好快，我好想跟上他的脚步，我真的好害怕，好害怕。 我虽然不能去送你，但是我会等你回来的。 阿雯和圣司就跟这块石头一样，是没有经过磨砺的自然原石，我最喜欢这种原石了， 可是要做小提琴、写故事书就不一样了，要从自己心里去找那块原石，经过磨砺才行，那是要花一番功夫的。你也看过比这个还大的原石吧，其实这些石头被磨砺之后，反而没什么意思了，因为高纯度的部分都在内部比较小的地方，外表看起来不起眼的石头也有可能是一颗好原石。 向往的爱情是怎样的？ 像月岛雯的父母，虽然对雯的成绩下滑有不同的态度，但是能平等地给予孩子自己的建议 像圣司与月岛雯，都为了能与对方相见而努力着，在这个过程中彼此激励并找到自己的方向 青春时的迷茫应该如何度过？ 像原石一样，不必过于羡慕那些已经被打磨过的宝石，磨砺的过程反而是最值得细细体会的 勇敢，像圣司一样为着理想敢于去走一条不平凡的路 坚持，像阿雯为了弄清楚自己有没有写作的天分而夜以继日地写小说、像圣司为了理想而认真做小提琴、为了能让自己的名字出现在阿雯的面前而拼命读书 Reference抬头仰望，侧耳倾听 迷茫的时候不妨看看，看完我又相信了爱情","raw":null,"content":null,"categories":[{"name":"随记","slug":"随记","permalink":"http://jlutangchuan.github.io/categories/%E9%9A%8F%E8%AE%B0/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"http://jlutangchuan.github.io/tags/Chrome/"}]},{"title":"pandas学习","slug":"技术/编程/pandas学习","date":"2020-07-28T00:27:22.000Z","updated":"2023-07-03T15:04:37.045Z","comments":true,"path":"2020/07/28/ji-zhu/bian-cheng/pandas-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/28/ji-zhu/bian-cheng/pandas-xue-xi/","excerpt":"","text":"pandas学习主要参考书目：《利用python进行数据分析》^1 学习目标 了解Pandas的特点 熟悉Pandas的基本数据结构以及其属性 掌握pandas的数据创建、导入导出、索引、切片、拼接、转化这几项基本操作 掌握DataFrame的Index Column的相关操作（Reindex、Sort） 学习Pandas的数学运算 掌握Category类型和groupby方法 学习笔记Pandas特点 基于numpy实现，属于scipy科学计算包 很方便实现对一维数据、二维数据的数据分析 方便进行数据可视化 索引方式灵活（允许简单索引与多级索引） 实现了对缺失数据的处理 基础数据结构主要介绍三个数据结构：Index、Series、DataFrame（其实还有个Panel三维数据结构） 1. Index pandas的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建Series或DataFrame时，所用到的任何数组或其他序列的标签都会被转换成一个Index。Index对象不可修改，从而在多个数据结构之间安全共享。 注意： pandas的Index允许索引重复 不只是int还可以是string 2. Series 一维数据结构 允许不同类型的数据（此时dtype为object） 初始化的时候可以指定Index 初始化可以传list+index，也可以是dict、np一维ndarray类型、标量填充 若index和data中的索引不完全一致，最终生成的Series的index按照index参数 3. DataFrame 初始化： dict &#x3D;&gt; {‘name’:Series} ndarray(ndim&#x3D;2) 初始化参数（data、index、columns） 缺失值会用NaN填充 常用属性&amp;方法汇总 导入导出 pandas支持的导入导出非常多 常见的有： pd.read_csvpd.read_excelpd.read_jsonpd.read_picklepd.read_sqlpd.read_table 使用方法（read_csv）： data = pd.read_csv(&#39;file.csv&#39;,dtype=object) 常用dtype：int64 float64 object category 注意传进来的数据类型常常是不满足要求的，一般需要进行类型转换甚至是数据预处理 索引&amp;切片主要有三种索引方式：[]、loc、iloc 对于DataFrame，可以直接用df.col的形式取某一列 loc .loc主要是基于标签(label)的，包括行标签(index)和列标签(columns)，即行名称和列名称，可以使用df.loc[index_name,col_name]，选择指定位置的数据，其它的用法有： 使用单个标签。如果.loc[]中只有单个标签，那么选择的是某一行。 df.loc[3]选择的是index名为‘3’的一行，注意这里的’3’是index的名称，而不是序号 使用标签的list：同样是只选择行 标签的切片对象：与通常的python切片不同，在最终选择的数据中包含切片的start和stop 布尔型的数组：通常用于筛选符合某些条件的行 也可以是函数（lambda） iloc iloc是基于位置的索引，利用元素在各个轴上的索引序号进行选择，序号超出范围会产生IndexError，切片时允许序号超过范围，用法包括：（和loc的用法基本一样） 整数 单个list or ndarray（对行选择） 切片 。。。 [] 只能索引列 索引多列同样传个list 拼接拼接当出现没有匹配时默认NaN填充，当出现重复 扩充行列时可以直接用 df[&#39;new_col&#39;] = df.Series() df.iloc[-1] = list() 两个df组合时候使用concat、merge和join方法^2 concatpd.concat([df1, df2], axis=0) # 可以设置axis，axis=1表示左右拼接 merge这块还是要补补数据库部分的知识，忘得差不多了😂 join和merge差不多，但是join是DataFrame内置方法，直接df1.join(df2)即可 pandas的merge方法是基于共同列，将两个dataframe连接起来。merge方法的主要参数： left&#x2F;right：左&#x2F;右位置的dataframe。 how：数据合并的方式。left：基于左dataframe列的数据合并；right：基于右dataframe列的数据合并；outer：基于列的数据外合并（取并集）；inner：基于列的数据内合并（取交集）；默认为’inner’。 on：用来合并的列名，这个参数需要保证两个dataframe有相同的列名。 left_on&#x2F;right_on：左&#x2F;右dataframe合并的列名，也可为索引，数组和列表。 left_index&#x2F;right_index：是否以index作为数据合并的列名，True表示是。 sort：根据dataframe合并的keys排序，默认是。 suffixes：若有相同列且该列没有作为合并的列，可通过suffixes设置该列的后缀名，一般为元组和列表类型。 # 单列的内连接 # 定义df1 import pandas as pd import numpy as np df1 = pd.DataFrame(&#123;&#39;alpha&#39;:[&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;],&#39;feature1&#39;:[1,1,2,3,3,1], &#39;feature2&#39;:[&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;low&#39;,&#39;high&#39;]&#125;) # 定义df2 df2 = pd.DataFrame(&#123;&#39;alpha&#39;:[&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;F&#39;],&#39;pazham&#39;:[&#39;apple&#39;,&#39;orange&#39;,&#39;pine&#39;,&#39;pear&#39;], &#39;kilo&#39;:[&#39;high&#39;,&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;],&#39;price&#39;:np.array([5,6,5,7])&#125;) # print(df1) # print(df2) # 基于共同列alpha的内连接 df3 = pd.merge(df1,df2,how=&#39;inner&#39;,on=&#39;alpha&#39;) df3 转换主要内容： DataFrame转numpy或dict、list^3 df.values df.as_matrix() np.array(df) DataFrame内类型转换 df.dtypes查看数据类型 astype转换数据类型 df[&#39;col2&#39;] = df[&#39;col2&#39;].astype(&#39;int&#39;) 行列索引操作 sort (按index排序:sort_index; 按value排序:sort_values)，如果只是拿到一个排名Series，使用rank方法 df.sort_index( axis=0, level=None, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, sort_remaining=True, by=None, ) df.sort_values( by, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, ) rename reset_index 舍弃乱的index，重新生成，旧的index会成为一个新的column reindex 行列顺序重新指定，若出现新的行列会NaN填充 result3 = result.reindex(columns=[&#39;A&#39;,&#39;C&#39;]) 常见数学运算 df.describe() cov cor apply applymap apply(fun, axis&#x3D;’index’) ### groupby&amp;Category[^4] Category主要是将长字符串类别名称转为类别标号存储，减少存储空间 ```python pd.Categorical([&#39;a&#39;,&#39;b&#39;]) # or df[&#39;col&#39;].astype(&#39;category&#39;) groupby进行分组操作 df.groupby(Series or &#39;name&#39;) # 根据Series或者name字段分组 其他方法 one-hot(独热编码) pd.get_dummies(series) value_counts 统计某个series每个分类值的数量","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"Chrome插件推荐-V2","slug":"生活/Chrome插件推荐","date":"2020-07-25T05:52:55.000Z","updated":"2023-07-03T15:04:36.963Z","comments":true,"path":"2020/07/25/sheng-huo/chrome-cha-jian-tui-jian/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/25/sheng-huo/chrome-cha-jian-tui-jian/","excerpt":"","text":"Chrome插件推荐-V2今天发现了三个感觉挺有用的（能白嫖的）油猴插件分享一下，由于是油猴插件，因此要先下好油猴，然后再GrassFork上找这些插件 首先介绍下下面三个插件的功能： 文库复制 爱奇艺等视频平台广告加入 播放哔哩哔哩大会员观看电影（带弹幕） 一、文库复制链接 解除网站不允许复制的限制，文本选中后点击复制按钮即可复制，主要用于 百度文库 道客巴巴 无忧考网 学习啦 蓬勃范文 某些网站例如某度文库、道客某某等都不允许用户选中文本进行复制，作为一个搞前端的，就感觉离谱，文本都下载到本地了，还不让我复制，于是为了更好的学(复)习(制)，实现了一个脚本去解决这些限制。 使用方法 二、哔哩哔哩大会员电影播放链接 这个插件的主要原理是在网页哔哩哔哩上播放大会员视频时候将本来视频替换为其他几个视频源的视频，并且弹幕仍然保留。 使用拿前几天哔哩哔哩上架的《天气之子》为例，原本只能看10分钟，加入插件后，视频下方会出现“替换播放器选项”，点击这里并选择插件提供的播放源，就可以边看弹幕边看电影了😁。 三、爱奇艺视频广告加速播放链接 这个插件比较有意思，功能是“控制网页计时器速度|加速跳过页面计时广告|视频快进（慢放）|跳过广告|支持几乎所有网页.”。原来的一些去广告插件爱奇艺等能识别出来并进行拦截。而这个插件使用的时候就是会在视频广告旁边出现加速播放按钮，也可以使用快捷键’ctrl‘+‘-’，加速成64倍或16倍，让原来45秒的广告1秒过，实现半自动去广告的目的。 支持腾讯，优酷，爱奇艺等几乎所有视频网站和用于其他用途的任一网站（其他用途自行研究哦） 原理是控制网页计时器，几乎所有通过计时器实现的内容都可以变速 使用 使用方法： 安装（地址：GreasyFork） 网页左边有悬浮的能量球，鼠标移动过去有加速选项，你可以选择加速或减速，最上面的悬浮球表明现在的倍速 加速跳过某广告后，需要点击最后一个悬浮球恢复默认速度 该插件支持所有的网页限时广告的跳过，如腾讯，爱奇艺，优酷等等。 快捷键操作：’ctrl‘+‘=’ 或 ’ctrl‘+&#39;&gt;&#39; : 倍率+2, ’alt‘+‘=’ 或 ’alt‘+‘&gt;’ : 倍率x4, ’ctrl‘+‘-’ 或 ’ctrl‘+‘&lt;’ : 倍率-2, ’alt‘+‘-’ 或 ’ctrl‘+‘&lt;’ : 倍率&#x2F;4, ’ctrl‘+‘0’ 或 ’alt‘+‘0’ : 倍率恢复为1 在播放视频时，使用该插件可以对视频快进或慢放（注意必须使用 HTML5 视频播放器，Flash 播放器是无效的哦） 目前不太用爱奇艺等视频，简单举个例子。随便打开一个爱奇艺视频，视频左侧会出现几个按键，点击几次“&gt;&gt;”实现视频广告播放加速，当广告结束点”×1”变成正常速度。","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"http://jlutangchuan.github.io/tags/Chrome/"}]},{"title":"从argparse到click","slug":"技术/编程/从argparse到click","date":"2020-07-22T14:54:32.000Z","updated":"2023-07-03T15:04:37.076Z","comments":true,"path":"2020/07/22/ji-zhu/bian-cheng/cong-argparse-dao-click/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/22/ji-zhu/bian-cheng/cong-argparse-dao-click/","excerpt":"","text":"从argparse到click介绍介绍两个命令行传参数模块argparse与Click模块，这两个包的作用都是用来控制向python命令行传参数的 argparse属于自带的库，基本功能都能实现 click属于需要再安装的库，但是使用更加方便(通过装饰器实现)，其设计目标是可以支持灵活的命令嵌套 除此之外，还有很多方式操作这个，最简单的是sys.argv[] argparse基本方法介绍主要流程 在入口文件处加入argparse 注册parser argparse.ArgumentParser parser中添加参数 parser.add_argment 获取args parser.parse_args() 返回的是一个NameSpace(类似对象) add_argment详解基本用法parser.add_argument(&#39;--name&#39;, default=&#39;Great&#39;) parser.add_argument(&#39;-n&#39;, &#39;--name&#39;, default=&#39;None&#39;) 参数 default 默认参数 required 是否必须设置 type 参数类型 choices 一个list中选择 help -h时候会显示 nargs 输入参数数量 评价 比较简洁的方式（三步走：注册、加入参数、解析参数） 当非入口文件需要外部参数只需要在相应文件加入argparse即可 click介绍调用方式python 10-2.click.py --name=tc python 10-2.click.py --name tc 基本用法import click @click.command() @click.option(&#39;--count&#39;, default=1, help=&#39;Number of greetings.&#39;) @click.option(&#39;--name&#39;, prompt=&#39;Your name&#39;, help=&#39;The person to greet.&#39;) def hello(count, name): &quot;&quot;&quot;Simple program that greets NAME for a total of COUNT times.&quot;&quot;&quot; for x in range(count): click.echo(&#39;Hello %s!&#39; % name) if __name__ == &#39;__main__&#39;: hello() @click.command() 使函数 hello 成为命令行接口； @click.option 的第一个参数指定了命令行选项的名称，可以看到，count 的默认值是 1； 使用 click.echo 进行输出是为了获得更好的兼容性，因为 print 在 Python2 和 Python3 的用法有些差别。 其他方法 click.group Click还提供了group方法，该方法可以添加多个子命令 import click @click.group() def first(): print(&quot;hello world&quot;) @click.command() @click.option(&quot;--name&quot;, help=&quot;the name&quot;) def second(name): print(&quot;this is second: &#123;&#125;&quot;.format(name)) @click.command() def third(): print(&quot;this is third&quot;) first.add_command(second) first.add_command(third) first() $ python test.py second --name hh # 输出 hello world this is second: hh 相比argparse的扩充功能 argparse的choices只能从几个中选择，click的IntRange可以实现多个选择 命令的任意嵌套 密码输入时命令行加密 @click.option(&#39;-p&#39;,prompt=&#39;Your Password&#39;,hide_input=True,confirmation_prompt=True)","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"热风·随感录·四十一","slug":"诗词/热风-鲁迅","date":"2020-07-21T16:32:54.000Z","updated":"2023-07-03T15:04:36.954Z","comments":true,"path":"2020/07/22/shi-ci/re-feng-lu-xun/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/22/shi-ci/re-feng-lu-xun/","excerpt":"Here's something encrypted, password is required to continue reading.","text":"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 Hey, password is required here.","raw":null,"content":null,"categories":[{"name":"诗词","slug":"诗词","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%97%E8%AF%8D/"}],"tags":[]},{"title":"Shell学习","slug":"技术/编程/Shell学习","date":"2020-07-15T15:38:52.000Z","updated":"2023-07-03T15:04:37.062Z","comments":true,"path":"2020/07/15/ji-zhu/bian-cheng/shell-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/15/ji-zhu/bian-cheng/shell-xue-xi/","excerpt":"","text":"Shell学习 2020.07.15 最近开始做一些程序自动化的代码，重新温习一下shell语法 另外发现了一个hexo的解析问题：{和$不能连在一起 Linux shell推荐工具：tmux+zsh tmux实现终端复用，zsh中可以再装一些插件提高开发效率，而且界面也好看一些 基础 程序运行 运行shell ./run.sh # 注意是./run.sh而不是run.sh windows下运行shell 使用git bash 设置要调用的shell解释器 #!/bin/bash 设置shell脚本权限 由于默认创建的sh没有执行权限，因此需要chmod chmod +x run.sh 调用shell时附加参数 sh run.sh 0 abcd 123 echo $&#123;0&#125; # run.sh echo $&#123;1&#125; # 0 echo $# # 3 （3个参数） 变量 临时环境变量与永久环境变量 临时环境变量为一般环境变量，随控制台生灭 永久环境变量分为：系统变量、用户变量 /etc/profile # 系统变量文件 $HOME/.bash_profile # 用户变量文件 # 常见变量 $HOME $PATH $PWD 注：.bashrc 与 .bash_profile的区别，bashrc中的内容在每次开启新的控制台都会执行一次，关闭时也会跟着结束（临时变量） .bash_profile在用户登录时执行，属于永久变量 定义 name=&quot;tangchuan&quot; # 注意=不能有空格 arr=(1 2 3 4 5) # 注意是空格不是逗号 使用 在定义的变量面前加 $name echo $name echo $ &#123;a[0]&#125; echo $ &#123;a[@]&#125; # 输出全部元素 echo $ &#123;#a[@]&#125; # 计数 类型 类型 code 字符串 &#39;this is a string&#39; &quot;My name is $&#123;name&#125;&quot; 数组 a=(1 2 &#39;?&#39; &#39;hello&#39;) 注：字符串单双引号的区别，单引号中不能再出现单引号，双引号中可以插入变量 $&#123;var&#125; 运算\\* # 乘号需要转义 [ expression ] # 条件命令 等同于 test expression [ 1 == 1 ] ;echo $? # 返回上一个命令的返回值0表示true，1表示false 分号是命令连接号 整数比较符号-eq-ge-le-lt-gt-ne 其他 注释 # 特殊符号，见参考link 控制1. 条件if [ 条件判断式1 ] then 当条件判断式1成立时，执行程序1 elif [ 条件判断式2 ] then 当条件判断式2成立时，执行程序2 else 当所有条件都不成立时，最后执行此程序 fi 2. 循环for循环# for in for N in 1 2 3 do echo $N done # for((i=0;i&lt;=5;i++)) while循环while expression do done 函数 自定义函数 func() &#123; val=$0 return $&#123;val&#125; &#125; # 调用 func &quot;hello world&quot; 常用函数 函数名 用途 echo print $&#123; #string&#125; 输出字符串长度 $&#123;dtring:1:4&#125; 提取字符串 set 展示所有变量 unset NAME 删除某一个变量 export NAME&#x3D;value 声明环境变量（当前shell以及子shell） Reference blog https://www.jb51.net/article/120595.htm","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://jlutangchuan.github.io/tags/shell/"}]},{"title":"常见逻辑谬误","slug":"技术/理论/常见逻辑谬误","date":"2020-07-13T16:06:16.000Z","updated":"2023-07-03T15:04:37.027Z","comments":true,"path":"2020/07/14/ji-zhu/li-lun/chang-jian-luo-ji-miu-wu/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/14/ji-zhu/li-lun/chang-jian-luo-ji-miu-wu/","excerpt":"","text":"常见逻辑谬误之前看到的一篇关于科研中常见谬误的博客，想整理一下 科研是一种理性思维的活动。科学家通过观察与实验，描述客观世界，获得科学事实。常见的科研逻辑有分析与综合，归纳与演绎，比较与类比。 然而，并非每一种逻辑思维方法，都能保证获得的结论为真。 为了避免落入陷阱，作为新入行的科研工作者，尤其需要留心一些科研中常见的逻辑谬误： 01 诉诸权威02 肯定后件与否定前件03 以偏概全04 事后归因05 相关即因果06 证实性偏见07 稻草人谬误08 滥用统计09 滑坡谬误10 循环论证 十种常见逻辑谬误一、诉诸权威这个大致的意思是直接将别人的观点当做结论来进行自己工作的先验，典型的有盲目崇拜高影响因子的文章、未分析别人的结论是否能直接拿来用？ 二、肯定后件与否定前件这个是运用演绎法不当导致的错误，演绎法是指从一般推理到特殊的一种推理过程，正确的运用方法有两种：1. 前提由一般到特殊 2. 从结论的特殊否定对到前提的否定。 三、以偏概全感觉这是非常常见的逻辑谬误，很多工作往往只做了很少次实验但是为了体现出工作的杰出就给出非常普适的结论，用一个通俗的例子来讲：观察到两三只乌鸦是黑色的，就立即得出结论，天下乌鸦一般黑。 和演绎法相对归纳是从一般到特殊的过程，但是归纳并不能保证结论总是对的，比较有代表性的有现代医学研究，在分析一种药物是否有作用时，需要强调大样本多中心，随机、双盲、对照实验等因素。 四、事后归因事后归因的意思是： B事件发生在A之后（即A在B前），因此认为A是B的原因。这种谬误还能表达成“A发生在B之前，因此避免A则能阻止B”的形式。 这个告诉我们，我不能根据事件的发生先后来强加因果 五、相关即因果这个逻辑谬误也很常见，通常有观察到两个变量A、B具有相关性，就想当然的认为变量B的变化是受变量A引起的，强加因果。实际上两个变量具有相关性可能有多种形式：1. 变量a影响变量b；2. 变量b影响变量a；3. 变量a和变量b同时受其他未观察的变量影响 六、证实性偏见 这种谬误是指，倾向性地选择对自己有利的论据，而无视不利的证据。这种逻辑谬误在日常生活中相当常见。比如觉得星座运势说得好准，觉得暗恋对象的一举一动都是为了吸引自己而做，诸如此类。 七、稻草人谬误 与证实性偏见具有关联性的，是稻草人谬误。它是一种曲解所要否定的论点，重新树立一个毫不相关的靶子（稻草人）并加以攻击，以声称推翻了对方观点的逻辑谬误。 八、滥用统计这里的滥用统计是指我们对统计的数据进行错误解释，比如观测到改动实验的平均recall高于baseline的平均recall就直接说改进有效果，这种观测推导出结论是不正确的，因为有可能这个实验召回率的不确定性本身就很高，用平均数来描述偏峰分布的数据，Y轴不从零开始从视觉上夸大组间的差异，故意截取一小段X轴从视觉上营造相关性。另一个例子是，我们只取了某个参数在很小一段范围内进行搜参发现这段范围内参数值和recall正相关，就直接说这个参数越大、recall越大（同时也犯了以偏概全的错误）。 九、滑坡谬误这个逻辑谬误也很常见： 举个例子：不读书的人没文化，没文化的人不讲理，不讲理的人激化社会矛盾，社会矛盾激化会引发战争；为了避免战争，应该把不读书的人判死刑。我们可以看到，这个推理过程，每走一步，都存在着犯错误的风险，越往后推，错误的几率就会越来越大，最终得到荒谬的结论。 在逻辑的推导时忘记了概率的传递越传越小，从而推导出很荒谬的结论。 十、循环论证想要证明某个结论，直接将一个未证实的前提来进行推导，最后发现当承认了前提就相当于承认了结论，当承认了结论也能证明前提。 这种逻辑谬误非常低级，通常可以一眼看穿。然而就连大名鼎鼎的牛顿，也曾犯这种逻辑谬误。他曾用密度来定义质量，然而密度本身却依然需要质量来定义。（不过，质量定义这个话题迄今尚未完全终结，这里也并非苛求前人。） 总结做一个简单的归类 和前提有关的谬误 诉诸权威 循环论证 和推导有关的谬误 肯定后件与否定前件 以偏概全 滑坡谬误 分析过程中的谬误 相关即因果 事后归因 证实性偏见 稻草人谬误 滥用统计 Reference 科研工作者有哪些「新手常见错误」？ - 真知拙见KnowledgeHot的回答 - 知乎 https://www.zhihu.com/question/340495864/answer/1042743446","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://jlutangchuan.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[]},{"title":"前缘","slug":"诗词/前缘-席慕容","date":"2020-07-09T13:06:02.000Z","updated":"2023-07-03T15:04:36.952Z","comments":true,"path":"2020/07/09/shi-ci/qian-yuan-xi-mu-rong/","link":"","permalink":"http://jlutangchuan.github.io/2020/07/09/shi-ci/qian-yuan-xi-mu-rong/","excerpt":"","text":"前缘人若真能转世 世间若真有轮回那麽 我的爱 我们前世曾经是什麽 你 若曾是江南采莲的女子我 必是你皓腕下错过的那朵 你 若曾是逃学的顽童我 必是从你袋中掉下的那颗崭新的弹珠在路旁的草丛中目送你毫不知情地远去 你若曾是面壁的高僧我必是殿前的那一柱香焚烧著 陪伴过你一段静默的时光 因此 今生相逢 总觉得有些前缘未尽却又很恍忽 无法仔细地去分辨无法一一地向你说出","raw":null,"content":null,"categories":[{"name":"诗词","slug":"诗词","permalink":"http://jlutangchuan.github.io/categories/%E8%AF%97%E8%AF%8D/"}],"tags":[{"name":"席慕容","slug":"席慕容","permalink":"http://jlutangchuan.github.io/tags/%E5%B8%AD%E6%85%95%E5%AE%B9/"}]},{"title":"解决hexo图床问题","slug":"技术/编程/解决hexo图床问题","date":"2020-06-10T14:21:16.000Z","updated":"2023-07-03T15:04:37.081Z","comments":true,"path":"2020/06/10/ji-zhu/bian-cheng/jie-jue-hexo-tu-chuang-wen-ti/","link":"","permalink":"http://jlutangchuan.github.io/2020/06/10/ji-zhu/bian-cheng/jie-jue-hexo-tu-chuang-wen-ti/","excerpt":"","text":"解决hexo图床问题目前采用的是typora+picgo+github图床的方式，在github中创建一个repo链接到picgo，新版typora支持使用picGo上传图片，比较方便，具体方式可在网上找。 使用后可能存在一个问题：如果不挂VPN仍然显示不出图片，这是因为raw.githubusercontent.com的IP地址找不到，需要手动在host文件中添加其地址，Win10中host文件位置 C:\\Windows\\System32\\drivers\\etc raw.githubusercontent.com的IP地址如下（可以ping一下或者在IPAddress中搜索） 199.232.68.133 raw.githubusercontent.com","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://jlutangchuan.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"http://jlutangchuan.github.io/tags/Blog/"}]},{"title":"TensorFlow2学习 - 0.Overall & 1.Model","slug":"技术/编程/TensorFlow2学习-1","date":"2020-06-09T10:44:04.000Z","updated":"2023-07-03T15:04:37.065Z","comments":true,"path":"2020/06/09/ji-zhu/bian-cheng/tensorflow2-xue-xi-1/","link":"","permalink":"http://jlutangchuan.github.io/2020/06/09/ji-zhu/bian-cheng/tensorflow2-xue-xi-1/","excerpt":"","text":"TensorFlow2学习 - 0.Overall & 1.Model Q1：学习目标？ A1：了解新版TensorFlow的主要模块，能够完成数据预处理、模型搭建、模型训练、监控等功能的实现；感受一个机器学习框架的设计结构 Q2：怎么学？ A2：此前按照一些网课粗略地学习了一些，当前阶段计划从TF官网的API文档和Keras的API文档中学习 Q3：学习重点？ A3：主要是tf.keras部分的使用 Q4：如何介绍一个class？ A4： Describe a class with a few words list key methods(usage、parameters、return) list key attributes how to subclass it? modules list Tensor &amp; opr tf.keras tf.data TensorBoard tf.kerasContent Models Layers Activations Callback Funcs Data preprocessing Optimizers Metrics Losses Datasets Backbones Models主要内容 how to subclass a Model class? Sequential how to train a model? save &amp; load a model tf.keras.ModelDescription通常将一个网络模型用Model封装 如果比较简单可以用Sequential或Model方法描述输入输出流程 如果模型比较复杂会实现一个继承子类 Method Model(inputs,outputs,name)tf.keras.Model()是Model类的构造函数，如果直接用这个构造函数来建立模型，一般需定义tf.keras.Input作为inputs，再实现计算过程，将out作为Model的outputs import tensorflow as tf inputs = tf.keras.Input(shape=(3,)) x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs) outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x) model = tf.keras.Model(inputs=inputs, outputs=outputs) model.summary() 输出网络结构（主要是各层的name以及维度），可以选择print_fn model.get_layer(name = None, index = None) 用name或index获取某一层 Attribute model.weight 列出模型中所有权值（可训练的+不可训练的） Subclass继承Model需要实现__init__方法和call方法 其中__init__主要是定义一些layer或者其他设置，并且要显示调用父类的初始化函数super(MyModel, self).__init__() call有两个形参：inputs和training(boolean)，此处实现用inputs计算outputs的过程，返回outputs import tensorflow as tf class MyModel(tf.keras.Model): def __init__(self): super(MyModel, self).__init__() self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu) self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax) def call(self, inputs): x = self.dense1(inputs) return self.dense2(x) model = MyModel() tf.keras.SequentialDescription用来封装线性堆叠层的模型，应该继承自Model model = tf.keras.Sequential() model.add(tf.keras.layers.Dense(8, input_shape=(16,))) model.add(tf.keras.layers.Dense(4)) Method Sequential.add(layer) Sequential.pop() 弹出最后一层 Sequential.build() 可能add时没有指定输入数据的维度，需要build显示指定一下 Training APIsDescription compile fit evluate predict train_on_batch test_on_batch predict_on_batch Method compile 配置训练过程，此处需要指定：优化器、损失、metric等 Model.compile( optimizer=&quot;rmsprop&quot;, loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, **kwargs ) fit 进行模型训练，此处需要指定：数据、标注、batch_size、epoch、callback等 Model.fit( x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, ) x：numpy tensor tf.data generator keras.utils.Sequence y：当x中有标注时y可以不用指定 shuffle initial_epoch：integer workers：多worker供数据，需要数据是generator或keras.utils.Sequence类型 use_multiprocessing：多进程供数据 Return：返回History 主要记录每一次epoch训练的结果，结果包含loss以及acc的值 evluate 通常在fit后做evluate，拿到一些结果指标，默认返回loss和metric组成的list，也可以设置返回dict Model.evaluate( x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, ) predict 如果数据量比较小，可以直接用 model(x), or model(x, training=False) Model.predict( x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, ) train_on_batch test_on_batch predict_on_batch train or test or predict a single batch Model.train_on_batch( x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False, ) Model.test_on_batch( x, y=None, sample_weight=None, reset_metrics=True, return_dict=False ) Model.predict_on_batch(x) Save &amp; Load主要介绍模型的加载与保存 TensorFlow保存格式为hdf5或tf，一般1.x版默认保存格式为h5，2.x版本默认保存为tf，时间+epoch+loss为文件名 Mothods Model.save 保存网络的拓扑逻辑、参数、优化状态 Model.save( filepath, overwrite=True, include_optimizer=True, save_format=None, # &#39;tf&#39; or &#39;h5&#39; signatures=None, options=None, ) tf.keras.models.load_model tf.keras.models.load_model(filepath, custom_objects=None, compile=True) clone_model 拷贝一个网络 tf.keras.models.clone_model(model, input_tensors=None, clone_function=None) others 如果有需求比如只初始化网络头部，可以尝试get_weights、set_weights、load_weights等","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://jlutangchuan.github.io/tags/TensorFlow/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"http://jlutangchuan.github.io/tags/DeepLearning/"}]},{"title":"python 装饰器","slug":"技术/编程/python-装饰器","date":"2020-02-29T03:52:07.000Z","updated":"2023-07-03T15:04:37.053Z","comments":true,"path":"2020/02/29/ji-zhu/bian-cheng/python-zhuang-shi-qi/","link":"","permalink":"http://jlutangchuan.github.io/2020/02/29/ji-zhu/bian-cheng/python-zhuang-shi-qi/","excerpt":"","text":"Python装饰器模式Decorator in Design Pattern打开设计模式课的PPT，看到了当初老师讲的老虎的例子 Tiger属于Animals类，继承了Eat方法，目前的需求是Tiger中有一种TigerA在Eat前后额外的动作，比如Eat前后有Drink，为尽可能地重用代码、降低耦合、可替换等设计原则，将新的类用装饰器模式封装，类图如下 老师总结的优缺点 优点： 保持抽象层上关系的稳定； 比单独使用组合或继承灵活； 随时扩展功能或职责； 不足： 可能产生许多更小的子类； Component类过大时，效率较低，此时可考虑使用策略模式 嵌套很多比较复杂（多层装饰器） Decorator in PythonAspect-Oriented Programming面向切面编程，在函数进入或退出时不断加入新方法。此前遇到的case：js常用编程方法callback以实现加入新的相应 装饰器介绍​ python中有函数装饰器和类装饰器，此外functool中也有wraps 装饰器本质上是一个Python函数,它可以让其他函数在不需要做任何代码变动的前提下增加额外功能,装饰器的返回值也是一个函数对象 它经常用于有切面需求的场景,比如:插入日志 性能测试 事务处理 缓存 权限校验等场景 装饰器是解决这类问题的绝佳设计,有了装饰器,我们就可以抽离出大量与函数功能本身无关的雷同代码并继续重用 概括的讲,装饰器的作用就是为已经存在的对象添加额外的功能。 Usage函数装饰器原始代码 def foo(): print(&#39;i am foo&#39;) 新需求：在foo函数中追加日志需求，并且这种日志需求后续可能在其他函数中也要用到 改动v1 ——- 本人常做的：） def foo(): print(&#39;i am foo&#39;) logging.info(&quot;foo is running&quot;) 存在的问题：1. 后续无法重用 2. 改变了原有代码 改动v2 ——- 简单的装饰器 def use logging(func): logging.warn(&quot;%s is running&quot; % func. name ) func() def bar(): print(&#39;i am bar&#39;) use_logging(bar) 存在的问题：1. 改变了上层的调用 改动v3 ——- 真正的python装饰器，python为其添加了语法糖@ def use_logging(func): def wrapper(*args, **kwargs): logging.warn(&quot;%s is running&quot; % func. name ) return func(*args) return wrapper @use_logging def foo(): print(&quot;i am foo&quot;) @use_logging def bar(): print(&quot;i am bar&quot;) bar() 执行bar()，就相当于执行use_logging(bar)()，此时原来的代码内部我们没有做改动，上层的调用也不需要改 带参数装饰器装饰器变成三层函数，最外面一层接受装饰器的参数，中间层接受被装饰的函数，最里面层接受被装饰的函数的参数（通常用*args和**kwargs接受） import functools def log_with_param(text): def decorator(func): @functools.wraps(func) def wrapper(*args, **kwargs): print(&#39;call %s():&#39; % func.__name__) print(&#39;args = &#123;&#125;&#39;.format(*args)) print(&#39;log_param = &#123;&#125;&#39;.format(text)) return func(*args, **kwargs) return wrapper return decorator @log_with_param(&quot;param&quot;) def test_with_param(p): print(test_with_param.__name__) 多装饰器@wrap1 @wrap2 def func(): pass functools.wraps目的：原来的装饰器在打印函数的__name__等内置变量时都显示的是装饰器的；使用functools.wraps可以解决这个问题。 相当于functools.wraps来将这些内置变量改写成被装饰函数的内置变量 import functools def log(func): @functools.wraps(func) def wrapper(*args, **kwargs): print(&#39;call %s():&#39; % func.__name__) print(&#39;args = &#123;&#125;&#39;.format(*args)) return func(*args, **kwargs) return wrapper 类装饰器 类装饰器的意思是用一个装饰器类来装饰一个函数，这个类必须实现__init__和__call__内置函数 __init__ ：接收被装饰函数 __call__ ：实现装饰逻辑 class logger(object): def __init__(self, level=&#39;INFO&#39;): self.level = level def __call__(self, func): # 接受函数 def wrapper(*args, **kwargs): print(&quot;[&#123;level&#125;]: the function &#123;func&#125;() is running...&quot;\\ .format(level=self.level, func=func.__name__)) func(*args, **kwargs) return wrapper #返回函数 @logger(level=&#39;WARNING&#39;) def say(something): print(&quot;say &#123;&#125;!&quot;.format(something)) say(&quot;hello&quot;) 绝大多数装饰器都是基于函数和闭包实现的，但这并非制造装饰器的唯一方式。 事实上，Python 对某个对象是否能通过装饰器（ @decorator）形式使用只有一个要求：decorator 必须是一个“可被调用（callable）的对象。 对于这个 callable 对象，我们最熟悉的就是函数了。 除函数之外，类也可以是 callable 对象，只要实现了__call__ 函数，还有比较少人使用的偏函数也是 callable 对象。 Appendix*args, **kwargs *args表示任何多个无名参数，它是一个tuple；**kwargs表示关键字参数，它是一个dict。并且同时使用*args和**kwargs时，必须*args参数列要在**kwargs前，像foo(a=1, b=&#39;2&#39;, c=3, a&#39;, 1, None, )这样调用的话，会提示语法错误“SyntaxError: non-keyword arg after keyword arg”。 args 是一个tuple，*args是多个参数；同理kwargs是dict，**kwargs是多个关键字参数 关键字参数就是在调用时标记形参名的参数，如 func(3,b=1,c=&#39;hello&#39;)，这里3是无名参数，b和c是关键字参数 args和kwargs常用在装饰器模式等切面编程中以及一些参数个数任意的函数 Reference 如何理解Python装饰器 Gain 设计模式真的是需要自己再认真学习的一个topic，初次在课堂上学习的时候只是认识了每个模式是什么，属于哪个型，判断这段代码用的是什么模式，优缺点；没有去想这种模式提出是为了解决什么问题，这个模式的独特性在哪里；当自己要写代码的时候，脑子里没有设计模式的思想。","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"}]},{"title":"conda创建虚拟环境","slug":"技术/编程/conda创建虚拟环境","date":"2020-02-22T03:39:33.000Z","updated":"2023-07-03T15:04:37.032Z","comments":true,"path":"2020/02/22/ji-zhu/bian-cheng/conda-chuang-jian-xu-ni-huan-jing/","link":"","permalink":"http://jlutangchuan.github.io/2020/02/22/ji-zhu/bian-cheng/conda-chuang-jian-xu-ni-huan-jing/","excerpt":"","text":"Conda 创建虚拟环境 查看目前都有哪些环境 conda env list 建立一个新环境 conda create -n xxxx python=3.5 激活这个环境 conda activate xxxx 删除某个环境 conda remove -n xxxx 把某个环境设置为默认 修改环境变量 C:\\ProgramData\\Anaconda3\\Scripts -&gt; C:\\ProgramData\\Anaconda3\\envs\\xxxx\\Scripts C:\\ProgramData\\Anaconda3 -&gt; C:\\ProgramData\\Anaconda3\\envs\\xxxx 清理无用包 conda clean -p //删除没有用的包 conda clean -t //tar打包 安装ipykernal可以在notebook上运行其他conda虚拟环境","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jlutangchuan.github.io/tags/Python/"},{"name":"conda","slug":"conda","permalink":"http://jlutangchuan.github.io/tags/conda/"}]},{"title":"Chrome & VS Code插件推荐","slug":"生活/Chrome & VS Code插件推荐","date":"2020-02-18T15:33:51.000Z","updated":"2023-07-03T15:04:36.961Z","comments":true,"path":"2020/02/18/sheng-huo/chrome-vs-code-cha-jian-tui-jian/","link":"","permalink":"http://jlutangchuan.github.io/2020/02/18/sheng-huo/chrome-vs-code-cha-jian-tui-jian/","excerpt":"","text":"Chrome &amp; VS Code插件推荐 推荐几个自己用的插件 获取地址：如果能访问外网，Chrome Web Store直接搜；如果不能，好像有个Chrome中文插件网，在这装谷歌访问助手。 插件英雄榜github上13k的一个项目，推荐了一些好的插件 VS Code插件主要是根据自己写什么语言的code来配 Chrome插件 1. Tampermonkey 油猴号称最强的浏览器插件绝非浪得虚名，一个油猴抵得上数十个一般插件也并不是在开玩笑. 油猴上推荐的插件 安装完油猴后，点击油猴图标，点获取脚本，会显示几个获取脚本的途径，本人常用GreasyFork；由于目前自己电脑重装了一次，插件不多了 懒人专用，全网VIP视频免费破解去广告、全网音乐直接下载、百度网盘直接下载、知乎视频下载等多合一版（看着下载量最多就下了） 百度网盘直接下载插件（自己搜，看哪个最近更新了装哪个） 百度网盘提取码插件（同上） 2. Adblock 防一刀999，但是知乎好像能检测出来，可以单独禁掉 3. SmallPDF Small PDF 还有一个 ConvertIO，格式转换的在线工具 4. 单词发现者 今天刚在github上发现的，能把网页上的低频词汇高亮，感觉对学习英语有帮助。但是由于其本身的查词是页面跳转的查词，不是很方便，所以我关掉了它的弹出菜单，而是配合下面的沙拉查词。 5. 沙拉查词 能显示多个词典的词义 相应非常快，比有道的相应还要快 界面自定义丰富 可以设置使本地pdf文件也能在Chrome上浏览查词 能加入生词本，好像可以配合扇贝单词以及anki（之前一直想搞这个anki+kindle的生词本，但是苦于电脑端的生词不知道怎么一起同步） 6. 远方New tab 启动页，美观一些 但是原始的启动页其实看久了也还行 7. IDM for Chrome IDM感觉下载速度比普通下载快，可能是IDM多线程多任务做得好。 由于IDM是付费软件，不想付钱就得破解 装IDM应该哔哩哔哩上有教学视频 VS Code插件1. Chinese2. Windows opacity可以让VS Code变得透明（透明度在setting.json中可调） 3. Markdown All in OneCtrl + Shift + V 切换预览\\编辑 但目前我写MD用Typora，一个本地程序，优点是可以设置自动将复制的图片保存在指定位置，缺点是本地，如果发布博客插图有点麻烦。 4. Python目前的Python支持Notebook，直接在VS Code中写ipynb挺方便的 5. autoDocstring培养个人的写注释习惯，Tab切下一个[ ] 。但好像只针对Python def make_data(data1,data2,dicts): &quot;&quot;&quot;[summary] Arguments: data1 &#123;[type]&#125; -- [description] data2 &#123;[type]&#125; -- [description] dicts &#123;[type]&#125; -- [description] Returns: [type] -- [description] &quot;&quot;&quot; 6. GitLens强烈推荐！！！对于自己这个git小白，记git上的所有命令的代码很难，这个插件可以在VScode中帮助我们图形化管理我们的项目，而且能看到我们的每行代码是什么时候提交的，谁写的，也方便比较不同版本的code 7. vscode-icons美化不同后缀的文件图标 8. LeetCode在VS Code中直接做题，Submit Test直接点就可以，很方便；而且这里面对题按照难度和数据结构都分好类。 9. indent-rainbow美化编辑器 10. background如果觉得VS Code界面太单调，你可以用这个插件在VS Code中插张png图，透明度，位置大小均可调。","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://jlutangchuan.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"http://jlutangchuan.github.io/tags/Chrome/"},{"name":"VSCode","slug":"VSCode","permalink":"http://jlutangchuan.github.io/tags/VSCode/"}]},{"title":"朴素贝叶斯","slug":"技术/理论/机器学习/朴素贝叶斯","date":"2020-02-13T14:57:42.000Z","updated":"2023-07-03T15:04:37.091Z","comments":true,"path":"2020/02/13/ji-zhu/li-lun/ji-qi-xue-xi/po-su-bei-xie-si/","link":"","permalink":"http://jlutangchuan.github.io/2020/02/13/ji-zhu/li-lun/ji-qi-xue-xi/po-su-bei-xie-si/","excerpt":"","text":"朴素贝叶斯参数估计离散输入空间下MLE推导 百度 朴素贝叶斯 极大似然估计 推导这个是李航书上的课后题 Q &amp; A 朴素贝叶斯中为什么将 $P(X&#x3D;x_j|Y&#x3D;y_i)$ 视为“似然”？ 似然是针对估计概率模型的参数说的，这里的概率模型就是 $X^{(i)}|Y$ 服从多类分布，待估计参数也就是每个类别的概率计算完每个特征的似然后，我们在此基础上加入条件独立假设，得到总的似然数据在这里一方面让我们获得先验该率 $P(Y)$ （其实这里我们也是假设Y服从多类分布，再用MLE），一方面给我们计算概率模型的参数提供数据 为什么计算后验概率不直接将数据的频率作为概率? 我们采用的是贝叶斯统计而不是频率统计，贝叶斯统计的核心是使用观测不断更新先验。 后验概率有时不好取得，比如说考察癌症检测试剂的精确率，X表示试剂检测阳性，$Y_0$和$Y_1$分别表示是癌症或不是癌症；$P(X|Y_0)$和$P(X|Y_1)$非常好统计，拿一些癌症病人和正常人测下试剂就行，但是$P(Y|X)$不好统计，因为这要求我们需要从全人群中抽样并且需要知道每个人是否是癌症 如果我们采用频率也就是将后验视为一个条件概率来考虑，会出现以下问题 特征数很多、特征空间很大时，我们需要遍历所有特征空间上的点，计算每种情况上的频率作为 $P(Y&#x3D;y_k|X&#x3D;x_i)$ ，时间上不允许 当特征空间并非远大于样本空间时，由于样本数少，样本在特征空间上很稀疏，采用频率的方法会不准确 朴素贝叶斯有什么优势? 计算速度快，时间复杂度低 方便引入新的特征 $P(Y &#x3D; y_i)$ 和 $P(Y &#x3D; c_k)$ 区别？ 一个表示随机变量Y取特定值 $y_i$ 的概率，另一个表示随机变量取值和样本 $c_k$ 相同的概率 待学习 贝叶斯估计 迪利克雷分布 MAP有什么意义？","raw":null,"content":null,"categories":[{"name":"数学","slug":"数学","permalink":"http://jlutangchuan.github.io/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"MachineLearning","slug":"MachineLearning","permalink":"http://jlutangchuan.github.io/tags/MachineLearning/"},{"name":"BayesTheorem","slug":"BayesTheorem","permalink":"http://jlutangchuan.github.io/tags/BayesTheorem/"}]},{"title":"贝叶斯定理学习","slug":"技术/理论/机器学习/贝叶斯定理学习","date":"2020-01-30T03:43:16.000Z","updated":"2023-07-03T15:04:37.097Z","comments":true,"path":"2020/01/30/ji-zhu/li-lun/ji-qi-xue-xi/bei-xie-si-ding-li-xue-xi/","link":"","permalink":"http://jlutangchuan.github.io/2020/01/30/ji-zhu/li-lun/ji-qi-xue-xi/bei-xie-si-ding-li-xue-xi/","excerpt":"","text":"Bayes Theorem 最近看了3b1b发的贝叶斯定理的课程。以前对于这些概念一直很模糊，尤其是贝叶斯公式，只能把数带进去做题，不能理解这个公式的更深层次的意义，而且概率统计这门课年代久远，当初自己也是自学（当初对于这些意义重要于公式的知识自己也没有很深入地去思考），并且贝叶斯定理对于机器学习意义重大，所以再学一学，尝试理解得本质一些。 维基百科NB！！！概念性的资料不要看博客知乎百度百科！！！ 我觉得自己对于这个知识点的模糊是因为不理解贝叶斯统计和频率统计的区别，概率论各个理论之间的关系后面还需认真总结 Level of Understanding What is it saying? just can plug in numbers Why is it true? When is it useful? Notion Evidence 证据：能够帮助我们更新对于假设估计的事件 Hypothesis 假设：我们期望分析的对象，通常有多种互斥的假设，我们需要分析在给定证据下最可能为真的假设 Prior 先验概率，根据以往经验得到的概率，可以是来自于对于历史信息的统计、背景信息 在未考虑相关证据时得到的概率 Posterior 在贝叶斯统计中，随机事件的后验概率是在考虑相关证据或数据后得到的条件概率 Likelihood 语义上，likelihood 和probability意思相近 似然：表示在已知证据下概率模型中参数的似然性，用概率描述为 $P(E|\\theta)$， 记为 $L(\\theta;E)$ 在估计概率分布的参数模型下，似然函数的值等于 ,即$L(\\theta;D)&#x3D;f_{\\theta}(D)$ 注：不区分$P(A;B)$ 与 $P(A|B)$ 概率模型：用来描述不同随机变量之间关系的数学模型 参数：概率模型中需要未确定的量 极大似然估计：源于频率学派，认为概率模型的参数是一个定值，这个值可以用频率表示或解方程得到，估计最大似然的参数作为当前证据下的概率模型参数（数据（证据）决定参数取值） 最大后验概率估计：源于贝叶斯派，认为概率模型是不确定的，为简化认为概率模型的参数是随机变量，我们最终确定的参数值是其中参数的后验概率中最大的值，因此叫MAP（数据更新参数取值） 如把先验假设去掉，或者假设先验满足均匀分布的话，MLE和MAP一致 Formula 公式$$P(H|E)&#x3D;\\frac{P(H) P(E|H)}{P(H) P(E|H) + P(\\neg H) P(E|\\neg H)}$$ 直观理解 $P(H|E)$ 按照一般的解释为：事件E发生的情况下事件H发生(为真)的概率，在贝叶斯公式中也称为H的后验概率； $$posterior &#x3D; \\frac{likelihood \\times prior}{evidence}$$ 这个公式的推导是根据条件概率公式和全概率公式得到的，直观理解是后验概率由似然和先验共同决定； Think more 贝叶斯统计 通常我们要分析的问题是在已知证据E下，最可能发生的假设，也就是计算 最大后验概率 $$\\hat H &#x3D; argmax_{H_i}{P(H_i|E)}$$ 以往的思维习惯是根据似然 $P(E|H)$ 和 $P(E|\\neg H)$ 的相对大小来推测在证据E下，假设H（概率模型参数）为真为假的可能性（在概率模型参数估计问题下，我们容易把 $P(\\theta|D)$和 $P(D|\\theta)$ 搞混，也就是把似然当做后验） $$P(H|E)_{Inertial \\ thinking} &#x3D; \\frac{P(E|H)}{P(E|H) + P(E|\\neg H)}$$ 上面思考方式的缺陷是我们默认了每种假设是等可能分布的，也就是我们没有分析先验的概率分布情况； 贝叶斯定理告诉我们，分析 $P(H|E)$ 时，应当兼顾先验概率与似然，也就是在已有的思维方式上加入对于先验的思考。当我们考虑的证据与假设不相关时，新的证据并不会更新先验，也就是后验概率此时等于先验概率（无关证据不会影响我们对于结果的看法）。 $$posterior \\propto likelihood \\times prior$$ $$P(H|E)_{Bayes \\ Theorem}&#x3D;\\frac{P(H) P(E|H)}{P(H) P(E|H) + P(\\neg H) P(E|\\neg H)}$$ The key mantra underlying Bayes’ theorem is that new evidence does not completely determine your beliefs in a vacuum; it should update prior beliefs. 证据不能决定你的看法，而是更新你的看法 Appendix 一些概率论相关的知识点 Probability axioms 概率公理 又叫Kolmogorov Axioms The assumptions as to setting up the axioms can be summarised as follows: Let (Ω, F, P) be a measure space with P being the probability of some event E, denoted $ P(E)$}, and $P(\\Omega ) &#x3D; 1$ . Then (Ω, F, P) is a probability space, with sample space Ω, event space F and probability measure P. 定义概率空间 (Ω, F, P)，F为事件空间，P为概率观测，Ω为抽样空间，其本身也是一个测量空间 First axiomThe probability of an event is a non-negative real number: $$ P(E)\\in \\mathbb {R} ,P(E)\\geq 0\\qquad \\forall E\\in F $$ where $F$ is the event space. It follows that $P(E)$ is always finite, in contrast with more general measure theory. Theories which assign negative probability relax the first axiom. 非负性 Second axiomSee also: Unitarity (physics) This is the assumption of unit measure: that the probability that at least one of the elementary events in the entire sample space will occur is 1$$ P(\\Omega )&#x3D;1 $$全一性 Third axiomThis is the assumption of σ-additivity:Any countable sequence of disjoint sets (synonymous with mutually exclusive events) $E_{1},E_{2}\\ldots$ satisfiesSome authors consider merely finitely additive probability spaces, in which case one just needs an algebra of sets, rather than a σ-algebra. Quasiprobability distributions in general relax the third axiom.$$ P\\left(\\bigcup {i&#x3D;1}^{\\infty }E{i}\\right)&#x3D;\\sum {i&#x3D;1}^{\\infty }P(E{i}) $$可列可加性 注：摘自维基百科，对应于书本上的三个性质，但每个公理具体内容没看 Bayesian probability 频率学派将频率视为概率，因为他们考虑的事件是独立可重复的（under frequentist inference, a hypothesis is typically tested without being assigned a probability） 贝叶斯概率考虑那些非独立重复的假设（ In the Bayesian view, a probability is assigned to a hypothesis），所谓假设，相比于事件，强调了未发生、不可重复 the Bayesian probabilist specifies a prior probability. This, in turn, is then updated to a posterior probability in the light of new, relevant evidence. Reference 3blue1brown 贝叶斯定理 PRML Probability axioms WIKI Cox’s theorem","raw":null,"content":null,"categories":[{"name":"数学","slug":"数学","permalink":"http://jlutangchuan.github.io/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"BayesTheorem","slug":"BayesTheorem","permalink":"http://jlutangchuan.github.io/tags/BayesTheorem/"},{"name":"Math","slug":"Math","permalink":"http://jlutangchuan.github.io/tags/Math/"}]},{"title":"Latex 数学公式","slug":"技术/编程/Latex-数学公式","date":"2020-01-28T15:25:34.000Z","updated":"2023-07-03T15:04:37.038Z","comments":true,"path":"2020/01/28/ji-zhu/bian-cheng/latex-shu-xue-gong-shi/","link":"","permalink":"http://jlutangchuan.github.io/2020/01/28/ji-zhu/bian-cheng/latex-shu-xue-gong-shi/","excerpt":"","text":"公式符号 注意：在这里写公式要在开头加 mathjax: true（只是这个主题支持，不是hexo支持） 参考资料 Cmd Markdown 公式指导手册 很详细，在这里搜就可以 打开Mathtype，写好公式，设置复制格式为Latex，粘在md 行内与独行 行内公式：将公式插入到本行内，符号：$公式内容$，如：$xyz$ 独行公式：将公式插入到新的一行内，并且居中，符号：$$公式内容$$，如：$$xyz$$ 上标、下标与组合 上标符号，符号：^，如：$x^4$ 下标符号，符号：_，如：$x_1$ 组合符号，符号：&#123;&#125;，如：${16}{8}O{2+}{2}$ 汉字、字体与格式 汉字形式，符号：\\mbox&#123;&#125;，如：$V_{\\mbox{初始}}$ 字体控制，符号：\\displaystyle，如：$\\displaystyle \\frac{x+y}{y+z}$ 下划线符号，符号：\\underline，如：$\\underline{x+y}$ 标签，符号\\tag&#123;数字&#125;，如：$\\tag{11}$ 上大括号，符号：\\overbrace&#123;算式&#125;，如：$\\overbrace{a+b+c+d}^{2.0}$ 下大括号，符号：\\underbrace&#123;算式&#125;，如：$a+\\underbrace{b+c}_{1.0}+d$ 上位符号，符号：\\stacrel&#123;上位符号&#125;&#123;基位符号&#125;，如：$\\vec{x}\\stackrel{\\mathrm{def}}{&#x3D;}{x_1,\\dots,x_n}$ 加粗：$\\mathbf{x}$ 占位符 两个quad空格，符号：\\qquad，如：$x \\qquad y$ quad空格，符号：\\quad，如：$x \\quad y$ 大空格，符号\\，如：$x \\ y$ 中空格，符号\\:，如：$x : y$ 小空格，符号\\,，如：$x , y$ 没有空格，符号&#96;&#96;，如：$xy$ 紧贴，符号\\!，如：$x ! y$ 定界符与组合 括号，符号：（）\\big(\\big) \\Big(\\Big) \\bigg(\\bigg) \\Bigg(\\Bigg)，如：$（）\\big(\\big) \\Big(\\Big) \\bigg(\\bigg) \\Bigg(\\Bigg)$ 中括号，符号：[]，如：$[x+y]$ 大括号，符号：\\left\\&#123; x+y \\right\\&#125;，如：$\\left{ x+y\\right}$ 自适应括号，符号：\\left \\right，如：$\\left(x\\right)$，$\\left(x{yz}\\right)$ 组合公式，符号：&#123;上位公式 \\choose 下位公式&#125;，如：${n+1 \\choose k}&#x3D;{n \\choose k}+{n \\choose k-1}$ 组合公式，符号：&#123;上位公式 \\atop 下位公式&#125;，如：$\\sum_{k_0,k_1,\\ldots&gt;0 \\atop k_0+k_1+\\cdots&#x3D;n}A_{k_0}A_{k_1}\\cdots$ 四则运算 加法运算，符号：+，如：$x+y&#x3D;z$ 减法运算，符号：-，如：$x-y&#x3D;z$ 加减运算，符号：\\pm，如：$x \\pm y&#x3D;z$ 减甲运算，符号：\\mp，如：$x \\mp y&#x3D;z$ 乘法运算，符号：\\times，如：$x \\times y&#x3D;z$ 点乘运算，符号：\\cdot，如：$x \\cdot y&#x3D;z$ 星乘运算，符号：\\ast，如：$x \\ast y&#x3D;z$ 除法运算，符号：\\div，如：$x \\div y&#x3D;z$ 斜法运算，符号：/，如：$x&#x2F;y&#x3D;z$ 分式表示，符号：\\frac&#123;分子&#125;&#123;分母&#125;，如：$\\frac{x+y}{y+z}$ 分式表示，符号：&#123;分子&#125; \\voer &#123;分母&#125;，如：${x+y} \\over {y+z}$ 绝对值表示，符号：||，如：$|x+y|$ 高级运算 平均数运算，符号：\\overline&#123;算式&#125;，如：$\\overline{xyz}$ 开二次方运算，符号：\\sqrt，如：$\\sqrt x$ 开方运算，符号：\\sqrt[开方数]&#123;被开方数&#125;，如：$\\sqrt[3]{x+y}$ 对数运算，符号：\\log，如：$\\log(x)$ 极限运算，符号：\\lim，如：$\\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ 极限运算，符号：\\displaystyle \\lim，如：$\\displaystyle \\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ 求和运算，符号：\\sum，如：$\\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ 求和运算，符号：\\displaystyle \\sum，如：$\\displaystyle \\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$ 积分运算，符号：\\int，如：$\\int^{\\infty}_{0}{xdx}$ 积分运算，符号：\\displaystyle \\int，如：$\\displaystyle \\int^{\\infty}_{0}{xdx}$ 微分运算，符号：\\partial，如：$\\frac{\\partial x}{\\partial y}$ 矩阵表示，符号：\\begin&#123;matrix&#125; \\end&#123;matrix&#125;，如：$\\left[ \\begin{matrix} 1 &amp;2 &amp;\\cdots &amp;4\\ 5 &amp;6 &amp;\\cdots &amp;8\\ \\vdots &amp;\\vdots &amp;\\ddots &amp;\\vdots \\ 13 &amp;14 &amp;\\cdots &amp;16\\end{matrix} \\right]$ 逻辑运算 等于运算，符号：=，如：$x+y&#x3D;z$ 大于运算，符号：&gt;，如：$x+y&gt;z$ 小于运算，符号：&lt;，如：$x+y&lt;z$ 大于等于运算，符号：\\geq，如：$x+y \\geq z$ 小于等于运算，符号：\\leq，如：$x+y \\leq z$ 不等于运算，符号：\\neq，如：$x+y \\neq z$ 不大于等于运算，符号：\\ngeq，如：$x+y \\ngeq z$ 不大于等于运算，符号：\\not\\geq，如：$x+y \\not\\geq z$ 不小于等于运算，符号：\\nleq，如：$x+y \\nleq z$ 不小于等于运算，符号：\\not\\leq，如：$x+y \\not\\leq z$ 约等于运算，符号：\\approx，如：$x+y \\approx z$ 恒定等于运算，符号：\\equiv，如：$x+y \\equiv z$ 集合运算 属于运算，符号：\\in，如：$x \\in y$ 不属于运算，符号：\\notin，如：$x \\notin y$ 不属于运算，符号：\\not\\in，如：$x \\not\\in y$ 子集运算，符号：\\subset，如：$x \\subset y$ 子集运算，符号：\\supset，如：$x \\supset y$ 真子集运算，符号：\\subseteq，如：$x \\subseteq y$ 非真子集运算，符号：\\subsetneq，如：$x \\subsetneq y$ 真子集运算，符号：\\supseteq，如：$x \\supseteq y$ 非真子集运算，符号：\\supsetneq，如：$x \\supsetneq y$ 非子集运算，符号：\\not\\subset，如：$x \\not\\subset y$ 非子集运算，符号：\\not\\supset，如：$x \\not\\supset y$ 并集运算，符号：\\cup，如：$x \\cup y$ 交集运算，符号：\\cap，如：$x \\cap y$ 差集运算，符号：\\setminus，如：$x \\setminus y$ 同或运算，符号：\\bigodot，如：$x \\bigodot y$ 同与运算，符号：\\bigotimes，如：$x \\bigotimes y$ 实数集合，符号：\\mathbb&#123;R&#125;，如：\\mathbb&#123;R&#125; 自然数集合，符号：\\mathbb&#123;Z&#125;，如：\\mathbb&#123;Z&#125; 空集，符号：\\emptyset，如：$\\emptyset$ 数学符号 无穷，符号：\\infty，如：$\\infty$ 虚数，符号：\\imath，如：$\\imath$ 虚数，符号：\\jmath，如：$\\jmath$ 数学符号，符号\\hat&#123;a&#125;，如：$\\hat{a}$ 数学符号，符号\\check&#123;a&#125;，如：$\\check{a}$ 数学符号，符号\\breve&#123;a&#125;，如：$\\breve{a}$ 数学符号，符号\\tilde&#123;a&#125;，如：$\\tilde{a}$ 数学符号，符号\\bar&#123;a&#125;，如：$\\bar{a}$ 矢量符号，符号\\vec&#123;a&#125;，如：$\\vec{a}$ 数学符号，符号\\acute&#123;a&#125;，如：$\\acute{a}$ 数学符号，符号\\grave&#123;a&#125;，如：$\\grave{a}$ 数学符号，符号\\mathring&#123;a&#125;，如：$\\mathring{a}$ 一阶导数符号，符号\\dot&#123;a&#125;，如：$\\dot{a}$ 二阶导数符号，符号\\ddot&#123;a&#125;，如：$\\ddot{a}$ 上箭头，符号：\\uparrow，如：$\\uparrow$ 上箭头，符号：\\Uparrow，如：$\\Uparrow$ 下箭头，符号：\\downarrow，如：$\\downarrow$ 下箭头，符号：\\Downarrow，如：$\\Downarrow$ 左箭头，符号：\\leftarrow，如：$\\leftarrow$ 左箭头，符号：\\Leftarrow，如：$\\Leftarrow$ 右箭头，符号：\\rightarrow，如：$\\rightarrow$ 右箭头，符号：\\Rightarrow，如：$\\Rightarrow$ 底端对齐的省略号，符号：\\ldots，如：$1,2,\\ldots,n$ 中线对齐的省略号，符号：\\cdots，如：$x_1^2 + x_2^2 + \\cdots + x_n^2$ 竖直对齐的省略号，符号：\\vdots，如：$\\vdots$ 斜对齐的省略号，符号：\\ddots，如：$\\ddots$","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://jlutangchuan.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Latex","slug":"Latex","permalink":"http://jlutangchuan.github.io/tags/Latex/"}]},{"title":"Hexo-Theme-Sakura","slug":"技术/编程/Hexo-Theme-Sakura","date":"2018-12-12T14:16:01.000Z","updated":"2023-07-03T15:04:37.036Z","comments":true,"path":"2018/12/12/ji-zhu/bian-cheng/hexo-theme-sakura/","link":"","permalink":"http://jlutangchuan.github.io/2018/12/12/ji-zhu/bian-cheng/hexo-theme-sakura/","excerpt":"","text":"hexo-theme-sakura主题 English document 基于WordPress主题Sakura修改成Hexo的主题。 demo预览 正在开发中…… 交流群若你是使用者，加群QQ: 801511924 若你是创作者，加群QQ: 194472590 主题特性 首页大屏视频 首页随机封面 图片懒加载 valine评论 fancy-box相册 pjax支持，音乐不间断 aplayer音乐播放器 多级导航菜单（按现在大部分hexo主题来说，这也算是个特性了） 赞赏作者如果喜欢hexo-theme-sakura主题，可以考虑资助一下哦~非常感激！ paypal | Alipay 支付宝 | WeChat Pay 微信支付 未完善的使用教程那啥？老实说我目前也不是很有条理233333333~ 1、主题下载安装hexo-theme-sakura建议下载压缩包格式，因为除了主题内容还有些source的配置对新手来说比较太麻烦，直接下载解压就省去这些麻烦咯。 下载好后解压到博客根目录（不是主题目录哦，重复的选择替换）。接着在命令行（cmd、bash）运行npm i安装依赖。 2、主题配置博客根目录下的_config配置站点 # Site title: 你的站点名 subtitle: description: 站点简介 keywords: author: 作者名 language: zh-cn timezone: 部署 deploy: type: git repo: github: 你的github仓库地址 # coding: 你的coding仓库地址 branch: master 备份 （使用hexo b发布备份到远程仓库） backup: type: git message: backup my blog of https://honjun.github.io/ repository: # 你的github仓库地址,备份分支名 （建议新建backup分支） github: https://github.com/honjun/honjun.github.io.git,backup # coding: https://git.coding.net/hojun/hojun.git,backup 主题目录下的_config配置其中标明【改】的是需要修改部门，标明【选】是可改可不改，标明【非】是不用改的部分 # site name # 站点名 【改】 prefixName: さくら荘その siteName: hojun # favicon and site master avatar # 站点的favicon和头像 输入图片路径（下面的配置是都是cdn的相对路径，没有cdn请填写完整路径，建议使用jsdeliver搭建一个cdn啦，先去下载我的cdn替换下图片就行了，简单方便~）【改】 favicon: /images/favicon.ico avatar: /img/custom/avatar.jpg # 站点url 【改】 url: https://sakura.hojun.cn # 站点介绍（或者说是个人签名）【改】 description: Live your life with passion! With some drive! # 站点cdn，没有就为空 【改】 若是cdn为空，一些图片地址就要填完整地址了，比如之前avatar就要填https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/custom/avatar.jpg cdn: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6 # 开启pjax 【选】 pjax: 1 # 站点首页的公告信息 【改】 notice: hexo-Sakura主题已经开源，目前正在开发中... # 懒加载的加载中图片 【选】 lazyloadImg: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/loader/orange.progress-bar-stripe-loader.svg # 站点菜单配置 【选】 menus: 首页: &#123; path: /, fa: fa-fort-awesome faa-shake &#125; 归档: &#123; path: /archives, fa: fa-archive faa-shake, submenus: &#123; 技术: &#123;path: /categories/技术/, fa: fa-code &#125;, 生活: &#123;path: /categories/生活/, fa: fa-file-text-o &#125;, 资源: &#123;path: /categories/资源/, fa: fa-cloud-download &#125;, 随想: &#123;path: /categories/随想/, fa: fa-commenting-o &#125;, 转载: &#123;path: /categories/转载/, fa: fa-book &#125; &#125; &#125; 清单: &#123; path: javascript:;, fa: fa-list-ul faa-vertical, submenus: &#123; 书单: &#123;path: /tags/悦读/, fa: fa-th-list faa-bounce &#125;, 番组: &#123;path: /reading/, fa: fa-film faa-vertical &#125;, 歌单: &#123;path: /music/, fa: fa-headphones &#125;, 图集: &#123;path: /tags/图集/, fa: fa-photo &#125; &#125; &#125; 留言板: &#123; path: /comment/, fa: fa-pencil-square-o faa-tada &#125; 友人帐: &#123; path: /links/, fa: fa-link faa-shake &#125; 赞赏: &#123; path: /donate/, fa: fa-heart faa-pulse &#125; 关于: &#123; path: /, fa: fa-leaf faa-wrench , submenus: &#123; 我？: &#123;path: /about/, fa: fa-meetup&#125;, 主题: &#123;path: /theme-sakura/, fa: iconfont icon-sakura &#125;, Lab: &#123;path: /lab/, fa: fa-cogs &#125;, &#125; &#125; 客户端: &#123; path: /client/, fa: fa-android faa-vertical &#125; RSS: &#123; path: /atom.xml, fa: fa-rss faa-pulse &#125; # Home page sort type: -1: newer first，1: older first. 【非】 homePageSortType: -1 # Home page article shown number) 【非】 homeArticleShown: 10 # 背景图片 【选】 bgn: 8 # startdash面板 url, title, desc img 【改】 startdash: - &#123;url: /theme-sakura/, title: Sakura, desc: 本站 hexo 主题, img: /img/startdash/sakura.md.png&#125; - &#123;url: http://space.bilibili.com/271849279, title: Bilibili, desc: 博主的b站视频, img: /img/startdash/bilibili.jpg&#125; - &#123;url: /, title: hojun的万事屋, desc: 技术服务, img: /img/startdash/wangshiwu.jpg&#125; # your site build time or founded date # 你的站点建立日期 【改】 siteBuildingTime: 07/17/2018 # 社交按钮(social) url, img PC端配置 【改】 social: github: &#123;url: http://github.com/honjun, img: /img/social/github.png&#125; sina: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/sina.png&#125; wangyiyun: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/wangyiyun.png&#125; zhihu: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/zhihu.png&#125; email: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/email.svg&#125; wechat: &#123;url: /#, qrcode: /img/custom/wechat.jpg, img: /img/social/wechat.png&#125; # 社交按钮(msocial) url, img 移动端配置 【改】 msocial: github: &#123;url: http://github.com/honjun, fa: fa-github, color: 333&#125; weibo: &#123;url: http://weibo.com/mashirozx?is_all=1, fa: fa-weibo, color: dd4b39&#125; qq: &#123;url: https://wpa.qq.com/msgrd?v=3&amp;uin=954655431&amp;site=qq&amp;menu=yes, fa: fa-qq, color: 25c6fe&#125; # 赞赏二维码（其中wechatSQ是赞赏单页面的赞赏码图片）【改】 donate: alipay: /img/custom/donate/AliPayQR.jpg wechat: /img/custom/donate/WeChanQR.jpg wechatSQ: /img/custom/donate/WeChanSQ.jpg # 首页视频地址为https://cdn.jsdelivr.net/gh/honjun/hojun@1.2/Unbroken.mp4，配置如下 【改】 movies: url: https://cdn.jsdelivr.net/gh/honjun/hojun@1.2 # 多个视频用逗号隔开，随机获取。支持的格式目前已知MP4,Flv。其他的可以试下，不保证有用 name: Unbroken.mp4 # 左下角aplayer播放器配置 主要改id和server这两项，修改详见[aplayer文档] 【改】 aplayer: id: 2660651585 server: netease type: playlist fixed: true mini: false autoplay: false loop: all order: random preload: auto volume: 0.7 mutex: true # Valine评论配置【改】 valine: true v_appId: GyC3NzMvd0hT9Yyd2hYIC0MN-gzGzoHsz v_appKey: mgOpfzbkHYqU92CV4IDlAUHQ 分类页和标签页配置分类页 标签页 配置项在\\themes\\Sakura\\languages\\zh-cn.yml里。新增一个分类或标签最好加下哦，当然嫌麻烦可以直接使用一张默认图片（可以改主题或者直接把404图片替换下，征求下意见要不要给这个在配置文件中加个开关，可以issue或群里提出来），现在是没设置的话会使用那种倒立小狗404哦。 #category # 按分类名创建 技术: #中文标题 zh: 野生技术协会 # 英文标题 en: Geek – Only for Love # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/coding.jpg 生活: zh: 生活 en: live img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/writing.jpg #tag # 标签名即是标题 悦读: # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/reading.jpg 单页面封面配置如留言板页面页面，位于source下的comment下，打开index.md如下：&#96;&#96;&#96;mdtitle: commentdate: 2018-12-20 23:13:48keywords: 留言板description:comments: true# 在这里配置单页面头部图片，自定义替换哦~photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/comment.jpg ## 单页面配置 ### 番组计划页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） ![](https://wx2.sinaimg.cn/large/006bYVyvly1g07b2gyx60j31090jjahj.jpg) ```yml --- layout: reading title: reading comments: false date: 2019-02-10 21:32:48 keywords: description: readings: # 番组图片 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg # 番组名 title: 朝花夕誓——于离别之朝束起约定之花 # 追番状态 （追番ing/已追完） status: 已追完 # 追番进度 progress: 100 # 番剧日文名称 jp: さよならの朝に約束の花をかざろう # 放送时间 time: 放送时间: 2018-02-24 SUN. # 番剧介绍 desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg title: 朝花夕誓——于离别之朝束起约定之花 status: 已追完 progress: 50 jp: さよならの朝に約束の花をかざろう time: 放送时间: 2018-02-24 SUN. desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。 --- 友链页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） --- layout: links title: links # 创建日期，可以改下 date: 2018-12-19 23:11:06 # 图片上的标题，自定义修改 keywords: 友人帐 description: # true/false 开启/关闭评论 comments: true # 页面头部图片，自定义修改 photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/links.jpg # 友链配置 links: # 类型分组 - group: 个人项目 # 类型简介 desc: 充分说明这家伙是条咸鱼 &lt; (￣︶￣)&gt; items: # 友链链接 - url: https://shino.cc/fgvf # 友链头像 img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg # 友链站点名 name: Google # 友链介绍 下面雷同 desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 # 类型分组... - group: 小伙伴们 desc: 欢迎交换友链 ꉂ(ˊᗜˋ) items: - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 --- 写文章配置主题集成了个人插件hexo-tag-bili和hexo-tag-fancybox_img。其中hexo-tag-bili用来在文章或单页面中插入B站外链视频，使用语法如下： &#123;% bili video_id [page] %&#125; 详细使用教程详见hexo-tag-bili。 hexo-tag-fancybox_img用来在文章或单页面中图片，使用语法如下： &#123;% fb_img src [caption] %&#125; 详细使用教程详见hexo-tag-fancybox_img 还有啥，一时想不起来……To be continued…","raw":null,"content":null,"categories":[{"name":"编程","slug":"编程","permalink":"http://jlutangchuan.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://jlutangchuan.github.io/tags/Hexo/"}]}]}